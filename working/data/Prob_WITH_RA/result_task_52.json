{
    "Link_API":"https:\/\/api.stackexchange.com\/2.3\/questions\/124888",
    "Title":"Are the eigenvalues of $AB$ equal to the eigenvalues of $BA$?",
    "Score":99,
    "Category":"Chứng minh",
    "Tags":"linear-algebra, matrices, eigenvalues-eigenvectors",
    "Link":"https:\/\/math.stackexchange.com\/questions\/124888\/are-the-eigenvalues-of-ab-equal-to-the-eigenvalues-of-ba",
    "Content":"First of all, am I being crazy in thinking that if $\\lambda$ is an eigenvalue of $AB$, where $A$ and $B$ are both $N \\times N$ matrices (not necessarily invertible), then $\\lambda$ is also an eigenvalue of $BA$? If it's not true, then under what conditions is it true or not true? If it is true, can anyone point me to a citation?  I couldn't find it in a quick perusal of Horn & Johnson.  I have seen a couple proofs that the characteristic polynomial of $AB$ is equal to the characteristic polynomial of $BA$, but none with any citations. A trivial proof would be OK, but a citation is better.",
    "AcceptedAnswer":"If $v$ is an eigenvector of $AB$ for some nonzero $\\lambda$, then $Bv\\ne0$\nand $$\\lambda Bv=B(ABv)=(BA)Bv,$$ so $Bv$ is an eigenvector for $BA$ with the same eigenvalue. If $0$ is an eigenvalue of $AB$ then $0=\\det(AB)=\\det(A)\\det(B)=\\det(BA)$ so $0$ is also an eigenvalue of $BA$. More generally, Jacobson's lemma in operator theory states that for any two bounded operators $A$ and $B$ acting on a Hilbert space $H$ (or more generally, for any two elements of a Banach algebra), the non-zero points of the spectrum of $AB$ coincide with those of the spectrum of $BA$.",
    "llm_answer_create_structured_problem":"###BEGIN_OF_FORMAT###\nAssumption: \n$A$ is an $N \\times N$ matrix,\n$B$ is an $N \\times N$ matrix.\nProblem: \nProve that the eigenvalues of $AB$ are equal to the eigenvalues of $BA$.\n###",
    "reasoning_create_structured_problem":"Okay, let's try to tackle this problem. The user is asking whether the eigenvalues of AB are the same as those of BA for two N×N matrices A and B. They also want to know under what conditions this holds or doesn't hold, and if possible, a citation.\n\nFirst, I need to recall linear algebra concepts. I remember that for square matrices, there's a property related to eigenvalues of AB and BA. If either A or B is invertible, then AB and BA are similar matrices, which would mean they have the same eigenvalues. Because if A is invertible, then BA = A^{-1}(AB)A, so they're similar. Same if B is invertible.\n\nBut the question says A and B are not necessarily invertible. So what happens in that case? I think even if they aren't invertible, the non-zero eigenvalues should still be the same. Wait, how does that work?\n\nThere's a theorem that states that the characteristic polynomials of AB and BA are the same except for possibly a factor of λ^k where k is the difference in ranks or something. So the non-zero eigenvalues (counting multiplicities) should be the same for AB and BA. Therefore, the eigenvalues of AB and BA are the same, except that BA might have additional zero eigenvalues if the matrices are of different ranks. But wait, here both A and B are N×N, so AB and BA are also N×N, so maybe the multiplicities of zero eigenvalues would differ, but the set of eigenvalues (including zero) would still be the same? Or not?\n\nWait, let me think again. Suppose A is a singular matrix and B is also singular. For example, take A as a matrix with a zero column and B with a zero row. Then AB might have rank less than N, and BA as well. But maybe their eigenvalues still coincide. Let me take a simple example. Let A be [[0,1],[0,0]] and B be [[1,0],[0,0]]. Then AB is [[0,0],[0,0]], so its only eigenvalue is 0. BA would be [[0,1],[0,0]], which also has eigenvalues 0. So in that case, both have eigenvalue 0. Another example: Let A = [[0,1],[0,0]], B = [[0,0],[0,1]]. Then AB is [[0,1],[0,0]], which has eigenvalues 0. BA is [[0,0],[0,0]], eigenvalues 0. Hmm, same eigenvalues. Maybe even when they are singular, the eigenvalues (including zeros) are the same?\n\nWait, another example: Let A be a 2x2 matrix with first row [1,0] and second row [0,0], and B be [0,0;0,1]. Then AB is [0,0;0,0], eigenvalues 0. BA is [0,0;0,0], same eigenvalues. Hmm, maybe in all cases, the eigenvalues (including zero) are the same. Wait, but what if A and B are not square? Wait, in the problem they are both N×N. So maybe even for square matrices, regardless of invertibility, AB and BA have the same eigenvalues.\n\nBut I need to check. Wait, there's a theorem called Sylvester's determinant theorem, which says that det(I + AB) = det(I + BA) even for rectangular matrices. But eigenvalues are related to the characteristic polynomial. If we consider the characteristic polynomial of AB and BA, for square matrices, the eigenvalues are roots of det(λI - AB) and det(λI - BA). If A and B are square matrices, then det(λI - AB) = det(λI - BA). So their characteristic polynomials are the same, hence the eigenvalues (including algebraic multiplicities) are the same.\n\nWait, but this is only when they are square matrices. Let me confirm that. Suppose A and B are N×N. Then AB and BA are both N×N. So det(λI - AB) = det(λI - BA). If that's the case, then all eigenvalues (including multiplicities) are the same. Therefore, the answer would be yes, the eigenvalues are equal. But the user is asking for a citation. I think this is a standard result in linear algebra. Maybe in Horn and Johnson's Matrix Analysis, but the user says they checked and didn't find it.\n\nAlternatively, maybe when A and B are square matrices, AB and BA have the same eigenvalues. If A or B is invertible, then AB and BA are similar. If neither is invertible, then maybe the characteristic polynomials are still the same. Let's test with a 2x2 example where both A and B are singular. Let A be [[1,1],[1,1]] and B be [[1,0],[1,0]]. Then AB is [[2,0],[2,0]], which has eigenvalues 2 and 0. BA is [[1,1],[1,1]] times [[1,0],[1,0]] is [[2,0],[2,0]], same as AB. Wait, but that's a coincidence. Let me try another example. Let A = [[1,0],[0,0]] and B = [[0,1],[0,0]]. Then AB is [[0,1],[0,0]], which has eigenvalues 0. BA is [[0,0],[0,0]], which has eigenvalues 0. Hmm, same eigenvalues. Another example: A = [[0,1],[0,0]], B = [[1,1],[1,1]]. Then AB is [[1,1],[0,0]], eigenvalues 0 and 1. BA is [[0,1],[0,1]] times [[1,1],[1,1]]... Wait, let me compute BA: B is 2x2, A is 2x2. BA would be [[0*1 +1*1, 0*1 +1*1],[0*1 +1*1, 0*1 +1*1]] which is [[1,1],[1,1]], which has eigenvalues 2 and 0. AB was [[1,1],[0,0]], which has eigenvalues 0 and 1. Wait, that's different. Wait, so here AB has eigenvalues 0 and 1, BA has eigenvalues 0 and 2. So their non-zero eigenvalues differ. That contradicts the earlier idea. So in this case, AB and BA have different eigenvalues. Wait, so what's going on here?\n\nWait, in this example, A is [[0,1],[0,0]], B is [[1,1],[1,1]]. Then AB = A * B = [[0*1 +1*1, 0*1 +1*1],[0*1 +0*1, 0*1 +0*1]] = [[1,1],[0,0]]. The eigenvalues of AB are 0 and 1. Then BA is B * A = [[1*0 +1*0, 1*1 +1*0],[1*0 +1*0, 1*1 +1*0]] = [[0,1],[0,1]]. The eigenvalues of BA are 0 and 1. Wait, no, BA is [[0,1],[0,1]], which is a rank 1 matrix. Its trace is 0 +1=1, determinant is 0, so eigenvalues are 0 and 1. Wait, so AB and BA both have eigenvalues 0 and 1. Hmm, maybe my previous calculation was wrong.\n\nWait, let me check again. BA = [[1*0 +1*0, 1*1 +1*0], [1*0 +1*0, 1*1 +1*0]] = [[0,1], [0,1]]. Correct. So the trace is 1, determinant 0, so eigenvalues 0 and 1. So AB and BA have same eigenvalues. Then maybe my previous thought was wrong.\n\nWait, maybe another example. Let me try with A = [[0,1],[0,0]] and B = [[0,0],[1,0]]. Then AB = [[1,0],[0,0]], which has eigenvalues 1 and 0. BA = [[0,0],[0,1]], which has eigenvalues 0 and 1. So same eigenvalues. Hmm. Let me try another one where maybe they differ. Suppose A is [[1,0],[0,0]], B is [[0,1],[0,0]]. Then AB is [[0,1],[0,0]], eigenvalues 0. BA is [[0,0],[0,0]], eigenvalues 0. Same.\n\nWait, maybe I need a different example where AB and BA have different eigenvalues. Let me see. Take A as [[0,1,0],[0,0,1],[0,0,0]], B as some matrix. Hmm, maybe this is getting too complex. Alternatively, maybe it's always true that AB and BA have the same eigenvalues when A and B are square matrices. Because the characteristic polynomials are the same. Let me check that.\n\nFor square matrices A and B, the characteristic polynomial of AB and BA. Suppose A and B are n×n. Then, det(λI - AB) = det(λI - BA). Is this true? Let's test with λ=0. Then det(-AB) = (-1)^n det(AB) and det(-BA) = (-1)^n det(BA). But det(AB) = det(A)det(B) = det(BA). So for λ=0, it's the same. For general λ, is det(λI - AB) = det(λI - BA)? Wait, there's a theorem that says for square matrices, AB and BA have the same eigenvalues. But how?\n\nWait, if we consider the characteristic polynomial, det(λI - AB) = det(λI - BA). Let me see for 2x2 matrices. Let A = [[a,b],[c,d]], B = [[e,f],[g,h]]. Then AB and BA can be computed, and their characteristic polynomials calculated. Alternatively, maybe use the fact that trace(AB) = trace(BA), and det(AB) = det(BA). So if the trace and determinant are the same, then for 2x2 matrices, the characteristic polynomials are the same. So eigenvalues would be the same.\n\nIn general, trace(AB) = trace(BA), and more generally, the trace of any product is invariant under cyclic permutations. So for AB and BA, trace is same. Similarly, det(AB) = det(A)det(B) = det(B)det(A) = det(BA). For n×n matrices, the characteristic polynomial is determined by the traces of powers, determinants, etc. But maybe for AB and BA, all the coefficients of the characteristic polynomial are the same. Therefore, their eigenvalues (with algebraic multiplicities) are the same.\n\nTherefore, the answer is that yes, the eigenvalues of AB and BA are the same when A and B are square matrices of the same size. The user also asks under what conditions it's true. So if A and B are square matrices, then eigenvalues are the same. If they are rectangular, then it's not necessarily the case, but the question specifies both are N×N.\n\nSo in the problem, since A and B are both N×N matrices, the eigenvalues of AB and BA are equal. The assumption is that A and B are square matrices of the same size. The problem is to show that the eigenvalues of AB and BA are equal, or to determine under what conditions this holds.\n\nBut the original question mentions that they are not necessarily invertible, so the answer holds regardless of invertibility. Therefore, the problem structured would have the assumption that A and B are N×N matrices, with no invertibility required. The problem is to prove that the eigenvalues of AB are equal to those of BA, or to find conditions where this is true or not. But since in the square case, they are always equal, the answer would be that it's always true for square matrices, and if they are rectangular, then the non-zero eigenvalues are the same.\n\nBut the user's question specifically states that A and B are both N×N, so the answer would be that it's always true in that case. The example given in the original problem's assumption in the user's example was adding that n is divisible by 7, but here, the assumptions are that A and B are N×N matrices. So the formatted problem would have assumptions: A is an N×N matrix, B is an N×N matrix. Problem: Prove that the eigenvalues of AB are equal to the eigenvalues of BA.",
    "Original_Problem":"Assumption: \n$A$ is an $N \\times N$ matrix,\n$B$ is an $N \\times N$ matrix.\nProblem: \nProve that the eigenvalues of $AB$ are equal to the eigenvalues of $BA$.",
    "Proof_problem":"Yes",
    "Redundant_assumption":"$$\\lambda Bv=B(ABv)=(BA)Bv,$$",
    "Problem_with_redundant_assumption":"Assumption:\nAssumption 1: $A$ is an $N \\times N$ matrix,\nAssumption 2: $B$ is an $N \\times N$ matrix.\nAssumption 3: $$\\lambda Bv=B(ABv)=(BA)Bv,$$\nProblem: \nProve that the eigenvalues of $AB$ are equal to the eigenvalues of $BA$.",
    "judge":"Answer to Q1: yes\nNew_problem:\nGiven A and B are N×N matrices, prove that the eigenvalues of AB are equal to the eigenvalues of BA.\nSolution_for_new_problem:\nProof: Let λ be an eigenvalue of AB with eigenvector v ≠ 0, so ABv = λv.\n\nCase 1: λ ≠ 0. Then Bv ≠ 0 (otherwise ABv = A(0) = 0 = λv, contradiction). Now BA(Bv) = B(ABv) = B(λv) = λ(Bv). Thus λ is eigenvalue of BA with eigenvector Bv.\n\nCase 2: λ = 0. Then ABv = 0. If Bv ≠ 0, then BA(Bv) = B(ABv) = B(0) = 0, so 0 is eigenvalue of BA with eigenvector Bv. If Bv = 0, then B has nontrivial nullspace, so 0 is eigenvalue of B, hence 0 is eigenvalue of BA (since det(BA) = det(B)det(A) = 0).\n\nSimilarly, if μ is eigenvalue of BA, then μ is eigenvalue of AB by symmetric argument (swap A and B).\n\nThus eigenvalues of AB = eigenvalues of BA.\n",
    "proof strategy planner":"Given A and B are N×N matrices, prove that the eigenvalues of AB are equal to the eigenvalues of BA.\nStep 1) Let λ be an eigenvalue of AB with eigenvector v ≠ 0, so ABv = λv.\nStep 2) Case 1: λ ≠ 0. Show Bv ≠ 0 (otherwise contradiction). Then compute BA(Bv) = B(ABv) = B(λv) = λ(Bv), proving λ is eigenvalue of BA with eigenvector Bv.\nStep 3) Case 2: λ = 0. Then ABv = 0. Subcase 2a: If Bv ≠ 0, then BA(Bv) = B(ABv) = B(0) = 0, so 0 is eigenvalue of BA with eigenvector Bv.\nStep 4) Subcase 2b: If Bv = 0, then B has nontrivial nullspace, so 0 is eigenvalue of B, hence 0 is eigenvalue of BA (since det(BA) = det(B)det(A) = 0).\nStep 5) By symmetric argument (swap A and B), any eigenvalue of BA is also an eigenvalue of AB.\nStep 6) Conclude that eigenvalues of AB = eigenvalues of BA.",
    "mathematician and proof writer":"Given A and B are N×N matrices, prove that the eigenvalues of AB are equal to the eigenvalues of BA.\nWe will prove that every eigenvalue of AB is also an eigenvalue of BA, and vice versa. Since the argument is symmetric, it suffices to show one direction.\n\n**Part 1: Every eigenvalue of AB is an eigenvalue of BA**\n\nLet λ be an eigenvalue of AB. Then there exists a nonzero vector v ∈ ℂ^N such that:\n\nABv = λv  \t(1)\n\nWe consider two cases: λ ≠ 0 and λ = 0.\n\n**Case 1: λ ≠ 0**\n\nFrom equation (1), we have ABv = λv. We claim that Bv ≠ 0. Suppose for contradiction that Bv = 0. Then from (1), we would have:\n\nABv = A(0) = 0 = λv\n\nSince λ ≠ 0, this implies v = 0, which contradicts v being an eigenvector (nonzero). Therefore, Bv ≠ 0.\n\nNow compute BA(Bv):\n\nBA(Bv) = B(ABv) \t(by associativity of matrix multiplication)\n        = B(λv) \t\t(using equation (1))\n        = λ(Bv) \t\t(since scalar multiplication commutes)\n\nThus, we have:\n\nBA(Bv) = λ(Bv)\n\nSince Bv ≠ 0, this shows that λ is an eigenvalue of BA with eigenvector Bv.\n\n**Case 2: λ = 0**\n\nWe have ABv = 0v = 0. Consider two subcases:\n\n**Subcase 2a: Bv ≠ 0**\n\nThen:\n\nBA(Bv) = B(ABv) = B(0) = 0 = 0·(Bv)\n\nSo 0 is an eigenvalue of BA with eigenvector Bv.\n\n**Subcase 2b: Bv = 0**\n\nIf Bv = 0, then v is in the nullspace of B, so 0 is an eigenvalue of B. Since det(BA) = det(B)det(A) = 0·det(A) = 0, the matrix BA is singular, which means 0 is an eigenvalue of BA.\n\nIn all cases, we have shown that if λ is an eigenvalue of AB, then λ is also an eigenvalue of BA.\n\n**Part 2: Every eigenvalue of BA is an eigenvalue of AB**\n\nThe argument is symmetric. Let μ be an eigenvalue of BA with eigenvector w ≠ 0, so BAw = μw. By exactly the same reasoning as above (with A and B swapped), we can show that μ is an eigenvalue of AB. The cases are:\n\n- If μ ≠ 0, then Aw ≠ 0 and AB(Aw) = μ(Aw)\n- If μ = 0 and Aw ≠ 0, then AB(Aw) = 0\n- If μ = 0 and Aw = 0, then 0 is eigenvalue of A, so AB is singular and has eigenvalue 0\n\n**Conclusion**\n\nWe have shown that every eigenvalue of AB is an eigenvalue of BA, and every eigenvalue of BA is an eigenvalue of AB. Therefore, the eigenvalues of AB are equal to the eigenvalues of BA.\n\n**Remark**: Note that the algebraic multiplicities may differ, but the sets of eigenvalues (counting without multiplicities) are identical.",
    "final reviewer":"```json\n{\n\"proof_review\": true,\n\"end_of_proof\": \"final:\"\n}\n```\nfinal:\n**Problem:**\n\nLet A and B be N×N matrices. Prove that the eigenvalues of AB are equal to the eigenvalues of BA.\n\n**Proof:**\n\nWe will prove that every eigenvalue of AB is also an eigenvalue of BA, and vice versa. Since the argument is symmetric, it suffices to show one direction.\n\n**Part 1: Every eigenvalue of AB is an eigenvalue of BA**\n\nLet λ be an eigenvalue of AB. Then there exists a nonzero vector v ∈ ℂ^N such that:\n\nABv = λv  (1)\n\nWe consider two cases: λ ≠ 0 and λ = 0.\n\n**Case 1: λ ≠ 0**\n\nFrom equation (1), we have ABv = λv. We claim that Bv ≠ 0. Suppose for contradiction that Bv = 0. Then from (1), we would have:\n\nABv = A(0) = 0 = λv\n\nSince λ ≠ 0, this implies v = 0, which contradicts v being an eigenvector (which must be nonzero). Therefore, Bv ≠ 0.\n\nNow, let's apply the matrix BA to the nonzero vector Bv:\n\nBA(Bv) = B(ABv) (by associativity of matrix multiplication)\n        = B(λv)   (using equation (1))\n        = λ(Bv)   (since scalar multiplication commutes)\n\nThus, we have:\n\nBA(Bv) = λ(Bv)\n\nSince Bv ≠ 0, this shows that λ is an eigenvalue of BA with eigenvector Bv.\n\n**Case 2: λ = 0**\n\nIf λ = 0 is an eigenvalue of AB, it means that the matrix AB is singular, so det(AB) = 0.\nUsing the property that the determinant of a product is the product of the determinants, we have:\n\ndet(AB) = det(A)det(B) = 0\n\nSince matrix multiplication of scalars is commutative, we also have:\n\ndet(BA) = det(B)det(A) = det(A)det(B) = 0\n\nSince det(BA) = 0, the matrix BA is also singular. A matrix is singular if and only if 0 is one of its eigenvalues. Therefore, 0 is an eigenvalue of BA.\n\nIn all cases, we have shown that if λ is an eigenvalue of AB, then λ is also an eigenvalue of BA.\n\n**Part 2: Every eigenvalue of BA is an eigenvalue of AB**\n\nThe argument is symmetric. By swapping the roles of A and B in the argument above, we can conclude that if μ is an eigenvalue of BA, then it is also an eigenvalue of AB.\n\n**Conclusion**\n\nWe have shown that the set of eigenvalues of AB is a subset of the set of eigenvalues of BA, and the set of eigenvalues of BA is a subset of the set of eigenvalues of AB. Therefore, the sets of eigenvalues are identical.",
    "Original_Problem_with_numerical_assumption":"Assumption:\nAssumption 1: $A$ is an $N \\times N$ matrix,\nAssumption 2: $B$ is an $N \\times N$ matrix.\nProblem: \nProve that the eigenvalues of $AB$ are equal to the eigenvalues of $BA$."
}