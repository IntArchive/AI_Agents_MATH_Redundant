{
    "Link_API":"https:\/\/api.stackexchange.com\/2.3\/questions\/124888",
    "Title":"Are the eigenvalues of $AB$ equal to the eigenvalues of $BA$?",
    "Score":99,
    "Category":"Chứng minh",
    "Tags":"linear-algebra, matrices, eigenvalues-eigenvectors",
    "Link":"https:\/\/math.stackexchange.com\/questions\/124888\/are-the-eigenvalues-of-ab-equal-to-the-eigenvalues-of-ba",
    "Content":"First of all, am I being crazy in thinking that if $\\lambda$ is an eigenvalue of $AB$, where $A$ and $B$ are both $N \\times N$ matrices (not necessarily invertible), then $\\lambda$ is also an eigenvalue of $BA$? If it's not true, then under what conditions is it true or not true? If it is true, can anyone point me to a citation?  I couldn't find it in a quick perusal of Horn & Johnson.  I have seen a couple proofs that the characteristic polynomial of $AB$ is equal to the characteristic polynomial of $BA$, but none with any citations. A trivial proof would be OK, but a citation is better.",
    "AcceptedAnswer":"If $v$ is an eigenvector of $AB$ for some nonzero $\\lambda$, then $Bv\\ne0$\nand $$\\lambda Bv=B(ABv)=(BA)Bv,$$ so $Bv$ is an eigenvector for $BA$ with the same eigenvalue. If $0$ is an eigenvalue of $AB$ then $0=\\det(AB)=\\det(A)\\det(B)=\\det(BA)$ so $0$ is also an eigenvalue of $BA$. More generally, Jacobson's lemma in operator theory states that for any two bounded operators $A$ and $B$ acting on a Hilbert space $H$ (or more generally, for any two elements of a Banach algebra), the non-zero points of the spectrum of $AB$ coincide with those of the spectrum of $BA$.",
    "llm_answer_create_structured_problem":"###BEGIN_OF_FORMAT###\nAssumption: \n$A$ is an $N \\times N$ matrix,\n$B$ is an $N \\times N$ matrix.\nProblem: \nProve that the eigenvalues of $AB$ are equal to the eigenvalues of $BA$.\n###",
    "reasoning_create_structured_problem":"Okay, let's try to tackle this problem. The user is asking whether the eigenvalues of AB are the same as those of BA for two N×N matrices A and B. They also want to know under what conditions this holds or doesn't hold, and if possible, a citation.\n\nFirst, I need to recall linear algebra concepts. I remember that for square matrices, there's a property related to eigenvalues of AB and BA. If either A or B is invertible, then AB and BA are similar matrices, which would mean they have the same eigenvalues. Because if A is invertible, then BA = A^{-1}(AB)A, so they're similar. Same if B is invertible.\n\nBut the question says A and B are not necessarily invertible. So what happens in that case? I think even if they aren't invertible, the non-zero eigenvalues should still be the same. Wait, how does that work?\n\nThere's a theorem that states that the characteristic polynomials of AB and BA are the same except for possibly a factor of λ^k where k is the difference in ranks or something. So the non-zero eigenvalues (counting multiplicities) should be the same for AB and BA. Therefore, the eigenvalues of AB and BA are the same, except that BA might have additional zero eigenvalues if the matrices are of different ranks. But wait, here both A and B are N×N, so AB and BA are also N×N, so maybe the multiplicities of zero eigenvalues would differ, but the set of eigenvalues (including zero) would still be the same? Or not?\n\nWait, let me think again. Suppose A is a singular matrix and B is also singular. For example, take A as a matrix with a zero column and B with a zero row. Then AB might have rank less than N, and BA as well. But maybe their eigenvalues still coincide. Let me take a simple example. Let A be [[0,1],[0,0]] and B be [[1,0],[0,0]]. Then AB is [[0,0],[0,0]], so its only eigenvalue is 0. BA would be [[0,1],[0,0]], which also has eigenvalues 0. So in that case, both have eigenvalue 0. Another example: Let A = [[0,1],[0,0]], B = [[0,0],[0,1]]. Then AB is [[0,1],[0,0]], which has eigenvalues 0. BA is [[0,0],[0,0]], eigenvalues 0. Hmm, same eigenvalues. Maybe even when they are singular, the eigenvalues (including zeros) are the same?\n\nWait, another example: Let A be a 2x2 matrix with first row [1,0] and second row [0,0], and B be [0,0;0,1]. Then AB is [0,0;0,0], eigenvalues 0. BA is [0,0;0,0], same eigenvalues. Hmm, maybe in all cases, the eigenvalues (including zero) are the same. Wait, but what if A and B are not square? Wait, in the problem they are both N×N. So maybe even for square matrices, regardless of invertibility, AB and BA have the same eigenvalues.\n\nBut I need to check. Wait, there's a theorem called Sylvester's determinant theorem, which says that det(I + AB) = det(I + BA) even for rectangular matrices. But eigenvalues are related to the characteristic polynomial. If we consider the characteristic polynomial of AB and BA, for square matrices, the eigenvalues are roots of det(λI - AB) and det(λI - BA). If A and B are square matrices, then det(λI - AB) = det(λI - BA). So their characteristic polynomials are the same, hence the eigenvalues (including algebraic multiplicities) are the same.\n\nWait, but this is only when they are square matrices. Let me confirm that. Suppose A and B are N×N. Then AB and BA are both N×N. So det(λI - AB) = det(λI - BA). If that's the case, then all eigenvalues (including multiplicities) are the same. Therefore, the answer would be yes, the eigenvalues are equal. But the user is asking for a citation. I think this is a standard result in linear algebra. Maybe in Horn and Johnson's Matrix Analysis, but the user says they checked and didn't find it.\n\nAlternatively, maybe when A and B are square matrices, AB and BA have the same eigenvalues. If A or B is invertible, then AB and BA are similar. If neither is invertible, then maybe the characteristic polynomials are still the same. Let's test with a 2x2 example where both A and B are singular. Let A be [[1,1],[1,1]] and B be [[1,0],[1,0]]. Then AB is [[2,0],[2,0]], which has eigenvalues 2 and 0. BA is [[1,1],[1,1]] times [[1,0],[1,0]] is [[2,0],[2,0]], same as AB. Wait, but that's a coincidence. Let me try another example. Let A = [[1,0],[0,0]] and B = [[0,1],[0,0]]. Then AB is [[0,1],[0,0]], which has eigenvalues 0. BA is [[0,0],[0,0]], which has eigenvalues 0. Hmm, same eigenvalues. Another example: A = [[0,1],[0,0]], B = [[1,1],[1,1]]. Then AB is [[1,1],[0,0]], eigenvalues 0 and 1. BA is [[0,1],[0,1]] times [[1,1],[1,1]]... Wait, let me compute BA: B is 2x2, A is 2x2. BA would be [[0*1 +1*1, 0*1 +1*1],[0*1 +1*1, 0*1 +1*1]] which is [[1,1],[1,1]], which has eigenvalues 2 and 0. AB was [[1,1],[0,0]], which has eigenvalues 0 and 1. Wait, that's different. Wait, so here AB has eigenvalues 0 and 1, BA has eigenvalues 0 and 2. So their non-zero eigenvalues differ. That contradicts the earlier idea. So in this case, AB and BA have different eigenvalues. Wait, so what's going on here?\n\nWait, in this example, A is [[0,1],[0,0]], B is [[1,1],[1,1]]. Then AB = A * B = [[0*1 +1*1, 0*1 +1*1],[0*1 +0*1, 0*1 +0*1]] = [[1,1],[0,0]]. The eigenvalues of AB are 0 and 1. Then BA is B * A = [[1*0 +1*0, 1*1 +1*0],[1*0 +1*0, 1*1 +1*0]] = [[0,1],[0,1]]. The eigenvalues of BA are 0 and 1. Wait, no, BA is [[0,1],[0,1]], which is a rank 1 matrix. Its trace is 0 +1=1, determinant is 0, so eigenvalues are 0 and 1. Wait, so AB and BA both have eigenvalues 0 and 1. Hmm, maybe my previous calculation was wrong.\n\nWait, let me check again. BA = [[1*0 +1*0, 1*1 +1*0], [1*0 +1*0, 1*1 +1*0]] = [[0,1], [0,1]]. Correct. So the trace is 1, determinant 0, so eigenvalues 0 and 1. So AB and BA have same eigenvalues. Then maybe my previous thought was wrong.\n\nWait, maybe another example. Let me try with A = [[0,1],[0,0]] and B = [[0,0],[1,0]]. Then AB = [[1,0],[0,0]], which has eigenvalues 1 and 0. BA = [[0,0],[0,1]], which has eigenvalues 0 and 1. So same eigenvalues. Hmm. Let me try another one where maybe they differ. Suppose A is [[1,0],[0,0]], B is [[0,1],[0,0]]. Then AB is [[0,1],[0,0]], eigenvalues 0. BA is [[0,0],[0,0]], eigenvalues 0. Same.\n\nWait, maybe I need a different example where AB and BA have different eigenvalues. Let me see. Take A as [[0,1,0],[0,0,1],[0,0,0]], B as some matrix. Hmm, maybe this is getting too complex. Alternatively, maybe it's always true that AB and BA have the same eigenvalues when A and B are square matrices. Because the characteristic polynomials are the same. Let me check that.\n\nFor square matrices A and B, the characteristic polynomial of AB and BA. Suppose A and B are n×n. Then, det(λI - AB) = det(λI - BA). Is this true? Let's test with λ=0. Then det(-AB) = (-1)^n det(AB) and det(-BA) = (-1)^n det(BA). But det(AB) = det(A)det(B) = det(BA). So for λ=0, it's the same. For general λ, is det(λI - AB) = det(λI - BA)? Wait, there's a theorem that says for square matrices, AB and BA have the same eigenvalues. But how?\n\nWait, if we consider the characteristic polynomial, det(λI - AB) = det(λI - BA). Let me see for 2x2 matrices. Let A = [[a,b],[c,d]], B = [[e,f],[g,h]]. Then AB and BA can be computed, and their characteristic polynomials calculated. Alternatively, maybe use the fact that trace(AB) = trace(BA), and det(AB) = det(BA). So if the trace and determinant are the same, then for 2x2 matrices, the characteristic polynomials are the same. So eigenvalues would be the same.\n\nIn general, trace(AB) = trace(BA), and more generally, the trace of any product is invariant under cyclic permutations. So for AB and BA, trace is same. Similarly, det(AB) = det(A)det(B) = det(B)det(A) = det(BA). For n×n matrices, the characteristic polynomial is determined by the traces of powers, determinants, etc. But maybe for AB and BA, all the coefficients of the characteristic polynomial are the same. Therefore, their eigenvalues (with algebraic multiplicities) are the same.\n\nTherefore, the answer is that yes, the eigenvalues of AB and BA are the same when A and B are square matrices of the same size. The user also asks under what conditions it's true. So if A and B are square matrices, then eigenvalues are the same. If they are rectangular, then it's not necessarily the case, but the question specifies both are N×N.\n\nSo in the problem, since A and B are both N×N matrices, the eigenvalues of AB and BA are equal. The assumption is that A and B are square matrices of the same size. The problem is to show that the eigenvalues of AB and BA are equal, or to determine under what conditions this holds.\n\nBut the original question mentions that they are not necessarily invertible, so the answer holds regardless of invertibility. Therefore, the problem structured would have the assumption that A and B are N×N matrices, with no invertibility required. The problem is to prove that the eigenvalues of AB are equal to those of BA, or to find conditions where this is true or not. But since in the square case, they are always equal, the answer would be that it's always true for square matrices, and if they are rectangular, then the non-zero eigenvalues are the same.\n\nBut the user's question specifically states that A and B are both N×N, so the answer would be that it's always true in that case. The example given in the original problem's assumption in the user's example was adding that n is divisible by 7, but here, the assumptions are that A and B are N×N matrices. So the formatted problem would have assumptions: A is an N×N matrix, B is an N×N matrix. Problem: Prove that the eigenvalues of AB are equal to the eigenvalues of BA.",
    "Original_Problem":"Assumption: \n$A$ is an $N \\times N$ matrix,\n$B$ is an $N \\times N$ matrix.\nProblem: \nProve that the eigenvalues of $AB$ are equal to the eigenvalues of $BA$.",
    "Proof_problem":"Yes",
    "Redundant_assumption":"$$\\lambda Bv=B(ABv)=(BA)Bv,$$",
    "Problem_with_redundant_assumption":"Assumption:\nAssumption 1: $A$ is an $N \\times N$ matrix,\nAssumption 2: $B$ is an $N \\times N$ matrix.\nAssumption 3: $$\\lambda Bv=B(ABv)=(BA)Bv,$$\nProblem: \nProve that the eigenvalues of $AB$ are equal to the eigenvalues of $BA$.",
    "Original_Problem_with_numerical_order_assumption":"Assumption:\nAssumption 1: $A$ is an $N \\times N$ matrix,\nAssumption 2: $B$ is an $N \\times N$ matrix.\nAssumption 3: $$\\lambda Bv=B(ABv)=(BA)Bv,$$\nProblem: \nProve that the eigenvalues of $AB$ are equal to the eigenvalues of $BA$.",
    "judge":"Answer to Q1: yes\nNew_problem:\nGiven A and B are N×N matrices, prove that the eigenvalues of AB are equal to the eigenvalues of BA.\nSolution_for_new_problem:\nProof: Let λ be an eigenvalue of AB with eigenvector v ≠ 0, so ABv = λv.\n\nCase 1: λ ≠ 0\nMultiply both sides by B: B(ABv) = B(λv) = λBv\nBut B(ABv) = (BA)Bv\nSo (BA)Bv = λBv\nIf Bv = 0, then ABv = A(0) = 0, implying λ = 0, contradicting λ ≠ 0. Thus Bv ≠ 0, so λ is an eigenvalue of BA with eigenvector Bv.\n\nCase 2: λ = 0\nIf 0 is an eigenvalue of AB, then AB is singular (det(AB) = 0). Since det(AB) = det(A)det(B) = det(BA), we have det(BA) = 0, so BA is also singular, meaning 0 is an eigenvalue of BA.\n\nThus every eigenvalue of AB is an eigenvalue of BA. By symmetry (swapping A and B), every eigenvalue of BA is an eigenvalue of AB. Therefore, AB and BA have the same eigenvalues.\n",
    "proof strategy planner":"Given A and B are N×N matrices, prove that the eigenvalues of AB are equal to the eigenvalues of BA.\nStep 1) Let λ be an eigenvalue of AB with eigenvector v ≠ 0, so ABv = λv.\nStep 2) Case 1: λ ≠ 0. Multiply both sides by B: B(ABv) = B(λv) = λBv.\nStep 3) Rearrange: B(ABv) = (BA)Bv, so (BA)Bv = λBv.\nStep 4) Show Bv ≠ 0: If Bv = 0, then ABv = A(0) = 0, implying λ = 0, contradicting λ ≠ 0.\nStep 5) Thus Bv ≠ 0, so λ is an eigenvalue of BA with eigenvector Bv.\nStep 6) Case 2: λ = 0. If 0 is eigenvalue of AB, then AB is singular, so det(AB) = 0.\nStep 7) Since det(AB) = det(A)det(B) = det(BA), we have det(BA) = 0, so BA is singular.\nStep 8) Therefore 0 is an eigenvalue of BA.\nStep 9) From Steps 1-8, every eigenvalue of AB is an eigenvalue of BA.\nStep 10) By symmetry (swap A and B), every eigenvalue of BA is an eigenvalue of AB.\nStep 11) Conclude: AB and BA have the same eigenvalues.",
    "mathematician and proof writer":"Given A and B are N×N matrices, prove that the eigenvalues of AB are equal to the eigenvalues of BA.\nLet A and B be N×N matrices over a field (typically ℝ or ℂ). We will prove that AB and BA have the same set of eigenvalues.\n\n**Part 1: Show that every eigenvalue of AB is an eigenvalue of BA.**\n\nLet λ be an eigenvalue of AB. Then there exists a nonzero vector v ∈ ℂ^N (or ℝ^N) such that:\n\n(1) ABv = λv\n\nWe consider two cases:\n\n**Case 1: λ ≠ 0**\n\nMultiply both sides of equation (1) by B:\n\nB(ABv) = B(λv)\n\nSince matrix multiplication is associative and scalar multiplication commutes, we have:\n\n(BA)(Bv) = λ(Bv)\n\nNow we need to show that Bv ≠ 0. Suppose, for contradiction, that Bv = 0. Then from equation (1):\n\nABv = A(0) = 0 = λv\n\nSince v ≠ 0, this implies λ = 0, which contradicts our assumption that λ ≠ 0. Therefore, Bv ≠ 0.\n\nThus, we have (BA)(Bv) = λ(Bv) with Bv ≠ 0, which means λ is an eigenvalue of BA with eigenvector Bv.\n\n**Case 2: λ = 0**\n\nIf 0 is an eigenvalue of AB, then AB is singular (not invertible). Therefore, det(AB) = 0.\n\nUsing the property of determinants for square matrices: det(AB) = det(A)det(B) = det(BA).\n\nThus, det(BA) = 0, which implies BA is also singular. A singular matrix has 0 as an eigenvalue. Therefore, 0 is an eigenvalue of BA.\n\nFrom Cases 1 and 2, we have shown that every eigenvalue λ of AB (whether zero or nonzero) is also an eigenvalue of BA.\n\n**Part 2: Show that every eigenvalue of BA is an eigenvalue of AB.**\n\nThis follows by symmetry. Interchanging the roles of A and B in Part 1, we can apply exactly the same argument to show that if μ is an eigenvalue of BA, then μ is also an eigenvalue of AB.\n\nMore formally: Let μ be an eigenvalue of BA. Then by the same reasoning as in Part 1 (with A and B swapped), μ is an eigenvalue of (BA) = (B)(A). But applying the argument with the roles reversed shows μ is an eigenvalue of AB.\n\n**Conclusion:**\n\nWe have shown:\n1. Every eigenvalue of AB is an eigenvalue of BA.\n2. Every eigenvalue of BA is an eigenvalue of AB.\n\nTherefore, the sets of eigenvalues of AB and BA are equal. That is, AB and BA have the same eigenvalues.\n\n**Additional Notes:**\n- The proof holds for matrices over any field where the determinant properties are valid.\n- The key insight is that for nonzero eigenvalues, if v is an eigenvector of AB with eigenvalue λ, then Bv is an eigenvector of BA with the same eigenvalue λ.\n- For the zero eigenvalue case, we use the determinant property det(AB) = det(BA) to show that if one matrix is singular, so is the other.\n- The symmetry argument completes the proof by showing the inclusion in both directions.",
    "final reviewer":"```json\n{\n  \"proof_review\": true,\n  \"end_of_proof\": \"final:\"\n}\n```\n**Problem:** Given that A and B are N×N matrices, prove that the eigenvalues of AB are the same as the eigenvalues of BA.\n\n**Proof:**\n\nLet A and B be N×N matrices. We will demonstrate that AB and BA share the same set of eigenvalues. The proof is divided into two parts.\n\n**Part 1: Every eigenvalue of AB is an eigenvalue of BA.**\n\nLet λ be an eigenvalue of AB. This means there exists a non-zero vector v such that:\n(1) ABv = λv\n\nWe consider two cases for the value of λ.\n\n**Case 1: λ ≠ 0**\n\nWe pre-multiply both sides of equation (1) by B:\nB(ABv) = B(λv)\n\nUsing the associative property of matrix multiplication and the fact that scalar multiplication commutes, we get:\n(BA)(Bv) = λ(Bv)\n\nTo show that λ is an eigenvalue of BA, we must verify that the vector Bv is non-zero. Let's assume, for the sake of contradiction, that Bv = 0.\nSubstituting Bv = 0 back into equation (1):\nA(Bv) = λv\nA(0) = λv\n0 = λv\n\nSince v is an eigenvector, it is non-zero (v ≠ 0). Therefore, for the equation 0 = λv to hold, λ must be 0. This contradicts our assumption in this case that λ ≠ 0. Thus, our assumption that Bv = 0 must be false.\n\nSince Bv is a non-zero vector, the equation (BA)(Bv) = λ(Bv) shows that λ is an eigenvalue of BA, with Bv as the corresponding eigenvector.\n\n**Case 2: λ = 0**\n\nIf λ = 0 is an eigenvalue of AB, it means that the matrix AB is singular (not invertible). A matrix is singular if and only if its determinant is zero.\ndet(AB) = 0\n\nUsing the property of determinants that det(XY) = det(X)det(Y) for any square matrices X and Y, we have:\ndet(A)det(B) = 0\n\nSince scalar multiplication is commutative, det(A)det(B) = det(B)det(A). This allows us to write:\ndet(BA) = 0\n\nA determinant of zero implies that the matrix BA is also singular. A singular matrix always has 0 as an eigenvalue. Therefore, 0 is an eigenvalue of BA.\n\nCombining both cases, we have shown that any eigenvalue of AB is also an eigenvalue of BA.\n\n**Part 2: Every eigenvalue of BA is an eigenvalue of AB.**\n\nThe argument is symmetric. By swapping the roles of A and B in the proof in Part 1, we can conclude that every eigenvalue of BA must also be an eigenvalue of AB.\n\n**Conclusion:**\n\nFrom Part 1, the set of eigenvalues of AB is a subset of the set of eigenvalues of BA. From Part 2, the set of eigenvalues of BA is a subset of the set of eigenvalues of AB. Therefore, the two sets of eigenvalues are identical. The matrices AB and BA have the same eigenvalues.\n\nfinal:\n**Problem:** Given that A and B are N×N matrices, prove that the eigenvalues of AB are the same as the eigenvalues of BA.\n\n**Proof:**\n\nLet A and B be N×N matrices. We will demonstrate that AB and BA share the same set of eigenvalues. The proof is divided into two parts.\n\n**Part 1: Every eigenvalue of AB is an eigenvalue of BA.**\n\nLet λ be an eigenvalue of AB. This means there exists a non-zero vector v such that:\n(1) ABv = λv\n\nWe consider two cases for the value of λ.\n\n**Case 1: λ ≠ 0**\n\nWe pre-multiply both sides of equation (1) by B:\nB(ABv) = B(λv)\n\nUsing the associative property of matrix multiplication and the fact that scalar multiplication commutes, we get:\n(BA)(Bv) = λ(Bv)\n\nTo show that λ is an eigenvalue of BA, we must verify that the vector Bv is non-zero. Let's assume, for the sake of contradiction, that Bv = 0.\nSubstituting Bv = 0 back into equation (1):\nA(Bv) = λv\nA(0) = λv\n0 = λv\n\nSince v is an eigenvector, it is non-zero (v ≠ 0). Therefore, for the equation 0 = λv to hold, λ must be 0. This contradicts our assumption in this case that λ ≠ 0. Thus, our assumption that Bv = 0 must be false.\n\nSince Bv is a non-zero vector, the equation (BA)(Bv) = λ(Bv) shows that λ is an eigenvalue of BA, with Bv as the corresponding eigenvector.\n\n**Case 2: λ = 0**\n\nIf λ = 0 is an eigenvalue of AB, it means that the matrix AB is singular (not invertible). A matrix is singular if and only if its determinant is zero.\ndet(AB) = 0\n\nUsing the property of determinants that det(XY) = det(X)det(Y) for any square matrices X and Y, we have:\ndet(A)det(B) = 0\n\nSince scalar multiplication is commutative, det(A)det(B) = det(B)det(A). This allows us to write:\ndet(BA) = 0\n\nA determinant of zero implies that the matrix BA is also singular. A singular matrix always has 0 as an eigenvalue. Therefore, 0 is an eigenvalue of BA.\n\nCombining both cases, we have shown that any eigenvalue of AB is also an eigenvalue of BA.\n\n**Part 2: Every eigenvalue of BA is an eigenvalue of AB.**\n\nThe argument is symmetric. By swapping the roles of A and B in the proof in Part 1, we can conclude that every eigenvalue of BA must also be an eigenvalue of AB.\n\n**Conclusion:**\n\nFrom Part 1, the set of eigenvalues of AB is a subset of the set of eigenvalues of BA. From Part 2, the set of eigenvalues of BA is a subset of the set of eigenvalues of AB. Therefore, the two sets of eigenvalues are identical. The matrices AB and BA have the same eigenvalues."
}