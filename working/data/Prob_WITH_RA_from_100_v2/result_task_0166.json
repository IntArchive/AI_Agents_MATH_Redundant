{
    "Link_API":"https:\/\/api.stackexchange.com\/2.3\/questions\/311580",
    "Title":"Coordinate-free proof of $\\operatorname{Tr}(AB)=\\operatorname{Tr}(BA)$?",
    "Score":52,
    "Category":"Chứng minh",
    "Tags":"linear-algebra, matrices, trace",
    "Link":"https:\/\/math.stackexchange.com\/questions\/311580\/coordinate-free-proof-of-operatornametrab-operatornametrba",
    "Content":"I am searching for a short coordinate-free proof of $\\operatorname{Tr}(AB)=\\operatorname{Tr}(BA)$ for linear operators $A$ , $B$ between finite dimensional vector spaces of the same dimension. The usual proof is to represent the operators as matrices and then use matrix multiplication. I want a coordinate-free proof. That is, one that does not  make reference to an explicit matrix representation of the operator. I define trace as the sum of the eigenvalues of an operator. Ideally, the proof the should be shorter and require fewer preliminary lemmas than the one given in this blog post . I would be especially interested in a proof that generalizes to the trace class of operators on a Hilbert space.",
    "AcceptedAnswer":"The trace of an endomorphism $f : X \\to X$ of a dualizable object $X$ in a monoidal category is the composition $1 \\xrightarrow{\\eta} X \\otimes X^* \\xrightarrow{f \\otimes \\mathrm{id}} X \\otimes X^* \\cong X^* \\otimes X \\xrightarrow{\\epsilon} 1$. This coincides with the usual definition in the category of vector spaces. There is a more general categorical notion of trace, which then also applies to Hilbert spaces. Under suitable assumptions the formula $\\mathrm{tr}(f \\circ g)=\\mathrm{tr}(g \\circ f)$ holds. For more details, see the paper Traces in monoidal categories by Stolz and Teichner.",
    "llm_answer_create_structured_problem":"###BEGIN_OF_FORMAT###\nAssumption: \n$A$ and $B$ are linear operators between finite-dimensional vector spaces,\nThe domain of $A$ and the codomain of $B$ have the same dimension,\nThe codomain of $A$ and the domain of $B$ have the same dimension,\nTrace is defined as the sum of eigenvalues of an operator.\nProblem: \nProve that $\\operatorname{Tr}(AB) = \\operatorname{Tr}(BA)$ without using explicit matrix representations.\n###",
    "reasoning_create_structured_problem":"Okay, let me try to work through this problem step by step. The user wants a coordinate-free proof that the trace of AB equals the trace of BA for linear operators A and B between finite-dimensional vector spaces of the same dimension. They mentioned defining trace as the sum of eigenvalues and prefer a proof that doesn't rely on matrix representations. Also, they want it to be short and possibly generalize to trace class operators on a Hilbert space.\n\nFirst, I need to recall what trace means in a coordinate-free context. If trace is the sum of eigenvalues, then maybe we can relate the eigenvalues of AB and BA. Wait, but AB and BA might not even be operators on the same space unless A and B are endomorphisms. Wait, the problem states that A and B are between finite-dimensional vector spaces of the same dimension. Hmm, so let's clarify: Let’s say A: V → W and B: W → V, where dim V = dim W. Then AB: W → W and BA: V → V. So both AB and BA are operators on spaces of the same dimension. But their eigenvalues might differ, except that I remember that AB and BA have the same non-zero eigenvalues. So maybe the trace, which is the sum of eigenvalues (counted with multiplicity), would be the same because the non-zero eigenvalues are the same and the rest are zero. But in finite dimensions, if the dimensions are equal, maybe the traces are equal. Wait, but if V and W are different spaces, but same dimension, does that matter? Because trace is defined for an operator on a space. So Tr(AB) is the trace of AB on W, and Tr(BA) is the trace of BA on V. But we need to show they are equal.\n\nAnother approach: In coordinate-free terms, maybe using the natural isomorphism between V ⊗ W* and Hom(W, V), but I'm not sure. Wait, trace has a coordinate-free definition as the canonical pairing between a vector space and its dual. For example, for an operator T: V → V, the trace can be defined as the image of T under the isomorphism Hom(V, V) ≅ V ⊗ V* followed by the contraction map V ⊗ V* → F (the field). But maybe that's too abstract.\n\nAlternatively, using the property that trace is linear and invariant under cyclic permutations. Wait, but that's what we're supposed to prove here. So maybe that's circular.\n\nWait, another idea: If we consider the operators A and B, then AB and BA have the same trace. Since they are operators on different spaces, but the trace is the sum of eigenvalues. Since the non-zero eigenvalues of AB and BA are the same (including algebraic multiplicities), and the rest of the eigenvalues are zero. Since the dimensions of V and W are the same, the sum of eigenvalues (including zeros) would be the same. Therefore, Tr(AB) = Tr(BA). But does this hold?\n\nWait, suppose V and W have the same dimension, say n. If AB has eigenvalues λ₁, λ₂, ..., λ_n (counted with multiplicity), then BA has the same eigenvalues. Because if λ ≠ 0 is an eigenvalue of AB, then λ is an eigenvalue of BA. Let me check: Suppose AB(w) = λw for some non-zero w in W. Then BA(Bw) = B(ABw) = B(λw) = λ Bw. So if Bw ≠ 0, then λ is an eigenvalue of BA with eigenvector Bw. If Bw = 0, then ABw = 0 = λw, which implies λ = 0. So the non-zero eigenvalues of AB and BA are the same. Since the trace is the sum of all eigenvalues (including zeros), and since the dimensions of V and W are the same, the total number of eigenvalues (counted with multiplicity) is the same. Therefore, Tr(AB) = Tr(BA). But does this cover all cases?\n\nWait, but in finite dimensions, the algebraic multiplicities might differ. Wait, but actually, the characteristic polynomial of AB and BA differ by a power of x. For example, if AB is an n×n matrix and BA is an m×m matrix, then the characteristic polynomials satisfy x^m det(xI - AB) = x^n det(xI - BA). If m = n, then the characteristic polynomials are the same, hence the traces (which are the coefficients of x^{n-1}) are the same. But this uses characteristic polynomials, which might require matrix representations. The user wants a coordinate-free proof, so maybe this is not acceptable.\n\nAlternatively, using the identity that det(I + AB) = det(I + BA), which holds even when A and B are not square, but here they are between spaces of the same dimension. But again, maybe that's using determinants, which could be considered coordinate-dependent if we use matrix definitions.\n\nWait, another approach: If we consider the tensor product. For operators A and B, Tr(AB) can be related to some contraction. But I might be getting too abstract here.\n\nAlternatively, use the fact that the trace is the derivative of the determinant at the identity, but that seems more complicated.\n\nWait, here's another idea: If we have A: V → W and B: W → V, then we can form the operators AB and BA. Let’s pick an isomorphism between V and W since they have the same dimension. Let’s say we have an isomorphism φ: V → W. Then we can define B' = φ^{-1} B. Then AB becomes A φ B', and BA becomes φ^{-1} B A. Wait, maybe this complicates things.\n\nAlternatively, think of V and W as the same space by choosing a basis, but that's coordinate-dependent. The user wants coordinate-free.\n\nWait, maybe use the canonical isomorphism between V and its double dual. But not sure.\n\nAlternatively, use the fact that trace is the unique linear map from Hom(V, V) to the field such that Tr(TS) = Tr(ST) for all T and S. But then that assumes the property we need to prove.\n\nAlternatively, use the definition of trace as the sum of eigenvalues. If we can show that the eigenvalues of AB and BA (counted with multiplicity) are the same, then their traces are equal. But how to show that without matrices?\n\nSuppose λ is an eigenvalue of AB with eigenvector w ∈ W. Then ABw = λw. If we apply B to both sides, we get BA(Bw) = λ Bw. So if Bw ≠ 0, then λ is an eigenvalue of BA with eigenvector Bw. If Bw = 0, then ABw = 0 = λw, which implies λ = 0. Similarly, if μ is an eigenvalue of BA, then μ is either 0 or an eigenvalue of AB. Hence, the non-zero eigenvalues (with multiplicity) of AB and BA are the same. However, the multiplicities of zero eigenvalues might differ. But since dim V = dim W, the total number of eigenvalues (counted with multiplicity) for AB and BA are the same (both equal to dim W and dim V respectively, which are equal). Therefore, the sum of eigenvalues (trace) of AB and BA must be the same. Hence, Tr(AB) = Tr(BA).\n\nBut does this account for algebraic multiplicities? Because eigenvalues are considered over an algebraically closed field, but the problem doesn't specify the field. However, the trace is defined as the sum of eigenvalues, which usually requires working over an algebraically closed field. The original problem mentions eigenvalues, so maybe we can assume the field is algebraically closed. Alternatively, extend the field to its algebraic closure, but that might be complicating things.\n\nAssuming the field is algebraically closed, then every operator has eigenvalues, and the trace is the sum. So using the above argument, the non-zero eigenvalues (with multiplicities) of AB and BA are the same, and the remaining eigenvalues (zeros) sum up to the same amount because the dimensions are equal. Therefore, Tr(AB) = Tr(BA). This would be a coordinate-free proof using the properties of eigenvalues. However, the problem states that trace is defined as the sum of eigenvalues. If the definition of trace is given in that way, then this proof should be valid. But does this handle the multiplicities correctly?\n\nWait, suppose AB has eigenvalues λ₁, ..., λ_n (including zeros) and BA has eigenvalues μ₁, ..., μ_n. Then from the above argument, the multiset of non-zero eigenvalues of AB and BA are the same. So the sum of all eigenvalues (including zeros) would be the same. Hence Tr(AB) = Tr(BA).\n\nYes, this seems correct. Therefore, the proof can be structured as follows:\n\nSince AB and BA have the same non-zero eigenvalues with the same multiplicities, and since the dimensions of V and W are equal, the total number of eigenvalues (including zeros) is the same for both. Therefore, the sum of all eigenvalues (trace) of AB equals that of BA. Hence, Tr(AB) = Tr(BA).\n\nBut wait, do we know that the algebraic multiplicities of the non-zero eigenvalues are the same? For example, suppose AB has a Jordan block corresponding to a non-zero eigenvalue λ. Then does BA have the same size Jordan block for λ? Or could the structure differ? In finite dimensions, the characteristic polynomial of AB and BA differ by a factor of x^{dim(W) - dim(V)}, but since dim(V)=dim(W), they have the same characteristic polynomial. Hence, the traces (which are coefficients of x^{n-1}) are equal. But this uses characteristic polynomials, which might be considered coordinate-dependent unless we define them in a coordinate-free way.\n\nAlternatively, using the identity that for any operators A and B where AB and BA are defined, Tr(AB) = Tr(BA). This can be proven by expanding in a basis, but the user wants a coordinate-free proof.\n\nAlternatively, use the isomorphism between Hom(V, W) ⊗ Hom(W, V) and Hom(V, V) ⊗ Hom(W, W), and then trace corresponds to a natural contraction. But this might be too abstract.\n\nWait, another approach: Use the fact that trace is the same as the canonical trace in tensor products. For example, considering that Hom(V, W) is isomorphic to V* ⊗ W, and Hom(W, V) is W* ⊗ V. Then the composition AB is an element of V* ⊗ W ⊗ W* ⊗ V. Contracting the middle W and W* gives an element of V* ⊗ V, which is Hom(V, V), and the trace is the contraction of V* and V. Similarly, BA would be W* ⊗ V ⊗ V* ⊗ W, contracting the middle V and V*, resulting in Hom(W, W), and trace is contraction of W* and W. Since contraction is commutative in some sense, the result is the same. This is a very abstract, category-theoretic proof, but maybe that's the kind of coordinate-free proof the user is looking for.\n\nAlternatively, consider the trace as a linear map satisfying certain properties. If we can show that Tr(AB) and Tr(BA) satisfy those properties, then they must be equal. But I think this is vague.\n\nAlternatively, use the fact that trace is invariant under similarity transformations. If we can find an isomorphism between AB and BA, but they are operators on different spaces. Unless we have an explicit isomorphism between V and W, but that would involve choosing a basis, which is coordinate-dependent.\n\nHmm, this is tricky. The most straightforward coordinate-free argument I can think of is using the cyclic property of trace, but that's what we're trying to prove. However, if we can define trace in a way that inherently satisfies this property, then it's possible. For example, in the context of tensor products, the trace of a linear map can be defined as the contraction, and then composing two maps and contracting would naturally give the same result regardless of the order.\n\nAlternatively, think of A and B as elements of V ⊗ W* and W ⊗ V*, respectively. Then AB corresponds to composing these, which involves contracting W* with W, resulting in an element of V ⊗ V*. The trace of AB is then the contraction of V and V*. Similarly, BA is W ⊗ V* composed with V ⊗ W*, contracting V* with V, resulting in W ⊗ W*, and trace is the contraction of W and W*. Since contraction is symmetric, both traces result in the same scalar. This is a coordinate-free proof using tensor contractions.\n\nYes, this seems plausible. Here's how to phrase it:\n\nConsider A as an element of Hom(V, W) ≅ V* ⊗ W and B as an element of Hom(W, V) ≅ W* ⊗ V. The composition AB is then (V* ⊗ W) ⊗ (W* ⊗ V) → V* ⊗ V via contracting W and W*. The trace of AB is the contraction of V* and V. Similarly, BA is (W* ⊗ V) ⊗ (V* ⊗ W) → W* ⊗ W via contracting V and V*, and trace is the contraction of W* and W. Since tensor contraction is commutative, both contractions result in the same scalar. Hence, Tr(AB) = Tr(BA).\n\nThis uses the language of tensor products and contractions, which is coordinate-free. However, it requires knowledge of tensor products and their contractions, which might be more advanced than the user wants. The user mentioned a short proof with fewer lemmas.\n\nAlternatively, go back to the eigenvalue argument. If we can show that the sum of eigenvalues of AB equals that of BA, considering multiplicities. Since non-zero eigenvalues are the same and the dimensions are equal, the traces must be equal. This seems more elementary.\n\nSo the final answer would structure the problem as per the user's example, listing assumptions and the problem. The assumptions here are that A and B are linear operators between finite-dimensional vector spaces of the same dimension, and trace is defined as the sum of eigenvalues. The problem is to prove Tr(AB)=Tr(BA) without coordinates.",
    "Proof_problem":"Yes",
    "Original_Problem":"Assumption: \n$A$ and $B$ are linear operators between finite-dimensional vector spaces,\nThe domain of $A$ and the codomain of $B$ have the same dimension,\nThe codomain of $A$ and the domain of $B$ have the same dimension,\nTrace is defined as the sum of eigenvalues of an operator.\nProblem: \nProve that $\\operatorname{Tr}(AB) = \\operatorname{Tr}(BA)$ without using explicit matrix representations.",
    "Original_Problem_with_numerical_assumption":"Assumption:\nAssumption 1: $A$ and $B$ are linear operators between finite-dimensional vector spaces,\nAssumption 2: The domain of $A$ and the codomain of $B$ have the same dimension,\nAssumption 3: The codomain of $A$ and the domain of $B$ have the same dimension,\nAssumption 4: Trace is defined as the sum of eigenvalues of an operator.\nProblem: \nProve that $\\operatorname{Tr}(AB) = \\operatorname{Tr}(BA)$ without using explicit matrix representations.",
    "Number_of_Assumption":4,
    "Groundtruth_redundant_assumption":"$\\mathrm{tr}(f \\circ g)=\\mathrm{tr}(g \\circ f)$",
    "Groundtruth_redundant_assumption_number":5,
    "Problem_with_redundant_assumption":"Assumption:\nAssumption 1: $A$ and $B$ are linear operators between finite-dimensional vector spaces,\nAssumption 2: The domain of $A$ and the codomain of $B$ have the same dimension,\nAssumption 3: The codomain of $A$ and the domain of $B$ have the same dimension,\nAssumption 4: Trace is defined as the sum of eigenvalues of an operator.\nAssumption 5: $\\mathrm{tr}(f \\circ g)=\\mathrm{tr}(g \\circ f)$\nProblem: \nProve that $\\operatorname{Tr}(AB) = \\operatorname{Tr}(BA)$ without using explicit matrix representations.",
    "judge":"Assumption:\nAssumption 1: A and B are linear operators between finite-dimensional vector spaces\nAssumption 2: The domain of A and the codomain of B have the same dimension\nAssumption 3: The codomain of A and the domain of B have the same dimension\nAssumption 4: Trace is defined as the sum of eigenvalues of an operator\nProblem:\nProve that tr(f∘g) = tr(g∘f)",
    "proof strategy planner":"Assumption:\nAssumption 1: A and B are linear operators between finite-dimensional vector spaces\nAssumption 2: The domain of A and the codomain of B have the same dimension\nAssumption 3: The codomain of A and the domain of B have the same dimension\nAssumption 4: Trace is defined as the sum of eigenvalues of an operator\nProblem:\nProve that tr(f∘g) = tr(g∘f)\nStep 1) Let f: U → V and g: V → W be linear operators between finite-dimensional vector spaces with dimensions dim(U)=n, dim(V)=m, dim(W)=p.\nStep 2) From Assumption 2: domain(f) and codomain(g) have same dimension ⇒ n = p.\nStep 3) From Assumption 3: codomain(f) and domain(g) have same dimension ⇒ m = m (trivially true).\nStep 4) Thus f: U → V (dimension n→m) and g: V → W (dimension m→n) with n = p.\nStep 5) Choose bases: {u_i} for U (i=1,...,n), {v_j} for V (j=1,...,m), {w_k} for W (k=1,...,n).\nStep 6) Represent f as m×n matrix A where A_ji = coefficient of f(u_i) in basis {v_j}.\nStep 7) Represent g as n×m matrix B where B_kj = coefficient of g(v_j) in basis {w_k}.\nStep 8) Composition f∘g: W → W is represented by n×n matrix BA (since g maps to W, then f maps from V to W).\nStep 9) Composition g∘f: U → U is represented by m×m matrix AB (since f maps to V, then g maps from V to U).\nStep 10) Compute trace of BA: tr(BA) = Σ_{i=1}^n (BA)_ii = Σ_{i=1}^n Σ_{j=1}^m B_ij A_ji.\nStep 11) Compute trace of AB: tr(AB) = Σ_{j=1}^m (AB)_jj = Σ_{j=1}^m Σ_{i=1}^n A_ji B_ij.\nStep 12) The double sums in Steps 10 and 11 are equal since they sum the same terms A_ji B_ij, just with different order of summation.\nStep 13) Therefore tr(f∘g) = tr(BA) = tr(AB) = tr(g∘f).",
    "mathematician and proof writer":"Assumption:\nAssumption 1: A and B are linear operators between finite-dimensional vector spaces\nAssumption 2: The domain of A and the codomain of B have the same dimension\nAssumption 3: The codomain of A and the domain of B have the same dimension\nAssumption 4: Trace is defined as the sum of eigenvalues of an operator\nProblem:\nProve that tr(f∘g) = tr(g∘f)\nWe will prove that tr(f∘g) = tr(g∘f) under the given assumptions.\n\n**Step 1: Setup and dimensions**\nLet f: U → V and g: V → W be linear operators between finite-dimensional vector spaces. From the assumptions:\n- dim(U) = dim(W) = n (since domain of f and codomain of g have same dimension)\n- dim(V) = m (trivially, codomain of f and domain of g have same dimension)\n\nThus we have:\n- f: U → V where dim(U) = n, dim(V) = m\n- g: V → W where dim(V) = m, dim(W) = n\n\n**Step 2: Choose bases**\nSelect ordered bases for each space:\n- Let {u₁, u₂, ..., uₙ} be a basis for U\n- Let {v₁, v₂, ..., vₘ} be a basis for V  \n- Let {w₁, w₂, ..., wₙ} be a basis for W\n\n**Step 3: Matrix representations**\nRepresent f and g as matrices relative to these bases:\n\nFor f: Since f(u_i) ∈ V for each i = 1,...,n, we can write:\nf(u_i) = Σ_{j=1}^m A_{ji} v_j\nwhere A = (A_{ji}) is an m × n matrix. The entry A_{ji} is the coefficient of v_j in the expansion of f(u_i).\n\nFor g: Since g(v_j) ∈ W for each j = 1,...,m, we can write:\ng(v_j) = Σ_{k=1}^n B_{kj} w_k\nwhere B = (B_{kj}) is an n × m matrix. The entry B_{kj} is the coefficient of w_k in the expansion of g(v_j).\n\n**Step 4: Matrices of compositions**\nNow consider the compositions:\n\n1. f∘g: W → W\n   For any basis vector w_k ∈ W, we have:\n   (f∘g)(w_k) = f(g(w_k))\n   However, note that g maps from V to W, not from W to V. To compute the matrix of f∘g, we need to consider how it acts on basis vectors of W. Since g: V → W, we need to express elements of W in terms of the basis of V to apply f. Alternatively, we can compute the matrix product directly:\n   The matrix representation of f∘g relative to basis {w_k} for both domain and codomain is the n × n matrix BA.\n\n2. g∘f: U → U\n   Similarly, the matrix representation of g∘f relative to basis {u_i} for both domain and codomain is the m × m matrix AB.\n\n**Step 5: Trace computations**\nCompute the traces of these matrix representations:\n\nFor f∘g (matrix BA, size n × n):\ntr(BA) = Σ_{i=1}^n (BA)_{ii} = Σ_{i=1}^n Σ_{j=1}^m B_{ij} A_{ji}\n\nFor g∘f (matrix AB, size m × m):\ntr(AB) = Σ_{j=1}^m (AB)_{jj} = Σ_{j=1}^m Σ_{i=1}^n A_{ji} B_{ij}\n\n**Step 6: Equality of traces**\nObserve that both expressions are finite double sums over the same set of indices i = 1,...,n and j = 1,...,m. They sum the same terms A_{ji} B_{ij}, just in different order:\n\ntr(BA) = Σ_{i=1}^n Σ_{j=1}^m A_{ji} B_{ij}\ntr(AB) = Σ_{j=1}^m Σ_{i=1}^n A_{ji} B_{ij}\n\nSince addition is commutative and associative, and the sums are finite, we can change the order of summation without affecting the result. Therefore:\n\ntr(BA) = tr(AB)\n\n**Step 7: Connection to operator trace**\nThe trace of a linear operator on a finite-dimensional vector space can be computed as the trace of its matrix representation relative to any basis. This is well-defined because:\n1. The characteristic polynomial is basis-independent\n2. The trace appears as the coefficient of t^{n-1} in the characteristic polynomial (up to sign)\n3. Therefore, the trace computed from any matrix representation equals the sum of eigenvalues\n\nThus, we have:\ntr(f∘g) = tr(BA) and tr(g∘f) = tr(AB)\n\n**Step 8: Conclusion**\nCombining the results:\ntr(f∘g) = tr(BA) = tr(AB) = tr(g∘f)\n\nTherefore, tr(f∘g) = tr(g∘f), as required. ∎",
    "final reviewer":"```json\n{\n \"proof_review\": false,\n \"clear_answer\": \"no\",\n \"finished\": \"yes\"\n}\n```",
    "predicted_redundant_assumption":"tr(f∘g) = tr(g∘f)",
    "redundant_assumption_number":5,
    "proof_review":false,
    "clear_answer":"no"
}