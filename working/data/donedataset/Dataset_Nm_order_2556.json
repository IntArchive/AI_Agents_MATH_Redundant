{
    "Link_API": "https://api.stackexchange.com/2.3/questions/1280804",
    "Title": "Solutions of autonomous ODEs are monotonic",
    "Score": 13,
    "Category": "Chứng minh",
    "Tags": "calculus, real-analysis, analysis, ordinary-differential-equations",
    "Link": "https://math.stackexchange.com/questions/1280804/solutions-of-autonomous-odes-are-monotonic",
    "Content": "Problem. Let $I,J$ be open intervals, $\\,f:I\\to \\mathbb R$, continuous, $\\,\\varphi :J\\to \\mathbb R$,  continuously differentiable, with $\\varphi[J]\\subset I$, and $\\varphi$ satisfying\n$$\n\\varphi'(t)=f\\big(\\varphi(t)\\big),  \\quad \\text{for all $t\\in J$}.\n$$\nShow that $\\varphi$ is monotonic. This becomes rather straight-forward if we further assume the $f$ is continuously differentiable, or even locally Lipschitz continuous, as this implies that IVP for $x'=f(x)$ enjoy uniqueness, and hence if $f\\big(\\varphi(t_0)\\big)=0$, for some $t_0\\in J$, then $\\varphi$ is constant. In fact something stronger holds in such case: $\\varphi$ is either strictly monotonic or constant. This problem is also straight-forward if $f(x)\\ne 0$, for all $x\\in I$, in which case uniqueness kicks in anew. The hard part is to show monotonicity of $\\varphi$ when $f$ is just continuous, and its values include zero.",
    "AcceptedAnswer": "We shall prove the Proposition: Let $J \\subset \\mathbb{R}$ an interval, and $g\\colon J \\to \\mathbb{R}$ a differentiable function. If $g$ is not monotonic, then there are $u,v\\in J$ with $g(u) = g(v)$ and $g'(u) \\neq g'(v)$. It follows that all solutions of autonomous (first order) ODEs - regardless of the regularity of $f$, not even continuity is required - are monotonic, since for such functions the derivative is a function of the value. Proof: Since $g$ is not monotonic, there are $a,b \\in J$ with $g'(a) > 0$ and $g'(b) < 0$. Without loss of generality, we may assume that $a < b$. Pick a $c\\in [a,b]$ such that $$g(c) = \\max \\{ g(t) : t \\in [a,b]\\}.$$ We have $c \\in (a,b)$ and $g(c) > \\max \\{g(a),g(b)\\}$ since $g'(a) > 0$ and $g'(b) < 0$. If $g(b) \\leqslant g(a)$, let $M = \\{t\\in (c,b] : g(t) = g(a)\\}$. By the intermediate value theorem, $M\\neq \\varnothing$, and we can choose $u = a,\\,v = \\min M > c$. Since $g(t) > g(a)$ for $t\\in [c,v)$ by the intermediate value theorem, it follows that $g'(v) \\leqslant 0 < g'(u)$. If $g(b) > g(a)$, we choose $u = \\max \\{ t\\in [a,c) : g(t) = g(b)\\}$ and $v = b$ and by the same reasoning find $g'(u) \\geqslant 0 > g'(v)$.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$I$ and $J$ are open intervals,\n$f: I \\to \\mathbb{R}$ is continuous,\n$\\varphi: J \\to \\mathbb{R}$ is continuously differentiable,\n$\\varphi[J] \\subset I$,\n$\\varphi'(t) = f(\\varphi(t))$ for all $t \\in J$.\nproblem:\nShow that $\\varphi$ is monotonic.\n###",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem step by step. So, the task is to show that a solution φ to the autonomous ODE φ'(t) = f(φ(t)) is monotonic, given that f is continuous and φ is continuously differentiable with its image contained in the domain of f. The challenge here is that f isn't necessarily Lipschitz or differentiable, so uniqueness of solutions isn't guaranteed. But even without uniqueness, we need to prove that φ must be monotonic.\n\nFirst, let me recall what it means for a function to be monotonic. A function is monotonic if it is entirely non-increasing or non-decreasing. So, we need to show that φ doesn't change its direction of increase or decrease. If φ had a local maximum or minimum, that would imply a change in monotonicity, right? So, perhaps the key is to show that such critical points can't exist unless the function is constant.\n\nGiven that φ is a solution to the ODE, its derivative at any point t is f(φ(t)). Now, if f(φ(t)) is positive at some point, then φ is increasing there, and if it's negative, φ is decreasing. If f(φ(t)) = 0, then the derivative is zero, which could be a critical point.\n\nBut since f is continuous, the set of points where f is zero is closed. Suppose φ(t) enters a region where f is zero. If f is zero over an interval, then φ would be constant there. However, without uniqueness, could φ behave differently? Wait, but even without uniqueness, once φ(t) is in a region where f is zero, then φ'(t) = 0, so φ must be constant on that interval. Because if the derivative is zero, integrating gives a constant function. So, if φ ever reaches a point where f(φ(t)) = 0, then φ must stay constant from that point onward as long as it's in that region.\n\nBut the problem allows f to have zeros. So, φ could be constant on some intervals and increasing/decreasing on others. However, the problem states that φ must be monotonic overall. So even if φ has intervals where it's constant, as long as it doesn't switch from increasing to decreasing or vice versa, it's still considered monotonic.\n\nWait, but how can φ switch? Suppose φ starts increasing, then hits a point where f becomes zero, stays constant for a while, and then starts increasing again. That's still non-decreasing. Similarly, if it decreases, becomes constant, then decreases again. But if φ were to increase, then decrease, that would violate monotonicity. So the key is to prevent φ from having both increasing and decreasing intervals.\n\nSuppose for contradiction that φ is not monotonic. Then there exist points t1 < t2 < t3 in J such that φ(t1) < φ(t2) and φ(t2) > φ(t3), making it non-monotonic. Alternatively, φ(t1) > φ(t2) and φ(t2) < φ(t3). Either way, there's a local maximum or minimum.\n\nBut if there's a local maximum at t2, then φ'(t2) = f(φ(t2)) = 0. Now, since f is continuous, near φ(t2), f might be positive or negative. But if φ is at a local maximum, then just to the left of t2, φ is increasing (derivative positive), and just to the right, decreasing (derivative negative). But if f(φ(t)) is zero at t2, then near t2, f(φ(t)) would have to change sign from positive to negative. However, if f is continuous, then if f(φ(t2)) = 0, but near φ(t2), f could be positive on one side and negative on the other. But wait, φ(t) approaches φ(t2) from the left and right. So if φ is at a maximum, then to the left, φ(t) is approaching φ(t2) from below, so φ(t) < φ(t2) near t2-. Then f(φ(t)) would need to be positive there, since φ is increasing. Similarly, to the right, φ(t) > φ(t2) near t2+, but since it's a maximum, φ is decreasing there, so f(φ(t)) must be negative. Therefore, f would have to change sign from positive to negative as φ(t) passes through φ(t2). But since f is continuous, that would mean f(φ(t2)) = 0, but in any neighborhood around φ(t2), there are points where f is positive and negative.\n\nBut if f doesn't change sign, then φ can't have such a local maximum. Wait, but the problem allows f to have zeros. The issue is whether φ can turn around. However, without uniqueness, could there be a solution that turns around at a zero of f? Normally, with uniqueness, if you have f(y0)=0, then the only solutions are the constant solution y(t)=y0 or solutions that approach y0 but don't cross it. But without uniqueness, maybe there are solutions that can reverse direction?\n\nWait, but here φ is a specific solution. Suppose φ has a local maximum at t2. Then, as t approaches t2 from the left, φ(t) approaches φ(t2) from below, and since φ'(t) = f(φ(t)), which is approaching f(φ(t2))=0. If f is positive just below φ(t2), then φ is increasing there. After t2, if f is negative just above φ(t2), then φ starts decreasing. But if f is continuous, then near φ(t2), f(x) must go from positive to negative as x passes through φ(t2). But if f does not change sign, then this can't happen. Wait, but if f is continuous and changes sign at φ(t2), then that's possible. But the problem states that f is just continuous, so it could have such zeros where it changes sign.\n\nBut the problem says to show that φ is monotonic. So even if f changes sign, φ cannot oscillate because once φ reaches a zero of f where f changes sign, it would have to stop or something. Wait, maybe the key is that if f(φ(t)) changes sign, then φ cannot cross that point. Wait, but how? For example, suppose f(y) = y, which is continuous. The solutions to y' = y are exponentials, which are monotonic. If f(y) = -y^3, similar. But if f(y) has a zero where it changes sign, like f(y) = y^2 - 1, then at y=1 and y=-1, f(y)=0. The solutions might approach these points asymptotically. But if you have a solution that reaches y=1 in finite time, can it reverse? Wait, but with f(y) = y^2 -1, the ODE is y' = y^2 -1. The solutions tend to -1 from above and below, and diverge from 1. Wait, actually, if you start between -1 and 1, the solution tends to -1. If you start above 1, it goes to infinity. But in any case, each solution is monotonic. Even though f has zeros where it changes sign, the solutions don't turn around. So maybe the key is that even if f changes sign, the solution can't reverse direction because that would require the derivative to change sign, but once you reach a zero of f, the solution either stays there or leaves. But without uniqueness, could there be a solution that stays at the zero for a while and then leaves? Wait, suppose f is zero at some point y0, but non-zero elsewhere. If a solution reaches y0, it can stay there (since y'=0) or maybe branch off. But if there's a solution that stays at y0 for an interval and then starts increasing or decreasing, that would make the solution non-monotonic. But is that possible without uniqueness?\n\nWait, let's think of an example. Let f(y) be continuous, say f(y) = 0 for y ≤ 0 and f(y) = sqrt(y) for y > 0. So f is continuous everywhere. Now, consider the ODE y' = f(y). Suppose we have a solution that starts at y(0) = -1. Then since f(y) = 0 for y ≤ 0, the solution is y(t) = -1 for all t. But suppose we have a solution that starts at y(0) = 1. Then y'(t) = sqrt(y(t)), which would lead to y(t) increasing. But what about a solution that starts at y(0) = 0. If we don't have uniqueness, could there be a solution that stays at 0 for some time and then starts increasing? Yes, for example, the function y(t) = 0 for t ≤ c and y(t) = ( (t - c)/2 )^2 for t > c. This would be a solution, right? Because for t ≤ c, y' = 0 = f(0), and for t > c, y' = (t - c)/2 = sqrt( ((t - c)/2)^2 ) = sqrt(y(t)). Wait, but sqrt(y(t)) is (t - c)/2, but y'(t) is also (t - c)/2. So yes, this works. So this solution stays at 0 until t = c and then starts increasing. This function is non-decreasing, so it's monotonic. Even though it has a flat part and then increases, it's still monotonic. So even if the solution has intervals where it's constant and intervals where it's increasing, it's still considered monotonic.\n\nSimilarly, if you have a solution that decreases, becomes constant, then decreases again, that's still non-increasing. So the problem is to show that φ cannot both increase and decrease at different points. So even if there are intervals where it's constant, as long as it doesn't switch from increasing to decreasing, it's okay.\n\nSo the key is to show that φ cannot have both an interval where it's increasing and another where it's decreasing. Suppose for contradiction that there are points t1 < t2 < t3 such that φ(t1) < φ(t2) and φ(t2) > φ(t3). Then by the Intermediate Value Theorem, φ must attain a maximum at some point between t1 and t3. Let's say it's at τ in (t1, t3). Then φ'(τ) = f(φ(τ)) = 0. Now, near τ, since φ was increasing before τ and decreasing after, f(φ(t)) must be positive before τ and negative after. But φ(t) approaches φ(τ) from below before τ and from above after τ. Therefore, f must be positive for x slightly less than φ(τ) and negative for x slightly greater than φ(τ). However, f is continuous, so this would imply that f(φ(τ)) = 0, which it does. But then, consider the behavior of φ(t) near τ. Before τ, φ(t) is increasing towards φ(τ), so f(φ(t)) is positive. After τ, φ(t) is decreasing, so f(φ(t)) is negative. But this requires that f changes sign at φ(τ). However, even though f changes sign, can φ(t) actually turn around?\n\nWait, but if f changes sign at φ(τ), then solutions approaching φ(τ) from below would have positive derivative and go towards φ(τ), and solutions approaching from above would have negative derivative and go towards φ(τ). But if φ(t) reaches φ(τ) at τ, then what happens after τ? If φ(t) starts decreasing, it moves into the region where f(x) is negative, so it continues decreasing. But in this case, the solution has a maximum at τ and then decreases. So this would mean the solution is first increasing, then decreasing. But the problem states that such a solution must be monotonic. But in this example, the solution isn't monotonic. So there's a contradiction. Therefore, such a situation cannot occur, implying that our assumption that φ is not monotonic is false.\n\nBut wait, this seems like a proof by contradiction, assuming that φ is not monotonic, leading to the existence of a maximum or minimum, then analyzing the behavior around that point. However, how does the continuity of f ensure that this cannot happen? Or maybe the point is that if f changes sign, then solutions can't cross from increasing to decreasing because that would require passing through a point where f is zero, but once you reach that point, the solution could stay there. However, if the solution leaves that point, it would have to go against the sign of f.\n\nAlternatively, consider that if φ has a local maximum at τ, then φ'(τ) = 0. For t < τ near τ, φ'(t) = f(φ(t)) > 0, so φ(t) is increasing, so φ(t) < φ(τ), hence f(φ(t)) > 0. For t > τ near τ, φ'(t) = f(φ(t)) < 0, so φ(t) > φ(τ), hence f(φ(t)) < 0. But this implies that f(x) > 0 for x < φ(τ) near φ(τ), and f(x) < 0 for x > φ(τ) near φ(τ). Thus, f changes sign at φ(τ). However, even with this, the solution φ(t) reaches φ(τ) and then turns around. But the problem is that if there's no uniqueness, could there be another solution that doesn't turn around? But φ is a given solution. If φ is constructed in such a way, then it would have to follow this behavior. But the problem states to show that any such solution φ is monotonic. So even if f changes sign, the solution can't have both increasing and decreasing parts. Wait, but in my previous example with f(y) = y^2 - 1, solutions are monotonic. Even though f changes sign at y=1 and y=-1, the solutions approach these points asymptotically but don't cross them. But in the case where f changes sign and a solution reaches the equilibrium point in finite time, like in the example with f(y) = sqrt(y) for y > 0 and 0 otherwise, the solution can stay at 0 for a while and then increase, but it's still non-decreasing, hence monotonic.\n\nAh, I see. The issue is not that the solution can't have a maximum or minimum, but that if it did, it would have to stay constant after that point. Wait, no. For example, if φ has a maximum at τ, then after τ, it starts decreasing. But this would require that f changes sign from positive to negative at φ(τ). However, once φ starts decreasing, it moves into the region where f(x) is negative, so it continues decreasing. But this would mean the solution is first increasing, then decreasing, hence not monotonic. But the problem states that this cannot happen, so such solutions don't exist. Therefore, the key is to show that such a scenario leads to a contradiction.\n\nAlternatively, maybe we can use the fact that autonomous ODEs have solutions that are either constant or strictly monotonic. But how to formalize this without uniqueness?\n\nAnother approach: suppose that φ is not monotonic. Then there exist t1 < t2 in J such that φ'(t1) > 0 and φ'(t2) < 0 (or vice versa). By the Intermediate Value Theorem for derivatives (since φ' is continuous, as f is continuous and φ is C^1), φ' must take every value between φ'(t1) and φ'(t2). Hence, there exists some τ between t1 and t2 where φ'(τ) = 0. So f(φ(τ)) = 0. Now, consider the behavior of φ around τ. Since φ'(t1) > 0 and φ'(τ) = 0, there must be a point where φ starts decreasing. But how does this happen? If f(φ(t)) > 0 before τ and f(φ(t)) < 0 after τ, then φ must pass through a zero of f. But once φ(t) reaches that zero, if f is zero there, then φ'(t) becomes zero. However, if f changes sign there, can φ(t) cross from positive to negative? In the case of uniqueness, no, because solutions cannot cross. But without uniqueness, can they?\n\nWait, even without uniqueness, suppose φ(t) reaches a point where f(φ(τ)) = 0. Then, according to the ODE, φ'(τ) = 0. If f is zero at that point, but changes sign in any neighborhood around it, then near τ, φ(t) could be either increasing or decreasing. But if φ is decreasing after τ, that would require f(φ(t)) < 0 for t > τ near τ, which means φ(t) > φ(τ), so x > φ(τ) implies f(x) < 0. Similarly, before τ, φ(t) < φ(τ), so f(x) > 0 for x < φ(τ). Thus, f must change sign at φ(τ). However, even with this, the solution φ could have a maximum at τ and then decrease. But this contradicts the conclusion that φ must be monotonic. Therefore, the assumption that φ is not monotonic must be false.\n\nBut how do we formalize this? Maybe by considering the set where f(φ(t)) > 0, f(φ(t)) < 0, and f(φ(t)) = 0. If φ is not monotonic, then there are points where f(φ(t)) changes sign, leading to a contradiction. Alternatively, we can use the fact that autonomous ODEs have solutions that are either non-increasing or non-decreasing because the sign of the derivative depends only on the current value of φ(t), not on t directly.\n\nSuppose φ is not monotonic. Then there exist t1 < t2 < t3 such that φ(t1) < φ(t2) and φ(t2) > φ(t3). By the Mean Value Theorem, there exists a point between t1 and t2 where the derivative is positive, and between t2 and t3 where the derivative is negative. Hence, there's a point where f(φ(t)) changes from positive to negative. Let τ be the infimum of all t > t2 where f(φ(t)) < 0. Then at τ, f(φ(τ)) = 0 by continuity. Now, consider the behavior near τ. For t < τ near τ, φ(t) < φ(τ) (since φ is decreasing after τ), so f(φ(t)) must be positive, but approaching zero. For t > τ near τ, φ(t) < φ(τ) (since φ is decreasing), but φ(t) would be moving away from φ(τ), so f(φ(t)) remains negative. Wait, this seems a bit confusing.\n\nAlternatively, consider that since f is continuous, the function f(φ(t)) is continuous. If φ is not monotonic, then f(φ(t)) must change sign. But if f(φ(t)) changes sign, say from positive to negative, then there exists a τ where f(φ(τ)) = 0. But at that point, φ'(τ) = 0. Now, the key insight is that once the solution reaches a point where f(x) = 0, it cannot move past it unless f(x) is non-zero on one side. However, if f changes sign at x = φ(τ), then for x slightly less than φ(τ), f(x) > 0, and for x slightly greater, f(x) < 0. But φ(t) at τ is equal to φ(τ). For t > τ, φ(t) would have to decrease, moving into the region where x < φ(τ), where f(x) > 0, causing φ'(t) to become positive again. But this creates a contradiction because if φ(t) decreases below φ(τ), then f(φ(t)) becomes positive, making φ increase back towards φ(τ). This oscillation would require φ to alternate between increasing and decreasing, but since f is continuous, this would imply infinitely many sign changes of f around φ(τ), which isn't possible unless f is zero in a neighborhood. Wait, but if f is zero only at φ(τ) and changes sign there, then near φ(τ), f is positive on one side and negative on the other. If φ(t) approaches φ(τ) from below, it would keep increasing towards φ(τ) but can't exceed it because f becomes negative beyond φ(τ). However, without uniqueness, could φ(t) reach φ(τ) and then stay there? If φ(t) reaches φ(τ) at t = τ, then for t ≥ τ, φ(t) could stay at φ(τ), since φ'(t) = 0. But in this case, the solution would be constant after τ, hence non-decreasing (if it was increasing before and constant after). But the problem allows for solutions to be constant on intervals, so this is still monotonic.\n\nWait, but in the scenario where φ has a local maximum, then after τ, it would have to decrease, but if decreasing leads to values where f(x) > 0, which would make φ increase again. This would create a contradiction unless f(x) is zero in that region. Therefore, the only way for φ to decrease after τ is if f(x) ≤ 0 for x < φ(τ). But if f(x) is positive just below φ(τ), then φ cannot decrease past τ. Hence, such a local maximum cannot exist unless f(x) is zero in a neighborhood below φ(τ), which would force φ to stay constant.\n\nThis is getting a bit convoluted. Maybe there's a simpler way. Let's think about the function φ and its derivative. Since φ'(t) = f(φ(t)), the sign of φ' depends only on the value of φ(t). Suppose there exists a time t0 where φ'(t0) > 0. Then φ(t) is increasing at t0. Now, if φ ever starts decreasing, there must be a time t1 > t0 where φ'(t1) < 0. But φ(t1) would have to be less than φ(t0) (since it's decreasing after t1), which means φ(t1) = φ(t0) + ∫_{t0}^{t1} f(φ(s)) ds. Wait, but if φ is increasing up to some point and then decreasing, there must be a local maximum in between. At that maximum, say at τ, φ'(τ) = 0. Now, for t just below τ, φ'(t) > 0, so f(φ(t)) > 0. For t just above τ, φ'(t) < 0, so f(φ(t)) < 0. This implies that f(x) changes sign from positive to negative as x increases through φ(τ). But if f is continuous, then f(φ(τ)) = 0. Now, consider the solution φ(t) near τ. For t > τ, φ(t) starts decreasing, so φ(t) < φ(τ). But then, φ(t) enters a region where x < φ(τ), where f(x) > 0 (since f changes sign from positive to negative at φ(τ)). Therefore, once φ(t) < φ(τ), f(φ(t)) becomes positive again, making φ'(t) > 0, so φ starts increasing back towards φ(τ). This creates a contradiction because φ would oscillate around φ(τ), which isn't possible unless f is zero in a neighborhood of φ(τ). Therefore, the only way this doesn't lead to a contradiction is if f(x) = 0 for all x near φ(τ), meaning φ(t) must stay constant once it reaches φ(τ).\n\nTherefore, if φ has a local maximum at τ, then f(x) = 0 for all x in some neighborhood around φ(τ), which implies that φ(t) is constant on an interval around τ. Hence, φ cannot have a true local maximum where it increases and then decreases; instead, if it reaches a point where f(x)=0, it must remain constant thereafter. Therefore, φ is either strictly monotonic or constant on each interval where f(φ(t)) ≠ 0, and constant on intervals where f(φ(t)) = 0. In either case, φ as a whole is monotonic.\n\nTo formalize this, assume that φ is not monotonic. Then there exist t1 < t2 < t3 such that φ(t1) < φ(t2) and φ(t2) > φ(t3). By the Intermediate Value Theorem, there exists a τ ∈ (t1, t3) where φ attains a local maximum. At τ, φ'(τ) = f(φ(τ)) = 0. For t slightly less than τ, φ(t) < φ(τ) and φ'(t) > 0, so f(φ(t)) > 0. For t slightly greater than τ, φ(t) < φ(τ) (since it's a local maximum), and φ'(t) < 0, so f(φ(t)) < 0. But φ(t) < φ(τ) for t > τ near τ implies that f(φ(t)) must be positive (since f(x) > 0 for x < φ(τ) near φ(τ)), contradicting φ'(t) < 0. Hence, the assumption that φ is not monotonic leads to a contradiction. Therefore, φ must be monotonic.\n\nThis completes the proof.",
    "Original_Problem": "Assumption: \n$I$ and $J$ are open intervals,\n$f: I \\to \\mathbb{R}$ is continuous,\n$\\varphi: J \\to \\mathbb{R}$ is continuously differentiable,\n$\\varphi[J] \\subset I$,\n$\\varphi'(t) = f(\\varphi(t))$ for all $t \\in J$.\nproblem:\nShow that $\\varphi$ is monotonic.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $I$ and $J$ are open intervals,\nAssumption 2: $f: I \\to \\mathbb{R}$ is continuous,\nAssumption 3: $\\varphi: J \\to \\mathbb{R}$ is continuously differentiable,\nAssumption 4: $\\varphi[J] \\subset I$,\nAssumption 5: $\\varphi'(t) = f(\\varphi(t))$ for all $t \\in J$.\nProblem:\nShow that $\\varphi$ is monotonic.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$g(c) = \\max \\{ g(t) : t \\in [a,b]\\}.$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $I$ and $J$ are open intervals,\nAssumption 2: $f: I \\to \\mathbb{R}$ is continuous,\nAssumption 3: $\\varphi: J \\to \\mathbb{R}$ is continuously differentiable,\nAssumption 4: $\\varphi[J] \\subset I$,\nAssumption 5: $\\varphi'(t) = f(\\varphi(t))$ for all $t \\in J$.\nAssumption 6: $$g(c) = \\max \\{ g(t) : t \\in [a,b]\\}.$$\nProblem:\nShow that $\\varphi$ is monotonic."
}