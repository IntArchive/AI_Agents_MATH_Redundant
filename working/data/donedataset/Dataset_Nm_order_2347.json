{
    "Link_API": "https://api.stackexchange.com/2.3/questions/3964557",
    "Title": "Show that $\\mathbb{E}\\left|\\hat{f_n}-f \\right| \\leq \\frac{2}{n^{1/3}}$ where $\\hat{f_n}$ is a density estimator for $f$",
    "Score": 15,
    "Category": "Chứng minh",
    "Tags": "probability-theory, statistics, expected-value, density-function, upper-lower-bounds",
    "Link": "https://math.stackexchange.com/questions/3964557/show-that-mathbbe-left-hatf-n-f-right-leq-frac2n1-3-where-h",
    "Content": "Question Suppose we have a continuous probability density $f : \\mathbb{R} \\to [0,\\infty)$ such that $\\text{sup}_{x \\in \\mathbb{R}}(\\left|f(x)\\right| + \\left|f'(x)\\right|) \\leq 1. \\;$ Define the density estimator: $$\\hat{f_n} = \\frac{1}{n^{2/3}}\\sum^n_{i=1}\\mathbf{1}\\{-1/2 \\leq n^{1/3}(x-X_i) \\leq 1/2\\}, \\: x \\in \\mathbb{R}$$ Show that, for every $x \\in \\mathbb{R} \\:$ and every $n \\in \\mathbb{N},$ $$\\mathbb{E}\\left|\\hat{f_n}(x)-f(x)\\right| \\leq \\frac{2}{n^{1/3}}$$ Attempt It's easy to show that $$\\mathbb{E}\\hat{f_n} = \\frac{F(x+\\frac{1}{2}n^{-1/3}) - F(x-\\frac{1}{2}n^{-1/3})}{n^{-1/3}}$$ where $F$ is the CDF of $f$ . From here, using the condition $\\:\\text{sup}_{x \\in \\mathbb{R}}(\\left|f(x)\\right| + \\left|f'(x)\\right|) \\leq 1 \\:$ and in particular, $\\:\\text{sup}_{x \\in \\mathbb{R}}\\left|f'(x)\\right|\\leq 1\\:$ we can show (geometrically) that, $$\\left|\\mathbb{E}\\hat{f_n}-f\\right| \\leq \\frac{1}{4n^{1/3}}$$ However, I'm not sure how to get a bound on $\\mathbb{E}\\left|\\hat{f_n}-f\\right|$ .",
    "AcceptedAnswer": "General The density estimator is a special case of a kernel density estimator (KDE) with rectangular kernel $$K(x)=\\mathbf{1}\\{-1/2\\leq x\\leq 1/2\\}$$ and bandwidth $h=n^{-1/3}$ . It would therefore be possible to use the general theory of KDEs and deduce the result. I will not follow that approach but instead derive properties of this specific estimator directly and link the results to the general KDE theory if possible. Distribution of $\\hat{f_n}$ As (apart from a multiplicative constant) the estimator is effectively counting the number of times an observation of $X_i$ is falling into the interval $\\left[x-\\frac{1}{2}n^{-1/3}, x+\\frac{1}{2}n^{-1/3}\\right]$ when calculating $\\hat{f_n}(x)$ we can immediately see that $$n^{2/3} \\hat{f_n}\\sim\\operatorname{Binomial}(n,p)$$ with $p$ equal to $$F\\left(x+\\frac{1}{2}n^{-1/3}\\right)-F\\left(x-\\frac{1}{2}n^{-1/3}\\right).$$ This secretly assumes that all the $X_i$ are independent and identically distributed with CDF $F$ . From this we can infer directly that $\\mathbb{E}\\hat{f_n}(x)=n^{1/3}p$ and $\\operatorname{Var}(\\hat{f_n}(x))=n^{-1/3}p(1-p)$ . Asymptotics To get the asymptotic behaviour of the expectation and variance we have to analyse $p$ from above. Using a Taylor approximation at $x$ we see that $$F\\left(x\\pm\\frac{1}{2}n^{-1/3}\\right)=F(x)\\pm f(x)\\frac{1}{2}n^{-1/3}+f'(\\xi_\\pm)\\frac{1}{8}n^{-2/3}$$ for some $\\xi_\\pm$ between $x$ and $x\\pm\\frac{1}{2}n^{-1/3}$ . Knowing that $|f'|\\leq 1$ we get $$\\left|\\mathbb{E}\\hat{f_n}(x)-f(x)\\right|\\leq\\frac{1}{4}n^{-1/3}\\tag1.$$ Remark Assuming that also $f''$ exists and is continuous we could get a stronger result. In this case the bias of $\\hat{f_n}$ would tend to zero with the order $n^{-2/3}$ . This is in line with the more general result that under mild assumptions on the kernel $h$ we have that $$\\left|\\mathbb{E}\\hat{f_n}(x)-f(x)\\right|=\\mathcal{O}(h^2)$$ for $n$ towards infinity. For the variance we also use a shortened version of the Taylor approximation $$F\\left(x\\pm\\frac{1}{2}n^{-1/3}\\right)=F(x)\\pm f(\\zeta_\\pm)\\frac{1}{2}n^{-1/3}$$ for some $\\zeta_\\pm$ between $x$ and $x\\pm\\frac{1}{2}n^{-1/3}$ . The variance can now be written as $n^{-1/3}p(1-p)=n^{-1/3}(p-p^2)$ with $$p-p^2=f(x)n^{-1/3}+(f'(\\xi_+)-f'(\\xi_-))\\frac{1}{8}n^{-2/3} - (f(\\zeta_+)+f(\\zeta_-))^2\\frac{1}{4}n^{-2/3}.$$ Again, using the given upper bounds for $f$ and $f'$ we can bound the variance from above by $$\\operatorname{Var}(\\hat{f_n}(x))\\leq n^{-1/3}\\left(n^{-1/3}+\\frac{1}{4}n^{-2/3}\\right)\\leq\\frac{5}{4}n^{-2/3}.\\tag2$$ Remark This result is similar to a result from the general theory of KDEs, which gives $$\\operatorname{Var}(\\hat{f_n}(x)) =\\mathcal{O}((nh)^{-1})$$ for $n$ towards infinity. Combining the results To get the desired result we use a decomposition of the mean absolute error (MAE) similar to that of the mean squared error. We start with \\begin{align}\\mathbb{E}\\left|\\hat{f_n}(x)-f(x)\\right|&\\leq\\mathbb{E}\\left|\\hat{f_n}(x)-\\mathbb{E}\\hat{f_n}(x)\\right|+\\mathbb{E}\\left|\\mathbb{E}\\hat{f_n}(x)-f(x)\\right|\\\\&\\leq\\left(\\mathbb{E}\\left|\\hat{f_n}(x)-\\mathbb{E}\\hat{f_n}(x)\\right|^2\\right)^{1/2}+\\left|\\mathbb{E}\\hat{f_n}(x)-f(x)\\right|\\\\&=\\operatorname{Var}\\left(\\hat{f_n}(x)\\right)^{1/2}+\\left|\\mathbb{E}\\hat{f_n}(x)-f(x)\\right|\\end{align} using the triangle and Hölder inequalities. Using bounds $(1)$ and $(2)$ we finally get $$\\mathbb{E}\\left|\\hat{f_n}(x)-f(x)\\right|\\leq\\left(\\frac{\\sqrt{5}}{2}+\\frac{1}{4}\\right)n^{-1/3}\\leq 2n^{-1/3}$$ and have the result.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nassumption: \n$f: \\mathbb{R} \\to [0, \\infty)$ is a continuous probability density function,\n$\\sup_{x \\in \\mathbb{R}} |f(x)| \\leq 1$,\n$\\sup_{x \\in \\mathbb{R}} |f'(x)| \\leq 1$.\nproblem:\nShow that for every $x \\in \\mathbb{R}$ and every $n \\in \\mathbb{N}$,  \n$$\\mathbb{E}\\left|\\hat{f_n}(x)-f(x)\\right| \\leq \\frac{2}{n^{1/3}},$$  \nwhere  \n$$\\hat{f_n} = \\frac{1}{n^{2/3}}\\sum^n_{i=1}\\mathbf{1}\\{-1/2 \\leq n^{1/3}(x-X_i) \\leq 1/2\\}.$$\n###END_OF_FORMAT###",
    "reasoning_create_structured_problem": "Okay, let's tackle this problem. First, I need to understand the given assumptions and what needs to be proven. The user wants me to structure the problem by listing each assumption line by line, focusing on one property per line applied to a single object. Then, present the problem statement clearly.\n\nLooking at the original question: The goal is to show that the expected absolute difference between the density estimator \\(\\hat{f_n}\\) and the true density \\(f\\) is bounded by \\(2/n^{1/3}\\). The assumptions given include that \\(f\\) is a continuous probability density with both \\(f(x)\\) and its derivative \\(f'(x)\\) bounded in supremum norm by 1. The estimator \\(\\hat{f_n}\\) is defined as a sum of indicator functions scaled by \\(n^{2/3}\\), involving \\(n^{1/3}\\) in the interval around each data point \\(X_i\\).\n\nThe user's attempt already derived the expectation of \\(\\hat{f_n}\\) as the difference quotient of the CDF \\(F\\), which relates to \\(f\\) through the mean value theorem. They managed to bound the bias term \\(|\\mathbb{E}\\hat{f_n} - f(x)|\\) by \\(1/(4n^{1/3})\\) using the Lipschitz condition from the bounded derivative. However, the issue is moving from the bias to the expectation of the absolute difference, which involves dealing with the variance of the estimator.\n\nTo structure this correctly, I need to list each assumption separately. The first assumption is that \\(f\\) is a continuous probability density function from \\(\\mathbb{R}\\) to \\([0, \\infty)\\). Second, the supremum of \\(|f(x)| + |f'(x)|\\) over all real numbers is at most 1. This can be split into two separate assumptions: one for the supremum of \\(f(x)\\) and another for the supremum of \\(f'(x)\\), but the problem states them together. However, according to the example provided, each assumption should address one property applied to one object. So maybe split them into two separate lines.\n\nWait, the original problem states \\(\\text{sup}_{x \\in \\mathbb{R}}(|f(x)| + |f'(x)|) \\leq 1\\). The user might consider this as a single condition, but to adhere to the format, we need to list each part separately. However, the problem as stated combines them. The user example had an assumption that \\(n\\) is an integer and another that \\(n\\) is divisible by 7. Here, the original problem's condition is a combined bound on \\(f\\) and its derivative. Since the user example split different conditions, maybe here we need to split into two: one for the bound on \\(f\\) and another for the bound on \\(f'\\). But the original problem's assumption is a single condition. Hmm. The example given by the user for the original problem had two separate assumptions. So perhaps here, even if the original problem states them together, we need to split them into separate assumptions. Wait, the original problem says \"such that \\(\\text{sup}_{x \\in \\mathbb{R}}(|f(x)| + |f'(x)|) \\leq 1\\)\", which is a single condition. However, the example given by the user in the initial instruction split different conditions (e.g., n is integer, n divisible by 7). So in this case, maybe the combined condition is one assumption, even though it involves two parts. Because the condition is a joint bound on \\(f\\) and its derivative. Alternatively, if we can split into two separate bounds, but given that the original problem states it as a single condition, perhaps we should keep it as one. But according to the user's instruction, each assumption should address only one property or condition applied to one object. So perhaps we need to split the supremum condition into two separate assumptions: one that \\(\\sup_{x} |f(x)| \\leq 1\\) and another that \\(\\sup_{x} |f'(x)| \\leq 1\\). Because the original problem's condition is equivalent to these two combined. Therefore, even though the problem states them together, we can split them into two separate assumptions. The user's attempt mentions using the condition on the derivative specifically. So, following the example, each assumption should be a single condition on a single object. Therefore, the assumptions would be:\n\n1. \\(f: \\mathbb{R} \\to [0, \\infty)\\) is a continuous probability density function.\n2. \\(\\sup_{x \\in \\mathbb{R}} |f(x)| \\leq 1\\).\n3. \\(\\sup_{x \\in \\mathbb{R}} |f'(x)| \\leq 1\\).\n\nThen, the problem is to show that for every \\(x \\in \\mathbb{R}\\) and every \\(n \\in \\mathbb{N}\\), the expectation of the absolute difference is bounded by \\(2/n^{1/3}\\).\n\nSo in the Assumption section, each line is one condition. The first line is about \\(f\\) being a continuous PDF. The second line bounds \\(f\\) itself, the third line bounds its derivative. Then the problem statement is as given.\n\nChecking the example again: The original problem had \"for every integer \\(n\\)\" and then \"divisible by 7\". The user split these into two assumptions. So in this case, even though the problem might have a combined condition, each part is separated. Therefore, here, splitting the supremum into two separate bounds on \\(f\\) and \\(f'\\) as separate assumptions makes sense.\n\nThus, the formatted problem should have three assumptions: continuity and being a PDF, bound on \\(f\\), bound on \\(f'\\). The problem statement then asks to show the bound on the expectation of the absolute difference.",
    "Original_Problem": "assumption: \n$f: \\mathbb{R} \\to [0, \\infty)$ is a continuous probability density function,\n$\\sup_{x \\in \\mathbb{R}} |f(x)| \\leq 1$,\n$\\sup_{x \\in \\mathbb{R}} |f'(x)| \\leq 1$.\nproblem:\nShow that for every $x \\in \\mathbb{R}$ and every $n \\in \\mathbb{N}$,  \n$$\\mathbb{E}\\left|\\hat{f_n}(x)-f(x)\\right| \\leq \\frac{2}{n^{1/3}},$$  \nwhere  \n$$\\hat{f_n} = \\frac{1}{n^{2/3}}\\sum^n_{i=1}\\mathbf{1}\\{-1/2 \\leq n^{1/3}(x-X_i) \\leq 1/2\\}.$$",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $f: \\mathbb{R} \\to [0, \\infty)$ is a continuous probability density function,\nAssumption 2: $\\sup_{x \\in \\mathbb{R}} |f(x)| \\leq 1$,\nAssumption 3: $\\sup_{x \\in \\mathbb{R}} |f'(x)| \\leq 1$.\nProblem:\nShow that for every $x \\in \\mathbb{R}$ and every $n \\in \\mathbb{N}$,  \n$$\\mathbb{E}\\left|\\hat{f_n}(x)-f(x)\\right| \\leq \\frac{2}{n^{1/3}},$$  \nwhere  \n$$\\hat{f_n} = \\frac{1}{n^{2/3}}\\sum^n_{i=1}\\mathbf{1}\\{-1/2 \\leq n^{1/3}(x-X_i) \\leq 1/2\\}.$$",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$\\operatorname{Var}(\\hat{f_n}(x)) =\\mathcal{O}((nh)^{-1})$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $f: \\mathbb{R} \\to [0, \\infty)$ is a continuous probability density function,\nAssumption 2: $\\sup_{x \\in \\mathbb{R}} |f(x)| \\leq 1$,\nAssumption 3: $\\sup_{x \\in \\mathbb{R}} |f'(x)| \\leq 1$.\nAssumption 4: $$\\operatorname{Var}(\\hat{f_n}(x)) =\\mathcal{O}((nh)^{-1})$$\nProblem:\nShow that for every $x \\in \\mathbb{R}$ and every $n \\in \\mathbb{N}$,  \n$$\\mathbb{E}\\left|\\hat{f_n}(x)-f(x)\\right| \\leq \\frac{2}{n^{1/3}},$$  \nwhere  \n$$\\hat{f_n} = \\frac{1}{n^{2/3}}\\sum^n_{i=1}\\mathbf{1}\\{-1/2 \\leq n^{1/3}(x-X_i) \\leq 1/2\\}.$$"
}