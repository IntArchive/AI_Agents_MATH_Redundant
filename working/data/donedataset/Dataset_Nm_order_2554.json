{
    "Link_API": "https://api.stackexchange.com/2.3/questions/1670030",
    "Title": "Convergence in law implies uniform convergence of cdf&#39;s",
    "Score": 13,
    "Category": "Chứng minh",
    "Tags": "probability-theory, probability-distributions, uniform-convergence",
    "Link": "https://math.stackexchange.com/questions/1670030/convergence-in-law-implies-uniform-convergence-of-cdfs",
    "Content": "Let $F_n, \\ F$ be distribution functions with respect to some variables $X_n,\\ X$ (in a not necessarily common probability space). Suppose that $F$ is continuous and $F_n \\overset{d}{\\rightarrow}F$ (i.e in law). Prove that $(F_n)$ converges uniformly to $F$, i.e. $$\\displaystyle \\lim_{n\\rightarrow +\\infty}\\sup_{x\\in \\mathbb{R}}|F_n(x)-F(x)|=0$$ Comments . On a proof by contadiction, I 'd suppose that for some $\\varepsilon>0$ for all $n$ there is $x_n$ such that $|F_n(x_n)-F(x_n)|\\geq \\varepsilon.$ But a classic analytic approach throught Bolzano - Weierstrass theorem can not be applied here since there is no information on the boundness of $(x_n).$ Thanks a lot in advance for the help!",
    "AcceptedAnswer": "Hint: (as stated in Parzen, 1960). Convergence in distribution is defined for points $x$ of continuity of $F$, so here since $F$ is continuous, that is for every $x\\in \\mathbb R$. Now, to any $ε>0$, choose points $$-\\infty=x_0<x_1<\\dots<x_K=+\\infty$$ so that $F(x_j)-F(x_{j-1})<ε, \\text{ for } \\ j=1,2,\\dots,K$ (recall that $F$ in non-decreasing). Verify that $$\\sup_{x\\in \\Bbb R}|F_{n}(x)-F(x)|\\le \\max_{j=0,1,\\dots,K}|F_n(x_j)-F(x_j)|+ε$$ If $F$ is not continuous, this statement fails. Bernoulli distributions provide already counterexamples, in this case.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$F_n$ and $F$ are distribution functions,\n$F$ is continuous,\n$F_n$ converges in distribution to $F$.\nProblem: \nProve that $$\\lim_{n\\rightarrow +\\infty}\\sup_{x\\in \\mathbb{R}}|F_n(x)-F(x)|=0.$$\n###END_OF_FORMAT###",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem step by step. So, the question is about proving that if a sequence of distribution functions \\( F_n \\) converges in law to a continuous distribution function \\( F \\), then the convergence is uniform. \n\nFirst, let's recall what convergence in law (or distribution) means. It means that \\( F_n(x) \\to F(x) \\) for all continuity points \\( x \\) of \\( F \\). But here, \\( F \\) is given as continuous, so that convergence should hold for all \\( x \\in \\mathbb{R} \\). However, pointwise convergence doesn't necessarily imply uniform convergence on its own. So, the continuity of \\( F \\) must play a crucial role here.\n\nThe user mentioned attempting a proof by contradiction. Suppose there exists some \\( \\varepsilon > 0 \\) such that for all \\( n \\), there exists \\( x_n \\) with \\( |F_n(x_n) - F(x_n)| \\geq \\varepsilon \\). The concern is that the sequence \\( x_n \\) might not be bounded, so applying Bolzano-Weierstrass (which requires boundedness to extract a convergent subsequence) isn't straightforward. \n\nHmm. Maybe we need to handle the cases where \\( x_n \\) is bounded and unbounded separately? If \\( x_n \\) is unbounded, perhaps we can use the properties of distribution functions at infinity. Since \\( F \\) is continuous, as \\( x \\to \\infty \\), \\( F(x) \\to 1 \\), and as \\( x \\to -\\infty \\), \\( F(x) \\to 0 \\). Similarly, \\( F_n(x) \\) approaches 1 and 0 at the extremes. So even if \\( x_n \\) is unbounded, maybe the difference \\( |F_n(x_n) - F(x_n)| \\) becomes small there because both \\( F_n(x_n) \\) and \\( F(x_n) \\) are approaching the same limit. \n\nWait, but if \\( x_n \\) is going to infinity, then \\( F_n(x_n) \\) should approach 1, and \\( F(x_n) \\) also approaches 1. But convergence in distribution doesn't necessarily control \\( F_n(x_n) \\) for sequences \\( x_n \\) tending to infinity. However, because \\( F \\) is continuous, it's uniformly continuous on \\( \\mathbb{R} \\). Maybe that's a key point. \n\nAlternatively, perhaps we can use the fact that for a continuous distribution function \\( F \\), the convergence in distribution implies that the convergence is uniform. This is similar to the Glivenko-Cantelli theorem, but that's for empirical distributions. However, the idea might be related. \n\nAnother approach: Since \\( F \\) is continuous, given any \\( \\varepsilon > 0 \\), we can find points \\( -\\infty = x_0 < x_1 < \\dots < x_k = \\infty \\) such that \\( F(x_{i+1}) - F(x_i) < \\varepsilon \\) for each \\( i \\). Then, because \\( F_n \\) converges to \\( F \\) at each \\( x_i \\), for sufficiently large \\( n \\), \\( |F_n(x_i) - F(x_i)| < \\varepsilon \\) for all \\( i \\). Then, for any \\( x \\in [x_i, x_{i+1}] \\), we can bound \\( |F_n(x) - F(x)| \\) using the triangle inequality and the fact that \\( F \\) has small increments over these intervals. \n\nWait, this seems promising. Let me elaborate. Since \\( F \\) is continuous, it is uniformly continuous on \\( \\mathbb{R} \\). Therefore, for any \\( \\varepsilon > 0 \\), there exists a partition \\( x_0 < x_1 < \\dots < x_k \\) such that \\( F(x_{i+1}) - F(x_i) < \\varepsilon \\) for all \\( i \\). Then, because \\( F_n(x_i) \\to F(x_i) \\) for each \\( i \\), there exists \\( N \\) such that for all \\( n \\geq N \\), \\( |F_n(x_i) - F(x_i)| < \\varepsilon \\) for all \\( i \\). \n\nNow, take any \\( x \\in \\mathbb{R} \\). Suppose \\( x \\in [x_i, x_{i+1}] \\). Then, \n\n\\( F_n(x) \\leq F_n(x_{i+1}) \\leq F(x_{i+1}) + \\varepsilon \\leq F(x) + \\varepsilon + \\varepsilon = F(x) + 2\\varepsilon \\).\n\nSimilarly, \\( F_n(x) \\geq F_n(x_i) \\geq F(x_i) - \\varepsilon \\geq F(x) - \\varepsilon - \\varepsilon = F(x) - 2\\varepsilon \\).\n\nHence, \\( |F_n(x) - F(x)| \\leq 2\\varepsilon \\). But wait, this gives a bound of \\( 2\\varepsilon \\), but maybe by adjusting the initial epsilon, we can get the desired result. \n\nHowever, I need to check if this approach works. The key idea is that the uniform continuity of \\( F \\) allows us to create a grid where the function doesn't vary too much, and then use pointwise convergence on the grid points to control the behavior between them. \n\nBut there's a problem here: in reality, we can't have \\( x_0 = -\\infty \\) and \\( x_k = \\infty \\). Instead, we can choose points \\( x_1 \\) and \\( x_{k-1} \\) such that \\( F(x_1) < \\varepsilon \\) and \\( 1 - F(x_{k-1}) < \\varepsilon \\). Then, for the intervals \\( (-\\infty, x_1] \\) and \\( [x_{k-1}, \\infty) \\), the difference \\( |F_n(x) - F(x)| \\) can be controlled using the tails. \n\nFor example, take \\( x \\leq x_1 \\). Then, \\( F_n(x) \\leq F_n(x_1) \\leq F(x_1) + \\varepsilon < \\varepsilon + \\varepsilon = 2\\varepsilon \\). Similarly, \\( F(x) \\leq F(x_1) < \\varepsilon \\), so \\( |F_n(x) - F(x)| < 2\\varepsilon \\). Similarly for \\( x \\geq x_{k-1} \\), \\( 1 - F(x) < \\varepsilon \\), and \\( 1 - F_n(x) \\leq 1 - F_n(x_{k-1}) \\leq 1 - (F(x_{k-1}) - \\varepsilon) = (1 - F(x_{k-1})) + \\varepsilon < \\varepsilon + \\varepsilon = 2\\varepsilon \\). \n\nTherefore, combining these, for all \\( x \\in \\mathbb{R} \\), \\( |F_n(x) - F(x)| < 2\\varepsilon \\). Since \\( \\varepsilon \\) is arbitrary, this would imply uniform convergence. \n\nBut in the original problem statement, the user mentioned a proof by contradiction. Let's see how that would work. Suppose that the convergence is not uniform. Then, there exists an \\( \\varepsilon > 0 \\), a subsequence \\( n_k \\), and points \\( x_{n_k} \\) such that \\( |F_{n_k}(x_{n_k}) - F(x_{n_k})| \\geq \\varepsilon \\). \n\nNow, if the sequence \\( x_{n_k} \\) is bounded, then by Bolzano-Weierstrass, there's a convergent subsequence \\( x_{n_{k_j}} \\to x^* \\). Then, since \\( F \\) is continuous, \\( F(x_{n_{k_j}}) \\to F(x^*) \\). Also, by convergence in distribution, \\( F_{n_{k_j}}(x^*) \\to F(x^*) \\). However, \\( |F_{n_{k_j}}(x_{n_{k_j}}) - F(x_{n_{k_j}})| \\geq \\varepsilon \\). If \\( x_{n_{k_j}} \\to x^* \\), then maybe we can relate \\( F_{n_{k_j}}(x_{n_{k_j}}) \\) to \\( F_{n_{k_j}}(x^*) \\). But convergence in distribution doesn't necessarily allow us to do that unless we have some uniform continuity or equicontinuity. \n\nAlternatively, using the fact that \\( F \\) is uniformly continuous, we can bound \\( |F_{n_{k_j}}(x_{n_{k_j}}) - F_{n_{k_j}}(x^*)| \\leq |F_{n_{k_j}}(x_{n_{k_j}}) - F(x_{n_{k_j}})| + |F(x_{n_{k_j}}) - F(x^*)| + |F(x^*) - F_{n_{k_j}}(x^*)| \\). But this seems messy. \n\nOn the other hand, if \\( x_{n_k} \\) is unbounded, then without loss of generality, suppose \\( x_{n_k} \\to \\infty \\). Then, \\( F(x_{n_k}) \\to 1 \\), and \\( F_{n_k}(x_{n_k}) \\) should also approach 1 because of convergence in distribution. But convergence in distribution implies that for any fixed \\( M \\), \\( F_{n_k}(M) \\to F(M) \\). However, if \\( x_{n_k} \\to \\infty \\), can we say \\( F_{n_k}(x_{n_k}) \\to 1 \\)? Not necessarily, unless we have some tightness condition. But since \\( F_n \\) are distribution functions, they are tight. \n\nTightness means that for any \\( \\varepsilon > 0 \\), there exists \\( M \\) such that \\( F_n(M) > 1 - \\varepsilon \\) and \\( F_n(-M) < \\varepsilon \\) for all \\( n \\). If we have tightness, then even if \\( x_{n_k} \\to \\infty \\), \\( F_{n_k}(x_{n_k}) \\) would be close to 1 for sufficiently large \\( k \\), and \\( F(x_{n_k}) \\) is also close to 1, so their difference would be small. \n\nBut tightness is a consequence of convergence in distribution if the limit distribution is tight, which it is since it's a distribution function. Therefore, perhaps combining tightness and the continuity of \\( F \\), we can handle the unbounded case. \n\nSo, putting this all together, the steps might be:\n\n1. Use the continuity of \\( F \\) to establish uniform continuity and tightness.\n\n2. For a given \\( \\varepsilon > 0 \\), choose a compact interval \\( [-M, M] \\) such that \\( F(-M) < \\varepsilon \\) and \\( F(M) > 1 - \\varepsilon \\). By tightness, \\( F_n(-M) < \\varepsilon \\) and \\( F_n(M) > 1 - \\varepsilon \\) for all sufficiently large \\( n \\).\n\n3. On the interval \\( [-M, M] \\), since \\( F \\) is uniformly continuous, create a partition \\( x_0, x_1, ..., x_k \\) such that \\( F(x_{i+1}) - F(x_i) < \\varepsilon \\).\n\n4. Use pointwise convergence at each \\( x_i \\) to get \\( |F_n(x_i) - F(x_i)| < \\varepsilon \\) for large \\( n \\).\n\n5. For any \\( x \\in [-M, M] \\), find the interval \\( [x_i, x_{i+1}] \\) containing \\( x \\), and use the monotonicity of \\( F_n \\) and \\( F \\) to bound \\( |F_n(x) - F(x)| \\).\n\n6. Combine the bounds inside and outside \\( [-M, M] \\) to get uniform convergence.\n\nAlternatively, in the contradiction approach, assuming that the convergence isn't uniform leads to a sequence \\( x_n \\) where \\( |F_n(x_n) - F(x_n)| \\geq \\varepsilon \\). If \\( x_n \\) is bounded, extract a convergent subsequence and use convergence in distribution to get a contradiction. If \\( x_n \\) is unbounded, use tightness to show that \\( F_n(x_n) \\) and \\( F(x_n) \\) are both close to 1 (or 0), leading to a contradiction. \n\nThis seems to cover both scenarios. Therefore, the proof would involve splitting into cases based on the boundedness of \\( x_n \\), using tightness for the unbounded case, and pointwise convergence plus continuity for the bounded case. \n\nSo, the main assumptions here are the continuity of \\( F \\), convergence in distribution of \\( F_n \\) to \\( F \\), and the properties of distribution functions (monotonicity, right-continuity, limits at infinity). The problem requires leveraging these to establish uniform convergence.",
    "Original_Problem": "Assumption: \n$F_n$ and $F$ are distribution functions,\n$F$ is continuous,\n$F_n$ converges in distribution to $F$.\nProblem: \nProve that $$\\lim_{n\\rightarrow +\\infty}\\sup_{x\\in \\mathbb{R}}|F_n(x)-F(x)|=0.$$",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $F_n$ and $F$ are distribution functions,\nAssumption 2: $F$ is continuous,\nAssumption 3: $F_n$ converges in distribution to $F$.\nProblem: \nProve that $$\\lim_{n\\rightarrow +\\infty}\\sup_{x\\in \\mathbb{R}}|F_n(x)-F(x)|=0.$$",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$\\sup_{x\\in \\Bbb R}|F_{n}(x)-F(x)|\\le \\max_{j=0,1,\\dots,K}|F_n(x_j)-F(x_j)|+ε$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $F_n$ and $F$ are distribution functions,\nAssumption 2: $F$ is continuous,\nAssumption 3: $F_n$ converges in distribution to $F$.\nAssumption 4: $$\\sup_{x\\in \\Bbb R}|F_{n}(x)-F(x)|\\le \\max_{j=0,1,\\dots,K}|F_n(x_j)-F(x_j)|+ε$$\nProblem: \nProve that $$\\lim_{n\\rightarrow +\\infty}\\sup_{x\\in \\mathbb{R}}|F_n(x)-F(x)|=0.$$"
}