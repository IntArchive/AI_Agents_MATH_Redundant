{
    "Link_API": "https://api.stackexchange.com/2.3/questions/411143",
    "Title": "Singular value decomposition of positive definite matrix",
    "Score": 16,
    "Category": "Chứng minh",
    "Tags": "linear-algebra, matrices, positive-definite, svd",
    "Link": "https://math.stackexchange.com/questions/411143/singular-value-decomposition-of-positive-definite-matrix",
    "Content": "Let $A$ be a positive definite matrix, and let $A = U \\Sigma V^*$ be its singular value decomposition (SVD). Show that $U=V$ . What I have done: $A$ is Hermitian, so $A$ is unitarily diagonalizable, say, $A=WDW^*$ where $D$ consists of the eigenvalues (decreasing order). Also $D=\\Sigma$ since $A$ is positive definite. From $A^2=AA^*=UD^2U^*$ , and similarly I have $A^2=UD^2U^*=VD^2V^*=WD^2W^*$ so the column vectors of $U,V,W$ corresponds to same eigenvalues of $A^2$ . And I'm now stuck. How could I proceed?",
    "AcceptedAnswer": "As you already figured out, $A = U D V^*$ gives $A^2 = UD^2 U^* = V D^2 V^*$. Now, since positive Hermitian matrices only have one positive Hermitian square root, $A = UDU^* = UDV^*$, and since $U$ and $D$ are invertible, $U^* = V^*$. Now, we need to show that positive Hermitian matrices have only one positive Hermitian square root. Suppose that $A$ is Hermitian. Consider the eigenspaces of $A$. Suppose that $Av = \\lambda v$. Then $A^2 v = \\lambda^2 v$. Since the map $\\lambda \\rightarrow \\lambda^2$ is one-to-one on positive reals, this shows that $A$ and $A^2$ have exactly the same eigenspaces, with an eigenvalue of $\\lambda$ in $A$ corresponding to an eigenvalue of $\\lambda^2$ in $A^2$. This is enough to uniquely characterize $A$, given $A^2$. (We are implicitly using the fact that the vector space is a direct sum of eigenspaces of $A$. This is true since $A$ is Hermitian.)",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$A$ is a positive definite matrix,\n$A$ has a singular value decomposition $A = U \\Sigma V^*$.\nproblem: \nShow that $U = V$.\n###",
    "reasoning_create_structured_problem": "Okay, let me try to figure out how to approach this problem. The user wants to show that for a positive definite matrix A, its SVD decomposition A = UΣV* must have U equal to V. \n\nFirst, I remember that positive definite matrices are Hermitian, which means they satisfy A = A*. So, A being Hermitian implies that in its eigenvalue decomposition, we can write A = WDW*, where W is unitary and D is diagonal with eigenvalues. Since A is positive definite, all eigenvalues in D are positive, right? And the singular values Σ should be the same as the eigenvalues because the singular values are the absolute values of the eigenvalues, but since they're all positive here, Σ = D.\n\nNow, the user mentioned the SVD of A is UΣV*. But for Hermitian matrices, the SVD and eigenvalue decomposition are related. Usually, the SVD has U and V as unitary matrices, and Σ as the diagonal matrix of singular values. But if A is Hermitian and positive definite, then maybe the left singular vectors (U) and right singular vectors (V) should be related to the eigenvectors of A.\n\nSince A is Hermitian, the eigenvalue decomposition is A = WDW*, where W is unitary and D has eigenvalues. The SVD would be A = UΣV*. Comparing these two decompositions, if D = Σ (since eigenvalues are positive and equal to singular values), then perhaps UΣV* = WDW*. But how does this lead to U = V?\n\nThe user also mentioned that A^2 = AA* (since A is Hermitian, A* = A, so AA* = A^2). Then, using the SVD, A^2 = (UΣV*)(VΣU*) = UΣ²U*, and similarly, the eigenvalue decomposition of A^2 would be WD²W*. So, from both expressions, UΣ²U* = WD²W*. Since Σ² = D² (as Σ = D), then U and W must be related. Maybe U and W are the same up to permutation of eigenvectors, but since the eigenvalues are in decreasing order in Σ, maybe W is arranged in the same order, so U = W. Similarly, from the SVD, A = UΣV* and from eigenvalue decomposition A = WDW*. Since Σ = D and U = W, then WDW* = UΣV* implies that V* must be equal to W*, so V = W. Therefore, U = V.\n\nWait, but the user seems to be stuck at the part where after equating A^2 expressions, how to conclude that U and V are the same. Let me check the steps again.\n\nOriginal problem steps:\n\n1. A is Hermitian, so A = WDW* (eigenvalue decomposition), D is diagonal with eigenvalues in decreasing order.\n2. Since A is positive definite, D = Σ (singular values are the eigenvalues here).\n3. Then, compute A^2 = AA* = UΣ²U* (since A = UΣV*, so A* = VΣU*, and multiplying gives UΣ²U*).\n4. Similarly, from eigenvalue decomposition, A^2 = W D² W*.\n5. Thus, UΣ²U* = VΣ²V* = W D² W*. Since Σ² = D² and they are in the same order, the unitary matrices U, V, W must be equal up to the eigenvectors corresponding to the same eigenvalues. But if eigenvalues are distinct, the eigenvectors are unique up to phase factors. If there are repeated eigenvalues, then there's freedom in choosing eigenvectors, but since the problem states that Σ (and hence D) is arranged in decreasing order, maybe the order enforces U = V = W.\n\nTherefore, since A can be expressed both as UΣV* and WDW*, and we have UΣV* = WDW*, with Σ = D, then U and V must be equal to W. Therefore, U = V.\n\nBut the user is stuck here. The key is that in the SVD, the left and right singular vectors are the eigenvectors of AA* and A*A. But since A is Hermitian and positive definite, AA* = A*A = A^2, so both U and V should be the eigenvectors of A^2. But since A is already diagonalizable by W, then U and V must be the same as W, hence U = V.\n\nAlternatively, since A is positive definite and Hermitian, its SVD is the same as its eigenvalue decomposition. So, UΣV* = WDW*, but since Σ = D and W is unitary, then U = W and V* = W*, so V = W. Hence, U = V.\n\nI think that's the reasoning. So the problem is to show that U = V in the SVD of a positive definite matrix A. The assumptions would include that A is positive definite (which implies Hermitian, all eigenvalues positive), and that the SVD is A = UΣV*. The problem is to show U = V.\n\nNow, structuring according to the required format:\n\nAssumptions should list each condition applied to one object. So:\n\nAssumption:\nA is a positive definite matrix,\nA has singular value decomposition A = UΣV*.\n\nProblem:\nShow that U = V.\n\nBut wait, the original problem didn't mention anything about A being Hermitian, but positive definite matrices are already Hermitian. So maybe the assumption should include that A is Hermitian, but in the problem statement, the user starts by saying \"Let A be a positive definite matrix\", which inherently makes it Hermitian. So maybe the key assumptions are:\n\nAssumption:\nA is a positive definite matrix,\nA is decomposed as A = UΣV* (SVD).\n\nThen the problem is to show U = V.\n\nBut according to the example, each assumption is one property applied to one object. So maybe:\n\nAssumption:\nA is a positive definite matrix,\nA is decomposed via SVD as A = UΣV*.\n\nProblem:\nShow that U = V.\n\nYes, that seems to fit. Because the positive definiteness gives that A is Hermitian, and the SVD decomposition is given. The problem is to show the equality of U and V.",
    "Original_Problem": "Assumption: \n$A$ is a positive definite matrix,\n$A$ has a singular value decomposition $A = U \\Sigma V^*$.\nproblem: \nShow that $U = V$.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $A$ is a positive definite matrix,\nAssumption 2: $A$ has a singular value decomposition $A = U \\Sigma V^*$.\nProblem: \nShow that $U = V$.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$\\lambda \\rightarrow \\lambda^2$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $A$ is a positive definite matrix,\nAssumption 2: $A$ has a singular value decomposition $A = U \\Sigma V^*$.\nAssumption 3: $\\lambda \\rightarrow \\lambda^2$\nProblem: \nShow that $U = V$."
}