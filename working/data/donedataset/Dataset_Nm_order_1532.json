{
    "Link_API": "https://api.stackexchange.com/2.3/questions/4492420",
    "Title": "The matrix logarithm is well-defined - but how can we *algebraically* see that it is inverse to the exponential, as a finite polynomial?",
    "Score": 20,
    "Category": "Chứng minh",
    "Tags": "linear-algebra, matrix-calculus, matrix-exponential, functional-calculus",
    "Link": "https://math.stackexchange.com/questions/4492420/the-matrix-logarithm-is-well-defined-but-how-can-we-algebraically-see-that-i",
    "Content": "This question is inspired by this which I saw earlier today. I started writing my answer, to share the insight that the matrix logarithm can be defined on matrices that do not have unit norm using an alternative technique. Now, Sangchul has posted a great answer explaining how it is that we know the map $X\\mapsto\\sum_{n=1}^\\infty\\frac{(-1)^{n-1}}{n}X^n$ defines a logarithm of $1+X$ whenever the sum is convergent, whenever $\\|X\\|\\lt1$ . By scaling, we can use this map to obtain arbitrary logarithms since there is an easy definition $\\log(\\lambda I)=(\\log\\lambda)I$ which satisfies $\\exp(\\log(\\lambda I))=\\lambda I$ trivially, and this matrix will also commute with all other matrices. I prefer an approach that sidesteps the functional calculus entirely, that I first learnt on Wikipedia over a year ago. The argument proceeds like this, paraphrased by me: For any invertible $n\\times n$ complex matrix $X$ , there is a basis of the space $\\Bbb C^n$ in which $X=\\bigoplus_{m=1}^kJ_m$ a decomposition into Jordan blocks with some associated eigenvalues $\\lambda_m$ . If we can find a matrix $Y=\\bigoplus_{m=1}^nT_m$ , where $\\exp(T_m)=J_m$ for all $m$ , then a simple inspection of the exponential series shows $\\exp(Y)=\\bigoplus_{m=1}^n\\exp(T_m)=\\bigoplus_{m=1}^nJ_m=X$ , so $Y$ is a logarithm of $X$ . Many will exist due to branching concerns. It remains to find a logarithm of any arbitrary Jordan block. For a block $J$ with eigenvalue $\\lambda$ , we can write $J=\\lambda(I+K)$ where $K$ is the matrix will all zero entries, except for entries $\\lambda^{-1}$ on the first superdiagonal ( $\\lambda\\neq0$ by invertibility). If we suppose the formal power series argument is valid , we can say: $$\\begin{align}\\log(\\lambda(I+K))&=\\log(\\lambda)I+\\log(I+K)\\\\&=\\log(\\lambda)I+K-\\frac{1}{2}K^2+\\frac{1}{3}K^3\\\\&+\\cdots+(-1)^j\\frac{1}{j-1}K^{j-1}\\end{align}$$ Since $K$ will be nilpotent of order $j$ if $j$ is the dimension of the Jordan block, the tail terms of the Mercator series vanish. Any branch of the complex logarithm is appropriate for $(\\log(\\lambda))I$ - due to commutativity, re-exponentiation gives $\\lambda\\exp(K-(1/2)K^2+\\cdots)\\overset{?}{=}\\lambda(1+K)$ . Then to claim that this process produces a logarithm for all invertible $X$ , it suffices to demonstrate the following: For all $\\lambda\\in\\Bbb C$ and all $n\\times n$ square matrices $K$ of the form: $$K=\\begin{pmatrix}0&\\lambda&0&0&\\cdots\\\\0&0&\\lambda&0&\\cdots\\\\0&0&0&\\lambda&\\cdots\\\\\\vdots&\\vdots&\\vdots&\\ddots&\\vdots\\\\0&0&0&\\cdots&0\\end{pmatrix}$$ We have the identity (by commutativity, the two are equivalent): $$\\exp\\left(\\sum_{m=1}^{n-1}\\frac{(-1)^{m-1}}{m}K^m\\right)=\\prod_{m=1}^{n-1}\\exp\\left(\\frac{(-1)^{m-1}}{m}K^m\\right)=I_n+K$$ I am looking for an algebraic (or similar) proof of this result. Don't get me wrong - I appreciate indirect proofs, and find them rather magical whenever they arise, but I have never studied any rigorous development of the functional calculus. Analytic functions can be extended to matrix arguments through a variety of methods - matrix Taylor series, Cayley-Hamilton, bizarre Cauchy integral representations, power series convergent in Banach space... and I accept all of these as extensions , with perhaps some convenient properties such as derivative relations carrying over from the complex/real-analytic theory. However, it seems suspicious that \"higher-order\" properties should also be preserved in this extension process. Although we can give well-defined and well-motivated analogues of $\\exp$ and $\\log$ to matrices, I don't see any immediate reason, a priori , to suppose that the extension reflects relations between them such as $\\exp\\log\\equiv\\mathrm{Id}$ . The main reason for my suspicion is the following observation: analysis tends to work through limiting arguments, and finite sums just won't do - they yield polynomials only. It is then rather odd that an analytic series maintains its \"special\" properties despite collapsing into a finite polynomial series - $\\Bbb C$ has no nilpotent nonzero elements, but the space of matrices certainly does, and is a key ingredient in the above construction of the logarithm. So what am I looking for? I'm looking for a strong explanation for why what I'm calling \"higher-order\" properties should carry over in this extension process, especially since there are many different ways to extend analytic functions to matrix arguments: of course, any properties that can be deduced from the power series will carry over, e.g. $\\exp(A+B)=\\exp(A)\\exp(B)$ if $A,B$ commute. However, $\\exp\\circ\\log$ 's power series is unclear to me here, since the $\\log$ is not actually a power series in this context, really, but a finite polynomial. To reiterate, it is the use of nilpotent elements that concerns me - since this challenges the algebra of $\\Bbb C$ , I feel it should also challenge the analytic series which hail from $\\Bbb C$ : at least, it should need some more justification. An algebraic proof (direct matrix-arithmetic proof, or maybe some clever linear algebra argument) for why this particular nilpotent logarithm should hold, would be greatly appreciated. My thoughts on this matter so far: $$T:=\\sum_{m=1}^{n-1}\\frac{(-1)^{m-1}}{m}K^m\\\\=\\begin{pmatrix}0&\\lambda&-\\frac{1}{2}\\lambda^2&\\cdots&(-1)^n\\frac{1}{n-1}\\lambda^{n-1}\\\\0&0&\\lambda&\\cdots&(-1)^{n-1}\\frac{1}{n-2}\\lambda^{n-2}\\\\0&0&0&\\cdots&(-1)^n\\frac{1}{n-3}\\lambda^{n-3}\\\\\\vdots&\\vdots&\\vdots&\\ddots&\\vdots\\\\0&0&0&\\cdots&0\\end{pmatrix}$$ An observation of the way that this matrix's elements \"shift\" up a diagonal every time the matrix is squared, cubed, etc. shows that the main superdiagonal has nonzero entries once and only once in $I+T+\\frac{1}{2}T^2+\\cdots$ , and we can easily partially compute the exponential: $$\\exp(T)=\\begin{pmatrix}1&\\lambda&?&?&\\cdots&?\\\\0&1&\\lambda&?&\\cdots&?\\\\0&0&1&\\lambda&\\cdots&?\\\\0&0&0&1&\\cdots&?\\\\\\vdots&\\vdots&\\vdots&\\vdots&\\ddots&\\vdots\\\\0&0&0&0&\\cdots&1\\end{pmatrix}$$ So it remains to show that the sum over all the remaining superdiagonals vanishes. Other pertinent point is that $T$ is nilpotent of order $n$ , so the exponential series terminates at $\\frac{1}{(n-1)!}T^{n-1}$ . This re-explains my suspicion, since now we are claiming these two polynomials are inverse, which is false in the complex world that we began in. How can we fill in the algebraic gaps here? The matrix powers seems quite intractable to symbolically compute. N.B. Sanchul's answer in the linked post never once needs the invertibility of $X$ , as far as I can see, whereas this Wikipedia-based construction does. How do we reconcile the two?",
    "AcceptedAnswer": "Here is an answer based on the principle of permanence. Define $c_{n,m}$ by $$ c_{n,m} = \\sum_{\\substack{j_1 \\geq 1, \\ldots, j_n \\geq 1 \\\\ j_1 + \\cdots + j_n = m}} \\frac{(-1)^{j_1-1}}{j_1} \\cdots \\frac{(-1)^{j_n-1}}{j_n}. $$ Then, for $|z| < 1$ , we have $\\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\sum_{j=1}^{\\infty} \\frac{1}{j} |z|^j \\right)^n < \\infty$ . This allows to rearrange the sum $$ \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\sum_{j=1}^{\\infty} \\frac{(-1)^{j-1}}{j} z^j \\right)^n\n= 1 + \\sum_{n=1}^{\\infty} \\frac{1}{n!} \\left( \\sum_{j_1 = 1}^{\\infty} \\cdots \\sum_{j_n = 1}^{\\infty} \\frac{(-1)^{j_1-1}}{j_1} \\cdots \\frac{(-1)^{j_n-1}}{j_n} z^{j_1 + \\cdots + j_n} \\right) $$ as we like. So, \\begin{align*}\n\\exp(\\log(1+z))\n&= \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\sum_{j=1}^{\\infty} \\frac{(-1)^{j-1}}{j} z^j \\right)^n \\\\\n&= 1 + \\sum_{n=1}^{\\infty} \\frac{1}{n!} \\left(\\sum_{m=1}^{\\infty} c_{n,m} z^m \\right) \\\\\n&= 1 + \\sum_{m=1}^{\\infty} \\left(\\sum_{n=1}^{\\infty} \\frac{1}{n!} c_{n,m} \\right) z^m.\n\\end{align*} Comparing this with $\\exp(\\log(1+z)) = 1+z$ , we get $$ \\sum_{n=1}^{\\infty} \\frac{1}{n!} c_{n,m} = \\begin{cases}\n1, & m = 1; \\\\\n0, & m \\geq 2.\n\\end{cases} $$ Now, let $K$ be a nilpotent matrix, so that $K^{d+1} = 0$ for some $d \\geq 1$ . Then \\begin{align*}\n\\exp\\left(\\sum_{j=1}^{\\infty} \\frac{(-1)^{j-1}}{j} K^j \\right)\n&= \\exp\\left(\\sum_{j=1}^{d} \\frac{(-1)^{j-1}}{j} K^j \\right) \\\\\n&= \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\sum_{j=1}^{d} \\frac{(-1)^{j-1}}{j} K^j \\right)^n \\\\\n&= 1 + \\sum_{n=1}^{\\infty} \\frac{1}{n!} \\left(\\sum_{m=1}^{d} c_{n,m} K^m \\right) \\\\\n&= 1 + \\sum_{m=1}^{d} \\left(\\sum_{n=0}^{\\infty} \\frac{1}{n!} c_{n,m}\\right) K^m \\\\\n&= 1 + K.\n\\end{align*}",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$K$ is an $n \\times n$ complex matrix,\n$K$ has zeros on the main diagonal,\nEach entry $(i, i+1)$ of $K$ is $\\lambda$ for $1 \\leq i \\leq n-1$,\nAll other entries of $K$ are zero,\n$T$ is defined as $T = \\sum_{m=1}^{n-1} \\frac{(-1)^{m-1}}{m} K^m$.\nProblem: \nProve that $\\exp(T) = I_n + K$.\n###END_OF_FORMAT###",
    "reasoning_create_structured_problem": "Okay, I need to structure the problem from the given Math Stack Exchange question according to the specified format. Let me first read through the problem carefully to understand what's being asked.\n\nThe user is asking for an algebraic proof that the exponential of a certain nilpotent matrix T, defined as the sum from m=1 to n-1 of [(-1)^(m-1)/m * K^m], equals I + K, where K is a specific nilpotent matrix. The key points here are:\n\n1. K is a Jordan block with zeros on the diagonal and λ on the superdiagonal, but scaled such that K has λ in the superdiagonal. Wait, in the problem statement, K is described as a matrix with 0s except for λ on the first superdiagonal. But in the matrix shown, the entries are λ, so maybe K is a nilpotent matrix with λ on the superdiagonal. However, the user later writes J = λ(I + K), so K must have 1s on the superdiagonal scaled by λ^{-1} to make J = λ(I + K). Wait, let me check that part again.\n\nThe user says: \"For a block J with eigenvalue λ, we can write J = λ(I + K) where K is the matrix with all zero entries except for entries λ^{-1} on the first superdiagonal (λ ≠ 0 by invertibility).\" So K here has entries λ^{-1} on the superdiagonal, making J = λ(I + K). But in the problem statement later, the user defines K as having λ on the superdiagonal. Wait, maybe there's a discrepancy here. Let me check again.\n\nWait, in the problem statement, the user writes: \"For all λ ∈ ℂ and all n×n square matrices K of the form:\n\nK = [[0, λ, 0, ..., 0],\n     [0, 0, λ, ..., 0],\n     ...,\n     [0, ..., 0]]\n\nSo here, K has λ on the superdiagonal. But earlier, when decomposing J, they had K with λ^{-1} on the superdiagonal. So perhaps in the general problem statement, K is any such matrix with λ on the superdiagonal, but in the specific case of the Jordan block, they had to scale it by λ^{-1} to factor out λ. But the key point is that in the problem to be solved, K is a nilpotent matrix with λ on the superdiagonal and zeros elsewhere. The problem is to show that exp(T) = I + K where T is the sum of (-1)^{m-1}/m K^m from m=1 to n-1.\n\nAssumptions need to be listed one by one, each addressing one property applied to one object. So let's extract the assumptions from the problem:\n\n1. K is an n×n matrix.\n2. K has 0s on the diagonal.\n3. K has λ on the first superdiagonal (entries (i, i+1) are λ for i=1 to n-1).\n4. All other entries of K are 0.\n5. K is nilpotent (which follows from the structure, as it's a Jordan block with zeros on the diagonal).\n6. T is defined as the sum from m=1 to n-1 of [(-1)^{m-1}/m K^m].\n7. The problem is to show that exp(T) = I + K.\n\nWait, but the problem statement as the user wrote is: \"We have the identity [...] exp(sum_{m=1}^{n-1} [(-1)^{m-1}/m K^m]) = I_n + K\". So the assumptions are about K being a specific nilpotent matrix, and then the problem is to prove that exponential of that sum equals I + K.\n\nSo, the assumptions are:\n\n- K is an n×n matrix.\n- K has entries 0 except on the first superdiagonal where they are λ.\n- λ is a complex number (since the context is complex matrices).\n- K is nilpotent of order n (since K^n = 0, as each power shifts the superdiagonal up).\n- T is the sum from m=1 to n-1 of [(-1)^{m-1}/m K^m].\n\nBut each assumption should be one line, one property. Let me structure that:\n\nAssumption:\nK is an n×n matrix over the complex numbers,\nK has zeros on the main diagonal,\nK has λ on the first superdiagonal entries (i.e., entries (i, i+1) equal to λ for 1 ≤ i ≤ n-1),\nAll other entries of K are zero,\nK is nilpotent (specifically, K^n = 0),\nT is defined as T = ∑_{m=1}^{n-1} [(-1)^{m-1}/m K^m].\n\nProblem:\nProve that exp(T) = I_n + K.\n\nBut wait, the user's question is more about the algebraic justification for why exp(log(I + K)) = I + K, where log is represented by that finite sum due to nilpotency. But in their specific problem statement, they mention for the matrix K as defined, exp(T) = I + K where T is the sum. So the problem is to show that the exponential of that particular sum T equals I + K.\n\nTherefore, the formatted problem should list all the assumptions about K and T, then the problem is to prove exp(T) = I + K.\n\nI need to ensure that each assumption is a single line, addressing one property. Let me check:\n\n- K is an n×n complex matrix. (Assumption about the size and field.)\n- K has zeros on the main diagonal. (Structure of K.)\n- K has λ on the first superdiagonal. (Non-zero entries' positions and value.)\n- All other entries of K are zero. (Completes the structure.)\n- K is nilpotent. (But this follows from the structure, so maybe it's redundant. However, the user might want to include it as an explicit assumption. Alternatively, since it's a consequence of the structure, perhaps it's not needed. But according to the example given, assumptions should list all conditions, even if some are implied. For instance, in the example, they included that n is an integer and n is divisible by 7, even though the original problem might not explicitly state it but inferred from context. So here, the user might need to include K being nilpotent as an assumption, even though it's structurally implied.)\n\nWait, but in the example, the original problem was to prove divisibility by 91 for every integer n, but the formatted problem added an assumption that n is divisible by 7. Wait, actually, looking at the example:\n\nOriginal problem: Prove that for every integer n, A(n) is divisible by 91.\n\nFormatted problem's assumption: n is an integer, n is divisible by 7.\n\nWait, that's different. The original problem says \"for every integer n\", but the formatted problem adds an assumption that n is divisible by 7. That seems like a mistake. Wait, maybe the user provided an example where they filtered out unrelated info. Wait, perhaps the original problem had a mistake, but in any case, the example shows that assumptions are listed line by line, each addressing one property. So perhaps in the current problem, even though K's nilpotency is implied by its structure, we should list it as an assumption. Alternatively, the user might have intended that the structure of K (zeros except λ on the superdiagonal) implies nilpotency, so maybe it's redundant. But to adhere to the example's style, perhaps we should include explicit assumptions.\n\nWait, in the example, the original problem says \"for every integer n\", but the formatted assumption adds \"n is an integer\" and \"n is divisible by 7\". But the original problem didn't mention divisibility by 7; perhaps that was part of the problem's actual hidden assumption. Wait, maybe the example is incorrect, but regardless, the instruction is to list all assumptions line by line, each addressing one property or condition applied to one object.\n\nIn the current problem, the matrix K is defined with 0s on the diagonal, λ on the superdiagonal, and zeros elsewhere. This structure makes K nilpotent (specifically, K^n = 0), so perhaps the nilpotency is a consequence and doesn't need to be listed as an assumption. But since the problem involves the exponential of T, which is a finite sum because K is nilpotent, maybe we should include the nilpotency as an assumption. Alternatively, since it's a consequence of K's structure, it's redundant. However, to be thorough, perhaps we should include it.\n\nBut the user's problem statement says: \"K is the matrix will all zero entries, except for entries λ^{-1} on the first superdiagonal\". Wait, no, in the problem statement the user is now considering K as per the specific form given, which is the matrix with λ on the superdiagonal. So given that K is upper triangular with zeros on the diagonal and λ on the superdiagonal, then K is nilpotent with K^n = 0. Therefore, the nilpotency is implied by the structure, so perhaps it's not an explicit assumption. However, the problem might require assuming that K is nilpotent, so to adhere to the example's structure, maybe we need to list it.\n\nAlternatively, the problem might not need to list it since it's a consequence. But the example included assumptions that were perhaps not all stated in the original problem but necessary for the formatted problem. Hmm, this is a bit confusing.\n\nLooking back at the example:\n\nOriginal problem: Prove that for every integer n, A(n) is divisible by 91.\n\nFormatted problem's assumptions: n is an integer, n is divisible by 7.\n\nWait, that seems like the formatted problem added an assumption that n is divisible by 7, which wasn't in the original problem. That suggests that perhaps the user (or the assistant) made a mistake in the example. Because the original problem says \"for every integer n\", but the formatted problem adds an assumption that n is divisible by 7. That would actually change the problem. So maybe the example is incorrect. But regardless, the instruction is to list all assumptions line by line.\n\nIn the current problem, the key assumptions are:\n\n1. K is an n×n matrix.\n2. K has zeros on the main diagonal.\n3. K has λ on the first superdiagonal (entries (i, i+1) = λ for 1 ≤ i ≤ n-1).\n4. All other entries of K are zero.\n5. T is defined as T = ∑_{m=1}^{n-1} [(-1)^{m-1}/m K^m].\n\nThe nilpotency of K is a consequence of its structure, so perhaps it's not listed as an assumption. Similarly, λ being a complex number is part of the context (as the matrices are over ℂ), so maybe that's an assumption as well.\n\nWait, the problem is set in the context of complex matrices, so perhaps we need to state that K is a complex matrix. Let me check the original problem statement:\n\n\"For all λ ∈ ℂ and all n×n square matrices K of the form [...]\"\n\nSo yes, λ is a complex number, and K is an n×n matrix over ℂ with the specified structure. Therefore, the assumptions should include:\n\n- K is an n×n complex matrix.\n- K has zeros on the main diagonal.\n- K has λ on the first superdiagonal entries.\n- All other entries of K are zero.\n- T is defined as T = ∑_{m=1}^{n-1} [(-1)^{m-1}/m K^m].\n\nAdditionally, since K is of that form, it's nilpotent, but that's a consequence. However, the problem's context might require assuming that K is nilpotent, but since it's structurally given, perhaps it's redundant. The example might have included redundant assumptions, so to follow that style, maybe we should include it. But given the example added an assumption not present in the original problem, perhaps we need to be cautious.\n\nAlternatively, maybe the key assumptions are just about the structure of K and the definition of T. The nilpotency follows from the structure, so it's not an assumption but a derived property. Therefore, the formatted assumptions would be:\n\nAssumption:\nK is an n×n complex matrix,\nK has zeros on the main diagonal,\nEach entry (i, i+1) of K is λ for 1 ≤ i ≤ n-1,\nAll other entries of K are zero,\nT is the sum from m=1 to n-1 of [(-1)^{m-1}/m K^m].\n\nProblem:\nProve that exp(T) = I_n + K.\n\nThis captures the necessary conditions. The nilpotency of K is implied by its structure (upper triangular with zero diagonal), so it's not an explicit assumption. The exponential here is the matrix exponential, which is defined as the sum of T^k /k! for k from 0 to infinity, but since T is nilpotent (as K is, and each term in T is a multiple of K^m, so T is also nilpotent), the series terminates at k = n-1.\n\nTherefore, the formatted problem should list the structure of K, the definition of T, and then the problem is to show exp(T) = I + K.",
    "Original_Problem": "Assumption: \n$K$ is an $n \\times n$ complex matrix,\n$K$ has zeros on the main diagonal,\nEach entry $(i, i+1)$ of $K$ is $\\lambda$ for $1 \\leq i \\leq n-1$,\nAll other entries of $K$ are zero,\n$T$ is defined as $T = \\sum_{m=1}^{n-1} \\frac{(-1)^{m-1}}{m} K^m$.\nProblem: \nProve that $\\exp(T) = I_n + K$.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $K$ is an $n \\times n$ complex matrix,\nAssumption 2: $K$ has zeros on the main diagonal,\nAssumption 3: Each entry $(i, i+1)$ of $K$ is $\\lambda$ for $1 \\leq i \\leq n-1$,\nAssumption 4: All other entries of $K$ are zero,\nAssumption 5: $T$ is defined as $T = \\sum_{m=1}^{n-1} \\frac{(-1)^{m-1}}{m} K^m$.\nProblem: \nProve that $\\exp(T) = I_n + K$.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$ \\sum_{n=1}^{\\infty} \\frac{1}{n!} c_{n,m} = \\begin{cases}\n1, & m = 1; \\\\\n0, & m \\geq 2.\n\\end{cases} $$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $K$ is an $n \\times n$ complex matrix,\nAssumption 2: $K$ has zeros on the main diagonal,\nAssumption 3: Each entry $(i, i+1)$ of $K$ is $\\lambda$ for $1 \\leq i \\leq n-1$,\nAssumption 4: All other entries of $K$ are zero,\nAssumption 5: $T$ is defined as $T = \\sum_{m=1}^{n-1} \\frac{(-1)^{m-1}}{m} K^m$.\nAssumption 6: $$ \\sum_{n=1}^{\\infty} \\frac{1}{n!} c_{n,m} = \\begin{cases}\n1, & m = 1; \\\\\n0, & m \\geq 2.\n\\end{cases} $$\nProblem: \nProve that $\\exp(T) = I_n + K$."
}