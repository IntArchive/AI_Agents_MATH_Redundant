{
    "Link_API": "https://api.stackexchange.com/2.3/questions/194123",
    "Title": "recurrence relation arising from Magic the Gathering scenario",
    "Score": 20,
    "Category": "Chứng minh",
    "Tags": "probability, recurrence-relations",
    "Link": "https://math.stackexchange.com/questions/194123/recurrence-relation-arising-from-magic-the-gathering-scenario",
    "Content": "Possible Duplicate: Probability of a random binary string containing a long run of 1s? EDIT : Cocopuffs below has partially answered the question, but the critical base case $L=2$ to his inductive argument is missing and it's not obvious how to fill the gap. This original problem is described in this thread at community.wizards.com. It originated as a question about a Magic: the Gathering scenario, but I will rephrase it here in general audience terms. Suppose you have \\$0, and your friend has \\$L. You start flipping coins. Every time you flip heads, you win \\$2 and your friend wins \\$1. Every time you flip tails, you lose all of your money. What is the probability you will eventually have (at least) as much money as your friend? As outlined in the thread above, the probability $p(L)$ of you eventually matching your friend is given by the recurrence relation $$p(L) = \\frac{1}{2^{L-1}} + \\sum_{i=1}^{L-1} \\frac{p(L+i)}{2^i}.$$ Other than the trivial observation that $p(L) = 1$ is a solution to this recurrence, I haven't been able to make headway. How do I prove this solution is unique (and therefore the right one)?",
    "AcceptedAnswer": "The solution is not the right one; in fact, you have a vanishingly small probability of ever catching your friend as $L$ becomes large. Let $X_{i}$ for $i=1,2,3,\\ldots$ be i.i.d. discrete random variables representing the lengths of your non-zero runs of heads.  (Note that there are a.s. infinitely many such runs.)  The probability distribution for each variable is $P[X=k]=2^{-k}$ for $k\\ge 1$.  So $P[X \\ge k]=2^{1-k},$ and $P[X<k]=1-2^{1-k}$.  After your $n$-th non-zero run of heads, you have $2X_n$ and your friend has $L+\\sum_{i=1}^{n}X_{i}$; you have as much money as your friend if\n$$\nX_{n}\\ge L + \\sum_{i=1}^{n-1}X_{i},\n$$\nwhich implies that $X_{n} \\ge L + (n-1)$.  That is, each time you flip at least one head and fail to catch your friend, your friend has at least one more dollar for you to match next time.  Therefore, the probability of success is at most $$\nP[X \\ge L] + P[X < L]P[X \\ge L+1]+P[X<L]^2P[X\\ge L+2] + ...,$$\nwhich is\n$$\nP[X\\ge L]\\left(1 + \\frac{1}{2}P[X<L]+\\frac{1}{4}P[X<L]^2+...\\right)=\\frac{P[X\\ge L]}{1-\\frac{1}{2}P[X<L]}=\\frac{2^{1-L}}{\\frac{1}{2}+\\frac{1}{2}2^{1-L}}=\\frac{2^{2-L}}{1+2^{1-L}}.\n$$\nFor $L=0$ or $L=1$, the probability of success is obviously $1$.  The above bound shows that the probability of success for $L=2$ is at most $2/3$, and that it decreases exponentially with $L$.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$L$ is a positive integer,\nYou start with \\$0,\nYour friend starts with \\$L,\nEach coin flip results in heads with probability $\\frac{1}{2}$,\nEach coin flip results in tails with probability $\\frac{1}{2}$,\nOn heads, you gain \\$2,\nOn heads, your friend gains \\$1,\nOn tails, you lose all your money,\nThe game ends when you have at least as much money as your friend,\nThe probability of eventual success is denoted by $p(L)$,\nThe recurrence relation for $p(L)$ is $$p(L) = \\frac{1}{2^{L-1}} + \\sum_{i=1}^{L-1} \\frac{p(L+i)}{2^i}.$$\nProblem: \nProve that $p(L) = 1$ is the unique solution to the recurrence relation.\n###",
    "reasoning_create_structured_problem": "Okay, let's tackle this problem. First, I need to understand what's being asked here. The user is talking about a recurrence relation that arises from a Magic: the Gathering scenario, which they've rephrased for a general audience. The setup is a gambling scenario where you start with $0, and your friend has $L. You flip coins: heads gives you $2 and your friend $1; tails makes you lose all your money. The question is the probability you'll eventually have at least as much as your friend. The recurrence relation given is p(L) = 1/(2^{L-1}) + sum_{i=1}^{L-1} p(L+i)/2^i. The user wants to prove that p(L) = 1 is the unique solution.\n\nWait, the example provided by the user had assumptions. Let me see. In their example, the original problem had an assumption that n is an integer and n is divisible by 7. Then the problem was to prove A(n) is divisible by 91. So the task here is to parse the given problem into Assumptions and Problem.\n\nLooking at the current problem, the user mentions that p(L) is defined by that recurrence relation, and they want to prove that p(L)=1 is the unique solution. The original scenario has certain conditions: starting with $0 vs. $L, each flip heads gives you +2, friend +1; tails you lose everything. The goal is to find the probability of eventually having at least as much as your friend. The recurrence relation is given, and they note that p(L)=1 is a solution, but they need to prove uniqueness.\n\nSo, to structure this into Assumptions and Problem sections. The Assumptions should list each condition applied to one object. Let's parse the problem step by step.\n\nAssumptions:\n\n1. You start with $0.\n2. Your friend starts with $L.\n3. Each coin flip is independent.\n4. Heads occurs with probability 1/2, giving you $2 and your friend $1.\n5. Tails occurs with probability 1/2, causing you to lose all your money.\n6. The process continues until you have at least as much money as your friend or indefinitely.\n7. The probability of eventually matching or exceeding your friend's money is p(L).\n8. The recurrence relation for p(L) is given as p(L) = 1/(2^{L-1}) + sum_{i=1}^{L-1} p(L+i)/2^i.\n\nEach of these is a separate assumption. But maybe some of these can be combined or phrased more precisely. Let me check:\n\n- The problem defines the scenario where you start with $0 and your friend with $L. So those are two separate assumptions about initial conditions.\n\n- The coin flip outcomes: each flip is heads or tails with probability 1/2 each. Heads gives you +2 and friend +1; tails makes you lose all your money. So each outcome's probability and effect should be separate assumptions.\n\n- The process continues until you reach or exceed your friend's money. So the stopping condition is when you have ≥ your friend's amount. If not, the game continues. However, the recurrence relation might implicitly handle this.\n\nWait, the recurrence relation is p(L) = 1/(2^{L-1}) + sum_{i=1}^{L-1} p(L+i)/2^i. Let me parse this. The 1/(2^{L-1}) term: where does that come from? Maybe if you flip heads L-1 times in a row, each time you get +2 and your friend +1. Starting from 0 vs L, after k heads, you have 2k and friend has L + k. So to reach at least the friend's amount, we need 2k ≥ L + k → k ≥ L. But L might not be an integer here? Wait, but the original problem is in dollars, so L is an integer. Wait, maybe not necessarily. The problem says \"Suppose you have $0, and your friend has $L.\" So L is a positive integer? The problem doesn't specify, but perhaps we can assume L is a positive integer. Alternatively, maybe L is any positive real number? But the recurrence uses sum from i=1 to L-1, implying L is an integer greater than 1. Because L-1 is the upper limit of the sum. So L must be an integer ≥1. Therefore, assumption: L is a positive integer.\n\nThat's an important point. So in the assumptions, we should list that L is a positive integer.\n\nSo possible assumptions:\n\n1. L is a positive integer.\n2. You start with $0.\n3. Your friend starts with $L.\n4. Each coin flip is independent with probability 1/2 for heads and 1/2 for tails.\n5. On heads, you gain $2 and your friend gains $1.\n6. On tails, you lose all your money.\n7. The game continues until you have at least as much money as your friend.\n8. The probability of eventual success starting from you having $0 and your friend having $L is p(L).\n9. The recurrence relation is p(L) = 1/(2^{L-1}) + sum_{i=1}^{L-1} p(L+i)/2^i for L ≥1.\n\nWait, but the recurrence might have a specific form. The term 1/(2^{L-1}) might correspond to a certain number of heads required immediately. Let's see: if you flip heads (L-1) times in a row, then each flip gives you 2 and friend 1. So after (L-1) heads, you have 2*(L-1) and your friend has L + (L-1) = 2L -1. Then 2*(L-1) = 2L -2, which is still less than the friend's 2L -1. So you need one more head. Wait, maybe not. Let me think again.\n\nWait, the initial problem says \"at least as much money as your friend\". So if you start at 0 vs L. Each heads gives you +2 and friend +1. So after k heads, your total is 2k, friend's total is L +k. So you need 2k ≥ L +k → k ≥ L. So you need k = L heads in a row. The probability of that is (1/2)^L. But in the recurrence, the term is 1/(2^{L-1}). Hmm, maybe the initial term is different.\n\nAlternatively, maybe the first term corresponds to the case where you flip tails on the first flip, but that would make you lose everything, which would end the game, but that's not contributing to success. So perhaps the 1/(2^{L-1}) term is the probability of some specific path to success. Alternatively, maybe the first term is the probability of immediately winning in the first step, but how?\n\nWait, let's parse the recurrence. The user says p(L) = 1/(2^{L-1}) + sum_{i=1}^{L-1} p(L+i)/2^i. So when you start with L, the probability is 1/(2^{L-1}) plus the sum over i=1 to L-1 of p(L+i)/2^i. This suggests that when you flip a coin, there's a certain probability of immediately winning (the 1/(2^{L-1}) term) and otherwise, depending on the flip, you transition to state L+i with some probability.\n\nBut I need to verify where the recurrence comes from. The user mentions that the recurrence is derived in the linked thread. Since I can't access the link, I need to infer.\n\nSuppose you start with 0 vs L. You flip a coin. If it's heads (prob 1/2), you get 2, friend gets 1, so now the gap is (L +1) - 2 = L -1. Wait, but that would mean your money is 2 and friend's is L +1. The new difference is L +1 - 2 = L -1. But the recurrence is in terms of p(L), so maybe after a head, the new L becomes L -1? Wait, not exactly. Wait, the problem is about the probability of reaching at least your friend's amount. So starting at difference L (you have 0, friend has L), each head reduces the difference by 1 (since you gain 2, friend gains 1: difference becomes L +1 -2 = L -1). Wait, but the difference is friend's money minus yours. Initially, it's L. After a head, it's (L +1) - 2 = L -1. After a tail, you lose everything, so the difference becomes (L +0) -0 = L, but since you have 0 again, but the friend's money has increased by 0. Wait, no: on a tail, you lose all your money, so your money is 0, but the friend's money doesn't change? Wait, original problem says \"Every time you flip heads, you win \\$2 and your friend wins \\$1. Every time you flip tails, you lose all of your money.\" So on tails, you lose your money, but the friend's money doesn't change. Wait, but the problem states \"your friend wins \\$1\" on heads. So on heads, both gain money; on tails, you lose yours, friend's remains the same?\n\nWait, the original problem says: \"Every time you flip heads, you win \\$2 and your friend wins \\$1. Every time you flip tails, you lose all of your money.\" So on heads, both gain: you +2, friend +1. On tails, you lose all your money (so your money becomes 0), and friend's money remains the same as before the flip. So, if you flip tails, your money resets to 0, and friend's money doesn't increase. Therefore, after a tail, the friend's money is still at the previous amount, and you're back to 0. Therefore, the difference (friend's money - your money) becomes friend's current amount - 0 = friend's previous amount + any gains from heads flips. Wait, but in the case of a tail, only your money is affected. So after a tail, you have 0, friend's money is whatever it was before the flip. So if you flipped a tail on the first try, your money is 0, friend's is still L. So you're back to the starting point. Therefore, the process could potentially loop indefinitely.\n\nBut the recurrence relation given is p(L) = 1/(2^{L-1}) + sum_{i=1}^{L-1} p(L+i)/2^i. That seems a bit non-intuitive. Let's try to derive it.\n\nWhen you start with 0 vs L, you flip a coin:\n\n- If it's heads (prob 1/2), you get 2, friend gets 1, so now you have 2 vs L+1. The difference is (L+1) - 2 = L -1. So the new L' would be L -1 +1? Wait, maybe not. Wait, the recurrence is in terms of L, which is the friend's money minus yours. Initially, you have 0, friend has L. After a head, you have 2, friend has L+1, so the new difference is (L+1) - 2 = L -1. So the new \"L\" in the recurrence would be L -1. But in the given recurrence, after a head, the state becomes L+i. That seems contradictory. Alternatively, maybe the index shifts differently.\n\nAlternatively, perhaps the recurrence is considering the number of heads required. For example, to reach at least your friend's amount, you need a certain number of consecutive heads. The term 1/(2^{L-1}) might be the probability of getting L-1 heads in a row, but that still wouldn't be enough. Wait, earlier calculation shows that to reach at least your friend's amount, you need k heads such that 2k ≥ L +k → k ≥ L. So you need L heads in a row. The probability of that is (1/2)^L. But the recurrence has 1/(2^{L-1}), which is different.\n\nAlternatively, maybe the 1/(2^{L-1}) term corresponds to the probability of winning immediately in some way. Let's consider when L=1. Then p(1) = 1/(2^{0}) + sum_{i=1}^{0} ... which is just 1. So p(1)=1. For L=2, p(2)=1/2^{1} + sum_{i=1}^{1} p(3)/2^1 = 1/2 + p(3)/2. But if p(L)=1 for all L, then this would give p(2)=1/2 +1/2=1, which holds. But if there's another solution, how?\n\nThe user says that p(L)=1 is a solution and wants to prove it's unique. So the assumptions should include the recurrence relation as given and the context of the problem.\n\nNow, back to structuring the problem. The assumptions should list each condition. Let me try:\n\nAssumption:\n\n1. You start with $0.\n2. Your friend starts with $L.\n3. Each coin flip is heads with probability 1/2 and tails with probability 1/2.\n4. On heads, you gain $2 and your friend gains $1.\n5. On tails, you lose all your money.\n6. The game continues until you have at least as much money as your friend.\n7. The probability of eventually matching or exceeding your friend's money is p(L).\n8. The recurrence relation for p(L) is given by p(L) = 1/(2^{L-1}) + sum_{i=1}^{L-1} p(L+i)/2^i.\n\nEach of these is a separate line. However, some of these can be merged. For example, points 3,4,5 are about the coin flip outcomes and their effects. But according to the example, each assumption should address only one property or condition applied to one object. So perhaps:\n\n- Each coin flip is independent.\n- Each coin flip results in heads with probability 1/2.\n- Each coin flip results in tails with probability 1/2.\n- On a heads result, you gain $2.\n- On a heads result, your friend gains $1.\n- On a tails result, you lose all your money.\n- The game ends when your money is at least your friend's money.\n- p(L) is defined as the probability of eventually ending the game successfully.\n- The recurrence relation p(L) = 1/(2^{L-1}) + sum_{i=1}^{L-1} p(L+i)/2^i holds.\n\nBut that's getting too granular. The original example had two assumptions for the integer n and divisibility by 7. So here, we need to list each assumption. Let's see:\n\n1. L is a positive integer.\n2. You start with $0.\n3. Your friend starts with $L.\n4. Each coin flip is heads or tails with equal probability (1/2).\n5. On heads, you gain $2.\n6. On heads, your friend gains $1.\n7. On tails, you lose all your money.\n8. The game continues until you have at least as much money as your friend.\n9. The probability of eventual success is p(L).\n10. The recurrence relation for p(L) is p(L) = 1/(2^{L-1}) + sum_{i=1}^{L-1} p(L+i)/2^i.\n\nEach of these is a single condition applied to one object. However, some might be combined. For example, 5 and 6 both happen on heads, but they are separate effects on different objects (you and your friend). Similarly, tails affects you only. The recurrence is a separate assumption.\n\nBut the problem statement from the user already includes the recurrence relation as part of the problem. So the assumptions should capture all the given conditions leading to the recurrence and the problem.\n\nThe user's problem is to prove that p(L)=1 is the unique solution to the recurrence. So the problem statement is: \"Prove that p(L) = 1 is the unique solution to the recurrence relation.\"\n\nBut in the example, the problem was stated as \"Prove that A(n) is divisible by 91.\" Here, the problem is to prove that p(L)=1 is the unique solution.\n\nSo putting it all together:\n\nAssumption:\n- L is a positive integer,\n- You start with $0,\n- Your friend starts with $L,\n- Each coin flip results in heads with probability 1/2,\n- Each coin flip results in tails with probability 1/2,\n- On heads, you gain $2,\n- On heads, your friend gains $1,\n- On tails, you lose all your money,\n- The game ends when you have at least as much money as your friend,\n- The probability of eventual success is p(L),\n- The recurrence relation is p(L) = 1/(2^{L-1}) + Σ_{i=1}^{L-1} p(L+i)/2^i.\n\nProblem:\nProve that p(L) = 1 is the unique solution to the recurrence relation.\n\nWait, but in the example, they included only the essential assumptions. Here, maybe some of these are redundant or can be phrased more concisely. For instance, the coin flip probabilities: heads and tails each have 1/2 chance. So instead of two separate assumptions, it can be one: \"Each coin flip is heads or tails with probability 1/2 each.\" But according to the example's structure, each assumption should be a single line addressing one property. So perhaps:\n\nAssumption:\n- L is a positive integer,\n- You have $0 initially,\n- Your friend has $L initially,\n- Each coin flip is independent,\n- Each coin flip has probability 1/2 of resulting in heads,\n- Each coin flip has probability 1/2 of resulting in tails,\n- On a heads result, you gain $2,\n- On a heads result, your friend gains $1,\n- On a tails result, you lose all your money,\n- The process continues until you have at least as much money as your friend,\n- The probability of eventual success is given by p(L),\n- The recurrence relation for p(L) is p(L) = 1/(2^{L-1}) + Σ_{i=1}^{L-1} p(L+i)/2^i.\n\nProblem:\nProve that p(L) = 1 is the unique solution to the recurrence relation.\n\nBut maybe some of these can be consolidated. For example, the initial conditions (you start with $0, friend with $L) can be one assumption each. The coin flip probabilities: perhaps two assumptions (heads and tails probabilities), but since they're complementary, maybe it's one assumption. However, the example split \"n is an integer\" and \"n is divisible by 7\" into two separate lines, even though both are about n. So following that, each atomic condition should be a separate line.\n\nAlso, the problem mentions that the recurrence arises from the Magic: the Gathering scenario, so the assumptions should capture the scenario's rules leading to the recurrence. Therefore, all the game rules and the definition of p(L) are necessary assumptions.\n\nAnother point: the recurrence relation might implicitly assume that L is a positive integer because the sum is from i=1 to L-1. So L must be at least 2 for the sum to have terms, but when L=1, the sum is from 1 to 0, which is empty. Hence, the assumption that L is a positive integer is crucial.\n\nIn the example, the assumptions included both that n is an integer and that it's divisible by 7. Here, L being a positive integer is a key assumption.\n\nSo, structuring the assumptions line by line:\n\nAssumption:\n- L is a positive integer,\n- You start with $0,\n- Your friend starts with $L,\n- Each coin flip is heads or tails with equal probability (1/2),\n- On heads, you gain $2,\n- On heads, your friend gains $1,\n- On tails, you lose all your money,\n- The game ends when you have at least as much money as your friend,\n- The probability of eventual success is p(L),\n- The recurrence relation for p(L) is p(L) = 1/(2^{L-1}) + Σ_{i=1}^{L-1} p(L+i)/2^i.\n\nProblem:\nProve that p(L) = 1 is the unique solution to the recurrence relation.\n\nThis seems comprehensive. Each assumption is a single line, addressing one property. The problem is to prove uniqueness of the solution p(L)=1.",
    "Original_Problem": "Assumption: \n$L$ is a positive integer,\nYou start with \\$0,\nYour friend starts with \\$L,\nEach coin flip results in heads with probability $\\frac{1}{2}$,\nEach coin flip results in tails with probability $\\frac{1}{2}$,\nOn heads, you gain \\$2,\nOn heads, your friend gains \\$1,\nOn tails, you lose all your money,\nThe game ends when you have at least as much money as your friend,\nThe probability of eventual success is denoted by $p(L)$,\nThe recurrence relation for $p(L)$ is $$p(L) = \\frac{1}{2^{L-1}} + \\sum_{i=1}^{L-1} \\frac{p(L+i)}{2^i}.$$\nProblem: \nProve that $p(L) = 1$ is the unique solution to the recurrence relation.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $L$ is a positive integer,\nAssumption 2: You start with \\$0,\nAssumption 3: Your friend starts with \\$L,\nAssumption 4: Each coin flip results in heads with probability $\\frac{1}{2}$,\nAssumption 5: Each coin flip results in tails with probability $\\frac{1}{2}$,\nAssumption 6: On heads, you gain \\$2,\nAssumption 7: On heads, your friend gains \\$1,\nAssumption 8: On tails, you lose all your money,\nAssumption 9: The game ends when you have at least as much money as your friend,\nAssumption 10: The probability of eventual success is denoted by $p(L)$,\nAssumption 11: The recurrence relation for $p(L)$ is $$p(L) = \\frac{1}{2^{L-1}} + \\sum_{i=1}^{L-1} \\frac{p(L+i)}{2^i}.$$\nProblem: \nProve that $p(L) = 1$ is the unique solution to the recurrence relation.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$\nP[X \\ge L] + P[X < L]P[X \\ge L+1]+P[X<L]^2P[X\\ge L+2] + ...,$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $L$ is a positive integer,\nAssumption 2: You start with \\$0,\nAssumption 3: Your friend starts with \\$L,\nAssumption 4: Each coin flip results in heads with probability $\\frac{1}{2}$,\nAssumption 5: Each coin flip results in tails with probability $\\frac{1}{2}$,\nAssumption 6: On heads, you gain \\$2,\nAssumption 7: On heads, your friend gains \\$1,\nAssumption 8: On tails, you lose all your money,\nAssumption 9: The game ends when you have at least as much money as your friend,\nAssumption 10: The probability of eventual success is denoted by $p(L)$,\nAssumption 11: The recurrence relation for $p(L)$ is $$p(L) = \\frac{1}{2^{L-1}} + \\sum_{i=1}^{L-1} \\frac{p(L+i)}{2^i}.$$\nAssumption 12: $$\nP[X \\ge L] + P[X < L]P[X \\ge L+1]+P[X<L]^2P[X\\ge L+2] + ...,$$\nProblem: \nProve that $p(L) = 1$ is the unique solution to the recurrence relation."
}