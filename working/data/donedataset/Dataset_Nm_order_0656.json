{
    "Link_API": "https://api.stackexchange.com/2.3/questions/476899",
    "Title": "Linear independence of the numbers $\\{1,e,e^2,e^3\\}$",
    "Score": 30,
    "Category": "Chứng minh",
    "Tags": "number-theory, reference-request, irrational-numbers, transcendental-numbers",
    "Link": "https://math.stackexchange.com/questions/476899/linear-independence-of-the-numbers-1-e-e2-e3",
    "Content": "Does someone know a proof that $\\{1,e,e^2,e^3\\}$  is linearly independent over $\\mathbb{Q}$? The proof should not use that $e$ is transcendental. $e:$ Euler's number. $\\{1,e,e^2\\}$  is linearly independent over $\\mathbb{Q}$ Any hints would be appreciated.",
    "AcceptedAnswer": "Since I've spent enough time thinking about this, yet not getting a proof, I might as well show what I've got. Others can comment on whether or not more can be done. Your problem is solved if you can show that for any integers $a, b, c$, we have $$\\sum^\\infty_{n=0} \\frac{1}{n!} (a + b 2^n + c 3^n)$$ irrational (using taylor series). WLOG, assume $c>0$. Pick $N$ large so that $(a+b2^n+c3^n) > 0$ for all $N \\geq 0$. Then our problem is equivalent to showing that the series with strictly positive terms\n$$\\sum^\\infty_{n=N} \\frac{1}{n!} (a + b 2^n + c 3^n)$$\nis irrational. Suppose it was not and equal to $p/q$. Now we try to mimic the proof of irrationality of $e$. Define $$x = q!\\left(\\frac{p}{q} - \\sum_{n=N}^{q} \\frac{1}{n!} (a + b 2^n + c 3^n) \\right).$$ One easily sees by distributing that it is an integer, and because our original series contains only positive terms, $x>0$. Note that we can also write \n$$x = \\sum_{n=q+1}^\\infty \\frac{q!}{n!} (a + b 2^n + c 3^n).$$ Now if $b=c=0$, then using $q!/n! < 1/(q+1)^{n-q}$ gives a geometric series bound that gives $x < 1/q$. Then we can get $x<1$ which is a contradiction that $x$ is an integer. The terms $2^n$ and $3^n$ grow too fast for this same trick to work. You'd get bounds of $2^q/q$ and $3^q/q$ respectively. Since  $q!/n! < 1/(q+1)^(n-q)$  is not tight, it is still possible that we can get our sum under 1. Or maybe we can monkey with our original definition for $x$. I think what really needs to be copied are proofs of the irrationality of $e^2$ and $e^3$, but I am not aware of such proofs. Googling, I found a very algebraic proof of the irrationality of $e^2$, but I didn't read it carefully. This suggests proofs of the irrationality of $e^2$ may not easily generalize, and hence you aren't really proving that $e$ is transcendental at the same time.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$1$, $e$, $e^2$ are linearly independent over $\\mathbb{Q}$,\nThe problem does not use the transcendence of $e$.\nProblem: \nProve that $\\{1, e, e^2, e^3\\}$ is linearly independent over $\\mathbb{Q}$.\n###END_OF_FORMAT###",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem. The user wants to prove that the set {1, e, e², e³} is linearly independent over the rationals, ℚ, without using the fact that e is transcendental. They mention that {1, e, e²} is already known to be linearly independent, so maybe I can build on that.\n\nFirst, let's recall what linear independence means. A set of elements {v₁, v₂, ..., vₙ} in a vector space over a field (here, the field is ℚ) is linearly independent if the only way a linear combination a₁v₁ + a₂v₂ + ... + aₙvₙ = 0 (with coefficients aᵢ in ℚ) is when all aᵢ are zero. So, we need to show that if there are rational numbers a, b, c, d such that a*1 + b*e + c*e² + d*e³ = 0, then a = b = c = d = 0.\n\nThe problem states not to use that e is transcendental. If e were transcendental, then by definition it's not a root of any non-zero polynomial with rational coefficients, which immediately implies that {1, e, e², e³} are linearly independent. But since we can't use that, we need another approach.\n\nThey also mention that {1, e, e²} is linearly independent. So maybe we can use induction or some properties of linear algebra. Suppose, for contradiction, that there's a non-trivial linear combination of 1, e, e², e³ over ℚ. That is, there exist rationals a, b, c, d not all zero such that a + b e + c e² + d e³ = 0.\n\nBut if such a relation exists, then e would satisfy a cubic equation with rational coefficients. However, proving that e doesn't satisfy any cubic equation over ℚ without invoking transcendence might be tricky. Maybe there's a known result about the linear independence of powers of e. Wait, but the user already knows that {1, e, e²} is independent. So perhaps we can use some theorem or lemma about extending linear independence to higher powers?\n\nAlternatively, maybe using calculus or integrals. Sometimes, proofs involving e use its properties related to integrals or series. For example, suppose we assume such a linear combination exists, then multiply both sides by some integrating factor or integrate from 0 to 1, but I'm not sure how that would work here.\n\nAnother approach: Use the fact that e is irrational and more. But we already know that {1, e, e²} are independent. Suppose we have a relation d e³ = - (a + b e + c e²). Then e³ would be expressed as a rational combination of 1, e, e². If we could show that e³ cannot be written in such a way, that would suffice. But how?\n\nMaybe using continued fractions or approximations. But I'm not familiar with specific approximations of e³ that would help here. Alternatively, consider differentiating both sides of the equation, but since the equation is algebraic, differentiation might not help unless we have a functional equation.\n\nWait, perhaps using the Taylor series expansion of e. Since e is the sum of 1/n! from n=0 to infinity. Suppose we substitute the series into the equation a + b e + c e² + d e³ = 0 and try to equate coefficients. But that seems complicated because multiplying series would give a convolution of coefficients. Maybe not straightforward.\n\nAlternatively, consider integer coefficients. Since the equation is over ℚ, we can clear denominators and assume a, b, c, d are integers. Then, perhaps use some estimates of the terms. For example, if a + b e + c e² + d e³ = 0, then |d e³| = |a + b e + c e²|. If we can bound the right-hand side and show that it's smaller than the left-hand side for integers a, b, c, d not all zero, that might lead to a contradiction. But this requires careful analysis.\n\nAlternatively, use the fact that e is a limit of (1 + 1/n)^n as n approaches infinity. Maybe approximate e with this sequence and plug it into the equation, then take limits. However, this approach might not directly lead to a contradiction unless we can show that the approximation can't satisfy the equation for large n.\n\nAlternatively, use linear algebra. If we have {1, e, e²} linearly independent, but adding e³ makes them dependent, then e³ would be in the span of {1, e, e²}. If we can somehow show that this is impossible, perhaps by considering properties of e. But again, without transcendence, this is not obvious.\n\nWait, maybe using the Lindemann-Weierstrass theorem, which states that if α₁, ..., αₙ are distinct algebraic numbers, then e^{α₁}, ..., e^{αₙ} are linearly independent over the algebraic numbers. But e is transcendental, so this theorem might not apply here directly, and also using Lindemann-Weierstrass would probably be circular since it's used to prove transcendence.\n\nHmm. The user wants a proof that doesn't use the transcendence of e. Maybe there's a known proof using linear algebra or calculus. Alternatively, consider using simultaneous approximations or rational approximations to e.\n\nAlternatively, use the fact that e can be represented as a continued fraction, but its continued fraction is non-repeating and infinite, which might not help directly.\n\nWait, here's another idea. Suppose there exists a non-trivial relation a + b e + c e² + d e³ = 0. Then, we can write this as a cubic equation in e: d e³ + c e² + b e + a = 0. If we can show that no such cubic equation with rational coefficients has e as a root, then we're done. But how to show this without invoking transcendence? Maybe by using the known proofs that e is irrational or that e is not algebraic of degree 3.\n\nBut the standard proof that e is transcendental is via the Lindemann-Weierstrass theorem, which is probably what they want to avoid. Alternatively, there's a proof by Fourier that e is irrational, and later proofs showing it's not algebraic of certain degrees. Maybe there's a specific proof for cubic equations.\n\nI recall that there's a theorem by Liouville that provides a criterion for transcendence via rational approximations, but applying that here might be complicated. Alternatively, maybe use Niven's proof for the transcendence of e, but simplified for the cubic case. However, that might still be too involved.\n\nAlternatively, use calculus. Suppose such a relation exists. Then, we can differentiate both sides multiple times. For example, differentiating the equation d e³ + c e² + b e + a = 0 gives 3d e² + 2c e + b = 0. Differentiating again gives 6d e + 2c = 0, and once more gives 6d = 0. Then, from 6d = 0, we get d = 0. Then substituting back, 2c = 0 => c=0, then b=0, then a=0. So this would show that the only solution is trivial. Wait, but does this work?\n\nWait, differentiation of a polynomial equation in e? But e is a constant, so differentiating with respect to what? If the equation holds for all x, but here e is a specific constant. So maybe this approach isn't valid. Because if we have an identity like a + b e + c e² + d e³ = 0, differentiating both sides with respect to some variable x wouldn't make sense because there are no variables here; it's just a constant equation. So differentiating might not be applicable here.\n\nHmm, so that approach doesn't work. Let me think again.\n\nSuppose we have a + b e + c e² + d e³ = 0 with a, b, c, d rationals not all zero. Let's assume d ≠ 0 (otherwise, we'd have a relation among 1, e, e² which contradicts the given that they are linearly independent). Then, we can solve for e³: e³ = (-a/d) - (b/d) e - (c/d) e². Now, substitute this into higher powers of e. For example, e⁴ = e * e³ = e*(-a/d - b/d e - c/d e²) = -a/d e - b/d e² - c/d e³. But we can replace e³ with the expression above: -a/d e - b/d e² - c/d*(-a/d - b/d e - c/d e²). This gives an expression for e⁴ in terms of 1, e, e². Continuing this way, every higher power of e can be expressed in terms of 1, e, e². Therefore, if e³ is in the span of 1, e, e², then all higher powers would be too, which might lead to a contradiction if we can show that, say, e⁴ can't be expressed that way. But how?\n\nAlternatively, since e is the sum from n=0 to ∞ of 1/n!, maybe plug that into the equation and equate coefficients. Let's try expanding e, e², e³ as their series.\n\nLet’s write e = ∑_{k=0}^∞ 1/k! , e² = ∑_{k=0}^∞ (2^k)/k! , e³ = ∑_{k=0}^∞ (3^k)/k! .\n\nThen, the equation a + b e + c e² + d e³ = 0 becomes:\n\na + b ∑_{k=0}^∞ 1/k! + c ∑_{k=0}^∞ 2^k /k! + d ∑_{k=0}^∞ 3^k /k! = 0.\n\nIf we combine these series, we get:\n\na + ∑_{k=0}^∞ [b + c 2^k + d 3^k] /k! = 0.\n\nSince the series converges to zero, all coefficients must be zero. But the constant term (k=0) is a + b + c + d = 0. For k ≥ 1, the coefficients [b + c 2^k + d 3^k] = 0.\n\nBut this gives an infinite system of equations:\n\nFor each k ≥ 0,\n\nif k=0: a + b + c + d = 0,\n\nfor k ≥ 1: b + c 2^k + d 3^k = 0.\n\nAssuming a, b, c, d are rational numbers. If we can show that the only solution is a = b = c = d = 0, then we’re done.\n\nLet’s consider the equations for k=1, 2, 3, etc.\n\nFor k=1: b + 2c + 3d = 0,\n\nFor k=2: b + 4c + 9d = 0,\n\nFor k=3: b + 8c + 27d = 0,\n\nAnd so on.\n\nThis is a system of equations where each subsequent equation involves higher powers of 2 and 3. If we can show that this system only has the trivial solution, then the original linear combination must be trivial.\n\nLet’s take the first three equations (k=1,2,3) to form a system:\n\n1) b + 2c + 3d = 0,\n\n2) b + 4c + 9d = 0,\n\n3) b + 8c + 27d = 0.\n\nSubtracting equation 1 from equation 2: 2c + 6d = 0 ⇒ c + 3d = 0 ⇒ c = -3d.\n\nSubtracting equation 2 from equation 3: 4c + 18d = 0. Substitute c = -3d: 4*(-3d) + 18d = (-12d + 18d) = 6d = 0 ⇒ d = 0.\n\nThen c = -3d = 0, and from equation 1: b + 0 + 0 = 0 ⇒ b = 0.\n\nFrom the k=0 equation: a + 0 + 0 + 0 = 0 ⇒ a = 0.\n\nThus, the only solution is a = b = c = d = 0. Therefore, the system of equations derived from the series expansion implies that the coefficients must all be zero. Hence, {1, e, e², e³} are linearly independent over ℚ.\n\nBut wait, does this work? Because we considered only the first three equations (k=1,2,3) and got that a = b = c = d = 0. But there are infinitely many equations for k ≥ 1. However, if the system of equations for k=1,2,3 already forces a = b = c = d = 0, then the rest of the equations (k ≥4) will automatically be satisfied because the coefficients would all be zero. Therefore, this shows that the only possible solution is the trivial one.\n\nTherefore, the approach is to expand each e, e², e³ into their respective power series, combine them into a single series, and then equate the coefficients of each term 1/k! to zero, leading to an infinite system which can be truncated to a finite system (using k=1,2,3) that only has the trivial solution. This method doesn't rely on e being transcendental but rather on the properties of the power series and solving the resulting linear system.\n\nSo the key steps are:\n\n1. Express e, e², e³ as their power series expansions.\n\n2. Substitute these into the linear combination equation.\n\n3. Combine like terms to form a single power series equated to zero.\n\n4. Set the coefficients of each term in the series to zero, leading to equations for a, b, c, d.\n\n5. Show that the only solution to this system is the trivial one.\n\nThis seems like a valid approach without invoking transcendence. Therefore, the formatted problem would list the assumptions based on the question, and then present the problem accordingly.",
    "Original_Problem": "Assumption: \n$1$, $e$, $e^2$ are linearly independent over $\\mathbb{Q}$,\nThe problem does not use the transcendence of $e$.\nProblem: \nProve that $\\{1, e, e^2, e^3\\}$ is linearly independent over $\\mathbb{Q}$.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $1$, $e$, $e^2$ are linearly independent over $\\mathbb{Q}$,\nAssumption 2: The problem does not use the transcendence of $e$.\nProblem: \nProve that $\\{1, e, e^2, e^3\\}$ is linearly independent over $\\mathbb{Q}$.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$x = q!\\left(\\frac{p}{q} - \\sum_{n=N}^{q} \\frac{1}{n!} (a + b 2^n + c 3^n) \\right).$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $1$, $e$, $e^2$ are linearly independent over $\\mathbb{Q}$,\nAssumption 2: The problem does not use the transcendence of $e$.\nAssumption 3: $$x = q!\\left(\\frac{p}{q} - \\sum_{n=N}^{q} \\frac{1}{n!} (a + b 2^n + c 3^n) \\right).$$\nProblem: \nProve that $\\{1, e, e^2, e^3\\}$ is linearly independent over $\\mathbb{Q}$."
}