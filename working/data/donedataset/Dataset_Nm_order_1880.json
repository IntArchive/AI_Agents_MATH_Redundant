{
    "Link_API": "https://api.stackexchange.com/2.3/questions/1577274",
    "Title": "Formal proof of Lyapunov stability",
    "Score": 17,
    "Category": "Chứng minh",
    "Tags": "ordinary-differential-equations, dynamical-systems, stability-in-odes",
    "Link": "https://math.stackexchange.com/questions/1577274/formal-proof-of-lyapunov-stability",
    "Content": "I was trying to solve the question of AeT. on the (local) Lyapunov stability of the origin (non-hyperbolic equilibrium) for the dynamical system $$\\dot{x}=-4y+x^2,\\\\\\dot{y}=4x+y^2.\\tag{1}$$ The streamplot below indicates that this actually is true. Performing the change of variables to polar coordinates $x=r\\cos\\phi$ , $y=r\\sin\\phi$ and after some trigonometric manipulations we result in $$\\dot{r}=r^2(\\cos^3\\phi+\\sin^3\\phi)\\\\ \\dot{\\phi}=4+r\\cos \\phi \\sin\\phi(\\cos \\phi -\\sin \\phi )$$ From this set of equations I want to prove that if we start with sufficiently small $r$ then $r$ will remain bounded with very small variations over time. My intuitive approach: For very small $r$ $$\\dot{\\phi}\\approx 4$$ that yields $$\\phi(t)\\approx 4t +\\phi_0$$ If we replace in the $r$ dynamics we obtain $$\\dot{r}\\approx r^2\\left[\\cos^3(4t+\\phi_0)+\\sin^3(4t+\\phi_0)\\right]$$ Integrating over $[0,t]$ we obtain $$\\frac{1}{r_0}-\\frac{1}{r(t)}\\approx \\int_0^t{\\left[\\cos^3(4s+\\phi_0)+\\sin^3(4s+\\phi_0)\\right]ds}$$ The right hand side is a bounded function of time with absolute value bounded by $4\\pi$ since $$\\int_{t_0}^{t_0+2\\pi}{\\left[\\cos^3(4s+\\phi_0)+\\sin^3(4s+\\phi_0)\\right]ds}=0 \\quad \\forall t_0$$ Thus for very small $r_0$ it holds true that $r(t)\\approx r_0$ . I understand that the above analysis is at least incomplete (if not erroneous) and I would be glad if someone can provide a rigorous treatment on the problem. I think that a \"singular-perturbation like\" approach may be the solution (bounding $r$ by $\\epsilon$ ) and considering the comparison system to prove the global boundedness result but I haven't progressed much up to now.",
    "AcceptedAnswer": "There is another insight that could be given by streamplot. Two observations: 1) trajectories are suspiciously symmetric; 2) most of them look like closed trajectories. Therefore, it's not reasonable trying to find only Lyapunov function: Lyapunov function means some sort of dissipation near equilibrium, and here it looks more like that we have a family of closed trajectories around equilibrium point, i.e. some sort of conservation. To prove that we have closed trajectories we might use two concepts: first integral and equivariant system (system with symmetry) . Both methods can help proving that some integral curves are closed: first integral method utilizes the fact that integral curves lie on its level sets (and if some of them closed and don't contain equilibria, then integral curve is closed); equivariance in its simplest form utilizes symmetries like reflection. I tried to come up with first integral for this system, but I was unsuccessful. \nThen I decided to check the symmetry. I expected that symmetry will be generated by reflection w.r.t. line $y=-x$ and I wanted to check that. First, let's make the change of variables:\n$$ u = x + y, \\; v = x - y .$$\nThe system of ODEs for new variables looks like this:\n$$ \\dot{u} = 4v + \\frac{u^2+v^2}{2}, $$\n$$ \\dot{v} = u (v - 4). $$ I had a suspicion that mapping $(u, v) \\mapsto (-u, v)$ sends trajectories to trajectories. Let's check this. Suppose we have solution $(\\hat{u}(t), \\hat{v}(t))$; will $(-\\hat{u}(t), \\hat{v}(t))$ be the solution too? $$ \\frac{d}{dt} \\left ( -\\hat{u}(t) \\right )= -\\frac{d}{dt} \\left (\\hat{u}(t) \\right ) = - 4\\hat{v}(t) - \\frac{\\hat{u}^2(t)+\\hat{v}(t)^2}{2} \\neq \n 4\\hat{v}(t) + \\frac{(-\\hat{u}(t))^2+\\hat{v}(t)^2}{2} $$\n$$ \\frac{d}{dt} \\left ( \\hat{v}(t) \\right ) = \\hat{u}(t) (\\hat{v}(t) - 4)\n\\neq\n (-\\hat{u}(t) )\\cdot(\\hat{v}(t) - 4)\n. $$ Well, this simply means that $(u, v) \\mapsto (-u, v)$ isn't a symmetry of this system of ODEs. Euh. There's an annoying minus sign that spoils everything. Nor $(u, v) \\mapsto (-u, -v)$, nor $(u, v) \\mapsto (u, -v)$ won't fix it. At this moment I've remembered that there are also reversible systems . This suggests me to check whether mapping $(\\hat{u}(t), \\hat{v}(t)) \\mapsto (-\\hat{u}(-t), \\hat{v}(-t)$ sends trajectories to trajectories. And yeah, it sends :) What all this fuss was about? Why reversibility (the property, that $(-u(-t), v(-t))$ is also a solution when $(u(t), v(t))$ is a solution) helps here?\nLet me illustrate this: I think that image is pretty self-explanatory. From here follows that all trajectories that intersect $u=0$ twice are closed. It's not hard to show that trajectories in some neighbourhood of origin have this property. From this we conclude that origin is center equilibrium, which is Lyapunov stable but not asymptotically Lyapunov stable.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \nThe dynamical system is given by $\\dot{x} = -4y + x^2$, $\\dot{y} = 4x + y^2$,\nThe origin $(0,0)$ is a non-hyperbolic equilibrium point of the system,\nThe system is analyzed using polar coordinates $x = r\\cos\\phi$, $y = r\\sin\\phi$,\nThe polar coordinate dynamics are $\\dot{r} = r^2(\\cos^3\\phi + \\sin^3\\phi)$ and $\\dot{\\phi} = 4 + r\\cos\\phi\\sin\\phi(\\cos\\phi - \\sin\\phi)$,\nInitial conditions are such that the initial radius $r(0)$ is sufficiently small.\nProblem: \nProve that the origin is locally Lyapunov stable.\n###",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem step by step. So, the user is asking about proving the Lyapunov stability of the origin for the given dynamical system. The system is:\n\ndot x = -4y + x²\ndot y = 4x + y²\n\nFirst, I need to recall what Lyapunov stability means. If I remember correctly, an equilibrium point is Lyapunov stable if, for every neighborhood around it, solutions starting close enough stay within a neighborhood of the equilibrium point for all time. Since the origin is a non-hyperbolic equilibrium (the linearization has eigenvalues with zero real parts?), the standard linearization methods won't work here. So, we need to use other methods, maybe Lyapunov functions or something else.\n\nThe user mentioned they converted the system to polar coordinates. Let's check their equations. Starting with x = r cos φ and y = r sin φ. Then, the derivatives dot x and dot y can be expressed in terms of dot r and dot φ. The user derived:\n\ndot r = r² (cos³ φ + sin³ φ)\ndot φ = 4 + r cos φ sin φ (cos φ - sin φ)\n\nHmm, I should verify these equations. Let's recall that in polar coordinates:\n\ndot x = dot r cos φ - r sin φ dot φ\ndot y = dot r sin φ + r cos φ dot φ\n\nSo substituting into the original equations:\n\ndot r cos φ - r sin φ dot φ = -4 r sin φ + r² cos² φ\ndot r sin φ + r cos φ dot φ = 4 r cos φ + r² sin² φ\n\nNow, solve these two equations for dot r and dot φ. Let's multiply the first equation by cos φ and the second by sin φ and add them. Similarly, multiply the first by -sin φ and the second by cos φ and add to eliminate variables.\n\nAlternatively, maybe using the standard formula for converting to polar coordinates. The time derivative of r is (x dot x + y dot y)/r. Let's compute that:\n\nr dot r = x dot x + y dot y = x(-4y + x²) + y(4x + y²) = -4xy + x³ + 4xy + y³ = x³ + y³.\n\nTherefore, dot r = (x³ + y³)/r. Since x = r cos φ and y = r sin φ, this becomes r² (cos³ φ + sin³ φ), which matches the user's equation for dot r. Good.\n\nNow for the angular component. The time derivative of φ is (x dot y - y dot x)/r². Let's compute that:\n\nr² dot φ = x dot y - y dot x = x(4x + y²) - y(-4y + x²) = 4x² + x y² + 4y² - x² y.\n\nWait, let me compute this step by step:\n\nx dot y = x*(4x + y²) = 4x² + x y²\n\ny dot x = y*(-4y + x²) = -4y² + x² y\n\nSo, x dot y - y dot x = 4x² + x y² - (-4y² + x² y) = 4x² + x y² + 4y² - x² y\n\nFactor terms:\n\n= 4x² + 4y² + x y² - x² y\n\nFactor x y terms:\n\n= 4(x² + y²) + x y (y - x)\n\nBut x² + y² = r², so:\n\n= 4 r² + x y (y - x)\n\nDivide by r² to get dot φ:\n\ndot φ = 4 + (x y (y - x))/r²\n\nNow, x = r cos φ, y = r sin φ:\n\nx y = r² cos φ sin φ\n\n(y - x) = r (sin φ - cos φ)\n\nTherefore, (x y (y - x))/r² = [r² cos φ sin φ * r (sin φ - cos φ)] / r² = r cos φ sin φ (sin φ - cos φ)\n\nSo, dot φ = 4 + r cos φ sin φ (sin φ - cos φ) = 4 - r cos φ sin φ (cos φ - sin φ)\n\nWhich matches the user's equation for dot φ. So their equations are correct.\n\nThe user then approximates for very small r. So when r is very small, the term with r in dot φ becomes negligible, so dot φ ≈ 4. Therefore, φ(t) ≈ 4t + φ₀. Then substituting into the equation for dot r, they get:\n\ndot r ≈ r² [cos³(4t + φ₀) + sin³(4t + φ₀)]\n\nIntegrating this, they get 1/r₀ - 1/r(t) ≈ integral of [cos³(4s + φ₀) + sin³(4s + φ₀)] ds from 0 to t.\n\nThey note that over a period (since the integrand is periodic with period π/2, since the argument is 4s, so the period would be 2π/4 = π/2), the integral over a full period is zero. Therefore, the integral remains bounded, which implies that 1/r(t) is approximately 1/r₀ plus a bounded term. Hence, for small r₀, r(t) remains approximately r₀, so stays small. Therefore, the origin is stable.\n\nBut the user says their analysis is incomplete or erroneous and asks for a rigorous treatment. So, what's missing here?\n\nFirst, their approximation assumes that φ(t) ≈ 4t + φ₀, but in reality, dot φ has a term with r, so as r might grow (even slightly), could there be a feedback effect? For example, if r increases a bit, then the term in dot φ might become non-negligible, leading to a change in φ, which might affect the integral for r. So, the approximation assumes that r remains small, but we need to ensure that even with the small perturbation in φ, r doesn't grow.\n\nAlso, the integral of cos³ + sin³ over time. Let's check the integral. The user says that over any interval of length 2π, the integral is zero. Wait, but the period of cos³(4t) is π/2, since cos(4t) has period π/2, and cos³ would have the same period. So integrating over a period of π/2 would give zero. Let's compute the integral over 0 to π/2:\n\nLet’s compute ∫ cos³(4t) + sin³(4t) dt from 0 to π/2. Let’s make substitution u = 4t, so du = 4dt, so integral becomes (1/4) ∫ [cos³ u + sin³ u] du from 0 to 2π.\n\nBut integrating cos³ u over 0 to 2π is zero because it's an odd function over a symmetric interval. Similarly for sin³ u. So the integral over a period is zero. Therefore, the integral over any interval of length π/2 would be zero. Therefore, the integral in the user's approximation is bounded, because over each period it cancels out, so the integral grows like O(1) as t increases. Therefore, 1/r(t) ≈ 1/r₀ + O(1), so for small r₀, 1/r₀ dominates, so r(t) ≈ r₀ / (1 + r₀ O(1)) ≈ r₀ (1 - r₀ O(1)) which is still small. Hence, r remains small.\n\nBut to make this rigorous, we need to bound the integral and show that r(t) doesn't escape to infinity. Perhaps using a Lyapunov function or applying averaging theory. Alternatively, using a comparison theorem for differential equations.\n\nAlternatively, use a Lyapunov function candidate. Let’s try that. Let’s consider V = r². Then, the derivative of V along trajectories is:\n\ndV/dt = 2r dot r = 2r * r² (cos³ φ + sin³ φ) = 2 r³ (cos³ φ + sin³ φ)\n\nBut cos³ φ + sin³ φ can be written as (cos φ + sin φ)(1 - cos φ sin φ). But not sure if that helps. Alternatively, note that |cos³ φ + sin³ φ| ≤ |cos φ|³ + |sin φ|³ ≤ 2, since each term is at most 1. So |dV/dt| ≤ 2 r³ * 2 = 4 r³. So dV/dt is O(r³). But V is r², so dV/dt ≤ 4 r³ = 4 V^(3/2). This is a differential inequality. Let’s see:\n\nIf dV/dt ≤ 4 V^(3/2), then we can separate variables:\n\ndV / V^(3/2) ≤ 4 dt\n\nIntegrate both sides:\n\n-2 / sqrt(V) ≤ 4 t + C\n\nWhich implies that sqrt(V) ≥ 1 / (-2 t - C/2). But this seems problematic as t increases, unless we have a bound from below. Wait, maybe integrating from t=0:\n\nAt t=0, V(0) = r₀².\n\nIntegrate from V₀ to V(t):\n\n∫_{V₀}^{V(t)} V^{-3/2} dV ≤ ∫_{0}^{t} 4 dt\n\nLeft integral: [-2 V^{-1/2}]_{V₀}^{V(t)} = -2 (V(t)^{-1/2} - V₀^{-1/2}) ≤ 4 t\n\nRearranged:\n\n-2 V(t)^{-1/2} + 2 V₀^{-1/2} ≤ 4 t\n\nMultiply both sides by -1/2 (inequality reverses):\n\nV(t)^{-1/2} - V₀^{-1/2} ≥ -2 t\n\nSo:\n\nV(t)^{-1/2} ≥ V₀^{-1/2} - 2 t\n\nWhich can be rewritten as:\n\nsqrt(V(t)) ≤ 1 / (1/sqrt(V₀) - 2 t)\n\nBut this gives a maximum time before the denominator becomes zero, which would be at t = 1/(2 sqrt(V₀)). But this suggests that V(t) doesn't blow up before that time, but for t approaching 1/(2 sqrt(V₀)), the bound goes to infinity. However, this is only an upper bound. If we want to show that V(t) remains small for all time, given V₀ is small, we need a different approach.\n\nAlternatively, maybe using Grönwall's inequality. Since dV/dt ≤ 4 V^{3/2}, which is a nonlinear ODE. Let's see, if V is small, then V^{3/2} is much smaller than V. For small V, the growth rate is very small. Let's suppose that V(t) is small for all time. Let's assume that V(t) ≤ 2 V₀ for t ≥ 0. Then, dV/dt ≤ 4 (2 V₀)^{3/2} = 4 * 2^{3/2} V₀^{3/2}. Then, integrating, V(t) ≤ V₀ + 4 * 2^{3/2} V₀^{3/2} t. For V(t) to remain ≤ 2 V₀, we need 4 * 2^{3/2} V₀^{3/2} t ≤ V₀. So, t ≤ V₀ / (4 * 2^{3/2} V₀^{3/2}) ) = 1 / (4 * 2^{3/2} V₀^{1/2}) ). But this gives a finite time, so maybe this approach isn't sufficient.\n\nAlternatively, consider that for small r, the term r² (cos³ φ + sin³ φ) is very small, so dot r is very small, so r doesn't change much. If we can show that r(t) stays within some bound for all time, given that r₀ is small enough. The user's approach suggests that since the integral of the fluctuating term is bounded, then 1/r(t) ≈ 1/r₀ + B(t), where |B(t)| ≤ C for some constant C. Hence, if r₀ is small enough that 1/r₀ - C > 0, then 1/r(t) ≥ 1/r₀ - C, so r(t) ≤ 1/(1/r₀ - C) ≈ r₀ / (1 - C r₀). If C r₀ < 1, then this is bounded. But as t increases, does B(t) stay bounded?\n\nYes, because the integral ∫ [cos³(4s) + sin³(4s)] ds from 0 to t is equal to (1/4) ∫ [cos³ u + sin³ u] du from 0 to 4t. Since the integrand is periodic with period π/2, over each period the integral is zero, so the integral over u is bounded. Let's compute the integral over one period:\n\nLet’s compute ∫ cos³ u + sin³ u du over 0 to 2π.\n\nBut ∫ cos³ u du from 0 to 2π is zero because it's an odd function over symmetric intervals. Similarly for sin³ u. So the integral over any interval of length 2π is zero. Therefore, the integral over u is bounded. Therefore, the integral from 0 to U is bounded by some constant C independent of U. Therefore, B(t) is bounded by C, so 1/r(t) ≥ 1/r₀ - C. Hence, if 1/r₀ - C > 0, i.e., r₀ < 1/C, then r(t) ≤ 1/(1/r₀ - C) ≤ 2 r₀, provided that C r₀ < 1/2. Therefore, choosing r₀ small enough ensures that r(t) remains bounded by 2 r₀, which can be made as small as desired. Hence, stability.\n\nBut this is still a bit heuristic. To make it rigorous, we can use the fact that the integral of a periodic function with zero average grows at most linearly, but in reality, it's bounded because the integral over each period is zero. Wait, no. If you have a function f(t) with period T, then ∫_{0}^{t} f(s) ds = N ∫_{0}^{T} f(s) ds + ∫_{0}^{t - NT} f(s) ds, where N is the integer part of t/T. If the integral over a period is zero, then the total integral is just the integral over the remaining part, which is bounded by the integral over one period. Therefore, the total integral is bounded by ∫_{0}^{T} |f(s)| ds, which is a constant. Therefore, the integral from 0 to t of f(s) ds is bounded by a constant C independent of t. Therefore, 1/r(t) ≈ 1/r₀ + C, so r(t) ≈ 1/(1/r₀ + C). Hence, as long as r₀ is small enough, 1/r₀ dominates, so r(t) remains small. Therefore, this suggests that r(t) is bounded, and thus the origin is stable.\n\nBut to formalize this, we need to set up the differential inequality properly. Let's consider the exact equation for r:\n\ndot r = r² (cos³ φ + sin³ φ)\n\nBut φ is not exactly 4t, but we have dot φ = 4 + r cos φ sin φ (cos φ - sin φ). Let’s denote the perturbation term as delta = r cos φ sin φ (cos φ - sin φ). So phi(t) = 4t + phi_0 + ∫ delta dt. However, since delta is of order r, which is small, then the deviation in phi from 4t is also small. Therefore, we can treat phi as approximately 4t + phi_0 with a small perturbation. But how does this affect the integral for r?\n\nPerhaps we can use a theorem from perturbation theory, such as averaging method, or use a Lyapunov function.\n\nAlternatively, consider the system as a perturbation of the case when r=0. When r=0, the system is dot phi = 4, dot r = 0. So, for r>0 but small, the perturbation is of order r. The averaging method suggests that over time, the average effect of the perturbation can be considered. However, since the average of cos³(4t) + sin³(4t) over a period is zero, the first-order averaging would suggest that r remains nearly constant. Therefore, the origin is stable.\n\nBut to make this rigorous, we might need to construct a Lyapunov function. Let’s try that. Suppose we define V(r) = r. Then, the derivative along trajectories is dot V = dot r = r² (cos³ φ + sin³ φ). Since |cos³ φ + sin³ φ| ≤ |cos φ|³ + |sin φ|³ ≤ 1 + 1 = 2. Therefore, |dot V| ≤ 2 r². So, dot V is of order r². If we can show that the integral of cos³ + sin³ over time doesn't accumulate, then V would not grow much. But since the average of cos³ + sin³ is zero, the integral doesn't have a secular term, hence V remains bounded.\n\nAlternatively, consider defining a Lyapunov function that incorporates the angle. For example, consider V = r + something depending on the angle to account for the oscillations. But this might be complicated.\n\nAlternatively, use the fact that the system is periodic in phi with period pi/2, and use a coordinate transformation to average out the angular dependence. The averaging theorem states that if the averaged system has a stable equilibrium, then so does the original system for small enough perturbations.\n\nThe averaged equation for r would be obtained by averaging the right-hand side of dot r over phi. Since the average of cos³ phi + sin³ phi over a period is zero, the averaged equation would be dot r_avg = 0. Therefore, the first-order approximation suggests that r does not change on average. However, to get stability, we need to look at higher-order terms. But since the original equation already has dot r = O(r²), which is higher order, maybe we need to consider second-order averaging. But this is getting complex.\n\nAnother approach: since the integral of cos³(4s) + sin³(4s) is bounded, then as per the user's approximation, 1/r(t) - 1/r₀ ≈ B(t), where |B(t)| ≤ C. Therefore, for small r₀, 1/r(t) ≈ 1/r₀, so r(t) ≈ r₀. Hence, for all t, |r(t) - r₀| ≤ C r₀². Therefore, if r₀ is small enough, r(t) remains within a small neighborhood of r₀, which implies stability.\n\nBut to formalize this, let's define 1/r(t) = 1/r₀ + B(t), then r(t) = 1/(1/r₀ + B(t)). If |B(t)| ≤ C, then as long as 1/r₀ > C, we have r(t) ≤ 1/(1/r₀ - C) = r₀ / (1 - C r₀). So, choosing r₀ < 1/(2C), then 1 - C r₀ > 1/2, so r(t) ≤ 2 r₀. Hence, for r₀ < epsilon/2, then r(t) ≤ epsilon. This shows Lyapunov stability.\n\nBut we need to ensure that B(t) is indeed bounded. Since B(t) = ∫₀ᵗ [cos³(4s + phi₀) + sin³(4s + phi₀)] ds. As discussed, this integral is bounded because the integrand has zero average over each period. Therefore, integrating over t gives a function that is bounded for all t. For example, integrating cos³(4s) over s gives (1/4) sin(4s) - (1/12) sin³(4s) evaluated from 0 to t, which is bounded. Similarly for sin³. Therefore, B(t) is bounded by some constant C independent of t. Therefore, the previous argument holds, and the origin is stable.\n\nHence, the user's approach is on the right track, but to make it rigorous, we need to bound the integral B(t) and show that it's uniformly bounded for all t, which it is due to the periodic zero-average integrand. Then, for sufficiently small r₀, r(t) remains bounded, hence the origin is Lyapunov stable.\n\nSo, the formatted problem should capture the key assumptions and the problem statement. Let's parse the original question:\n\nThe user wants to prove that the origin is locally Lyapunov stable for the system (1). They transformed to polar coordinates and obtained the equations for dot r and dot phi. Their approach uses a linear approximation for phi, leading to an approximate equation for r, and they want a rigorous proof.\n\nThe assumptions would include the dynamical system equations, the polar coordinate transformation, and the focus on small initial r. However, according to the example, each assumption should list one property or condition applied to one object.\n\nSo:\n\nAssumptions:\n- The dynamical system is given by $\\dot{x} = -4y + x^2$, $\\dot{y} = 4x + y^2$.\n- The origin $(0,0)$ is a non-hyperbolic equilibrium of the system.\n- The system is analyzed in polar coordinates $x = r\\cos\\phi$, $y = r\\sin\\phi$.\n- The time derivatives in polar coordinates are $\\dot{r} = r^2(\\cos^3\\phi + \\sin^3\\phi)$, $\\dot{\\phi} = 4 + r\\cos\\phi\\sin\\phi(\\cos\\phi - \\sin\\phi)$.\n- Initial conditions are such that $r(0)$ is sufficiently small.\n\nProblem: Prove that the origin is locally Lyapunov stable.\n\nWait, but in the example provided, the user filtered the original problem's assumptions. The original problem had the dynamical system, the transformation to polar coordinates, and the question about proving stability. So the formatted assumptions should list each condition or property. Let me check the example again.\n\nIn the example, the original problem had an assumption that n is an integer and divisible by 7, but in the formatted problem, the assumption lists \"n is an integer\" and \"n is divisible by 7\". Each in separate lines. So similarly here, each assumption is one condition.\n\nSo:\n\nAssumption:\n- The dynamical system is $\\dot{x} = -4y + x^2$, $\\dot{y} = 4x + y^2$.\n- The origin $(0,0)$ is an equilibrium point.\n- The system is converted to polar coordinates $x = r\\cos\\phi$, $y = r\\sin\\phi$.\n- The derived equations in polar coordinates are $\\dot{r} = r^2(\\cos^3\\phi + \\sin^3\\phi)$, $\\dot{\\phi} = 4 + r\\cos\\phi\\sin\\phi(\\cos\\phi - \\sin\\phi)$.\n- Initial radius $r(0)$ is sufficiently small.\n\nProblem: Prove that the origin is Lyapunov stable.\n\nBut the original question mentions it's non-hyperbolic, but maybe that's a property of the equilibrium, so perhaps:\n\nAssumption:\n- The dynamical system is $\\dot{x} = -4y + x^2$, $\\dot{y} = 4x + y^2$.\n- The origin $(0,0)$ is a non-hyperbolic equilibrium point.\n- The system is analyzed in polar coordinates $x = r\\cos\\phi$, $y = r\\sin\\phi$.\n- The time derivatives in polar coordinates are $\\dot{r} = r^2(\\cos^3\\phi + \\sin^3\\phi)$, $\\dot{\\phi} = 4 + r\\cos\\phi\\sin\\phi(\\cos\\phi - \\sin\\phi)$.\n- Initial conditions satisfy $r(0)$ sufficiently small.\n\nProblem: Prove that the origin is locally Lyapunov stable.\n\nYes, this captures the necessary assumptions and the problem.",
    "Original_Problem": "Assumption: \nThe dynamical system is given by $\\dot{x} = -4y + x^2$, $\\dot{y} = 4x + y^2$,\nThe origin $(0,0)$ is a non-hyperbolic equilibrium point of the system,\nThe system is analyzed using polar coordinates $x = r\\cos\\phi$, $y = r\\sin\\phi$,\nThe polar coordinate dynamics are $\\dot{r} = r^2(\\cos^3\\phi + \\sin^3\\phi)$ and $\\dot{\\phi} = 4 + r\\cos\\phi\\sin\\phi(\\cos\\phi - \\sin\\phi)$,\nInitial conditions are such that the initial radius $r(0)$ is sufficiently small.\nProblem: \nProve that the origin is locally Lyapunov stable.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: The dynamical system is given by $\\dot{x} = -4y + x^2$, $\\dot{y} = 4x + y^2$,\nAssumption 2: The origin $(0,0)$ is a non-hyperbolic equilibrium point of the system,\nAssumption 3: The system is analyzed using polar coordinates $x = r\\cos\\phi$, $y = r\\sin\\phi$,\nAssumption 4: The polar coordinate dynamics are $\\dot{r} = r^2(\\cos^3\\phi + \\sin^3\\phi)$ and $\\dot{\\phi} = 4 + r\\cos\\phi\\sin\\phi(\\cos\\phi - \\sin\\phi)$,\nAssumption 5: Initial conditions are such that the initial radius $r(0)$ is sufficiently small.\nProblem: \nProve that the origin is locally Lyapunov stable.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$ \\dot{v} = u (v - 4). $$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: The dynamical system is given by $\\dot{x} = -4y + x^2$, $\\dot{y} = 4x + y^2$,\nAssumption 2: The origin $(0,0)$ is a non-hyperbolic equilibrium point of the system,\nAssumption 3: The system is analyzed using polar coordinates $x = r\\cos\\phi$, $y = r\\sin\\phi$,\nAssumption 4: The polar coordinate dynamics are $\\dot{r} = r^2(\\cos^3\\phi + \\sin^3\\phi)$ and $\\dot{\\phi} = 4 + r\\cos\\phi\\sin\\phi(\\cos\\phi - \\sin\\phi)$,\nAssumption 5: Initial conditions are such that the initial radius $r(0)$ is sufficiently small.\nAssumption 6: $$ \\dot{v} = u (v - 4). $$\nProblem: \nProve that the origin is locally Lyapunov stable."
}