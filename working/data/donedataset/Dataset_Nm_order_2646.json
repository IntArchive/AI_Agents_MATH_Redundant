{
    "Link_API": "https://api.stackexchange.com/2.3/questions/119831",
    "Title": "How to prove that a bounded linear operator is compact?",
    "Score": 13,
    "Category": "Chứng minh",
    "Tags": "functional-analysis, compact-operators",
    "Link": "https://math.stackexchange.com/questions/119831/how-to-prove-that-a-bounded-linear-operator-is-compact",
    "Content": "I encountered a homework problem that says: If $A$ is a bounded linear operator from $X$ to $Y$. And $K$ is a compact operator from $X$ to $Y$, where $X$ and $Y$ are both Banach spaces, and Ran$(A)\\subset$ Ran$(K)$. Then $A$ is also a compact operator. I tried to use the definition of a compact operator to solve this one. (Indeed, the professor only covered the definition of compact operator in class and said that it would be enough for the homework problems.) Here's what I did. I started by choosing a bounded sequence $x_n$ in X and since A is bounded, $A(x_n)$ is also bounded. And from the assumption that $R(A)\\subset R(K)$, I conclude that there exist $y_n\\in X$, s.t. $K(y_n)=A(x_n)$. Now if I can somehow prove that $y_n$ is bounded in X, I can easily prove the problem by using the compactness of K. But this is exactly the place where I am stuck. Please help me out. Am I going along the right path? Also, I had another problem saying that: If X is infinitely dimensional and K is an compact operator and is one to one, then I-K must not be compact. I proved this one, but didn't really use the assumption that K is one to one. I looked over and over again but couldn't nd where I made the mistake. Here's what I did: Choose any sequence in X that is of norm 1. Then suppose I-K is compact. It follows there must exists a subsequence $x_{n_k}$ that $(I-K)(x_{n_k})$ converges. And since K is compact, there exists a sub-subsequence $x_{n_{k_j}}$ that $K(x_{n_{k_j}})$. Now I claim that in fact $x_{n_{k_j}}$ converges in X. Indeed, $x_{n_{k_j}}=(I-K)(x_{n_{k_j}})+K(x_{n_{k_j}})$. Hence, for any sequence on the unit sphere, I've found a subsequence that converges. This means the unit sphere is compact, which contradicts with X being infinitely dimensional. Did I do something wrong?",
    "AcceptedAnswer": "The following proof is adapted from Bruce Barnes, Majorization, range inclusion, and factorization for bounded linear operators . One maybe able to simplify the proof somewhat. Lemma Let $T,S\\in B(X,Y)$ and $R(T)\\subseteq R(S)$, then $\\exists M > 0$ such that for all $\\alpha\\in Y^*$,\n$$ \\|T^*\\alpha\\| \\leq M\\|S^*\\alpha\\| \\tag{1}$$\nwhere $*$ denotes the adjoint operator. Proof : Let $U$ be the map from $R(S^*) \\to X^*$ given by $U(S^*\\alpha) = T^*\\alpha$. This map is well-defined since the kernel of $S^*$ is contained in that of $T^*$. It suffices to show that $U$ is a bounded linear operator. Suppose not, then there exists a sequence $\\alpha_n$ in $Y^*$ such that $S^*\\alpha_n$ has norm 1 and $T^*\\alpha_n$ diverges. Now take an arbitrary $x\\in X$. By assumption there exists $z\\in X$ such that $Sz = Tx$. So \n$$ T^*\\alpha_n(x) = \\alpha_n(Tx) = \\alpha_n(Sz) = S^*\\alpha_n(z) $$\nand so \n$$ |T^*\\alpha_n(x)| \\leq \\|z\\| < \\infty$$\nfor each $n$. But by the Uniform Boundedness Principle we have that this implies\n$$ \\sup_n \\|T^*\\alpha_n\\| < \\infty $$\nand we get a contradiction. q.e.d. Now recall Schauder's Theorem (Dunford and Schwartz, Chapter VI.5, Theorem 2): An operator is compact if and only if its adjoint is compact. Corollary If in the previous lemma, $S$ is compact, then so is $T$. Proof : By Schauder's theorem we have that $S^*$ is compact. Since $T^* = US^*$, and $U$ is a bounded linear operator (with bounded linear extension to $R(S^*)$), we have that $T^*$ is a product of a bounded linear operator with a compact operator, and hence is compact. Appealing to Schauder's theorem again we conclude the proof. q.e.d.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$X$ and $Y$ are Banach spaces,\n$A$ is a bounded linear operator from $X$ to $Y$,\n$K$ is a compact operator from $X$ to $Y$,\nThe range of $A$ is contained in the range of $K$.\nProblem: \nProve that $A$ is a compact operator.\n\n---\n\nAssumption: \n$X$ is infinitely dimensional,\n$K$ is a compact operator from $X$ to $X$,\n$K$ is injective (one-to-one).\nProblem: \nProve that $I - K$ is not compact.\n###",
    "reasoning_create_structured_problem": "Okay, let me try to tackle this problem. So the user has two separate questions here. The first one is about proving that a bounded linear operator A is compact given that its range is contained within the range of a compact operator K. The second question is about showing that if K is a compact, one-to-one operator on an infinite-dimensional space, then I - K cannot be compact. Let me start with the first problem.\n\nFor the first problem: The user tried using the definition of compact operators. They took a bounded sequence x_n in X. Since A is bounded, A(x_n) is bounded. Then, because Ran(A) is in Ran(K), each A(x_n) can be written as K(y_n) for some y_n in X. The user wants to show y_n is bounded, which would allow them to use K's compactness to get a convergent subsequence of K(y_n), hence A(x_n) would have a convergent subsequence. But they're stuck on proving y_n is bounded. Maybe there's a theorem or property that if the range of A is contained in the range of K, then A factors through K? Like, there's a bounded operator B such that A = K B. If that's the case, then since K is compact and B is bounded, the composition would be compact. But how to show such a B exists? The user might need to use the open mapping theorem or some closed graph theorem here. Wait, but K is compact, which isn't necessarily surjective or invertible. Hmm. Alternatively, maybe the user can use the fact that if K is compact, then its range is a space where every bounded sequence has a convergent subsequence. But I'm not sure. Maybe the key is to use the closed graph theorem. Suppose we define a map from Ran(K) to X by sending K(y) to y, but that might not be well-defined unless K is injective. But the problem doesn't state that. So maybe that approach is stuck. Alternatively, since A is bounded and factors through K's range, perhaps the inverse of K (if it exists on the range) is bounded. But since K is compact and between Banach spaces, if it were injective, then its inverse wouldn't be bounded unless the space is finite-dimensional. So maybe this approach isn't working. Wait, but the user's approach was to take y_n such that K(y_n) = A(x_n). If they can show that y_n is bounded, then since K is compact, K(y_n) would have a convergent subsequence. But how to get y_n bounded? Maybe by using the bounded inverse theorem? If the restriction of K to some subspace is invertible, then the inverse would be bounded. But again, K's range might not be closed. Wait, but X and Y are Banach spaces. If K is compact, then its range is a Banach space only if it's finite-dimensional. But the problem doesn't specify that. Hmm. Maybe there's a different approach. Alternatively, if A is bounded and factors through K, then A is compact. But how to show the factorization? Maybe using the closed graph theorem. Suppose we define a map B: X → X such that K B = A. Let’s see: For each x in X, A x is in Ran(K), so there exists some y in X with K y = A x. If we can choose y in a linear and bounded way, then B x = y would be a bounded operator. To apply the closed graph theorem, suppose x_n → x in X, and B x_n → y in X. Then K B x_n = A x_n → A x, and K B x_n → K y. Therefore, K y = A x = K B x. But unless K is injective, we can't conclude y = B x. So maybe this approach requires K to be injective, which isn't given. Therefore, perhaps another way. Maybe using the fact that the image of a bounded operator under a compact operator is compact? Wait, no. Alternatively, perhaps the user's approach is missing a step. The key might be to use that the inclusion from Ran(K) to Y is compact, but since K is compact, the range is contained in a compact set. Wait, but in infinite dimensions, compact operators have ranges that are not closed unless finite-dimensional. Maybe another angle. Let me think. The problem states that X and Y are Banach spaces. The user wants to show A is compact. Since A is bounded and its range is inside the range of K, which is a compact operator. But even if Ran(A) is in Ran(K), since K is compact, the image of the unit ball under K is relatively compact. So if A maps bounded sequences to sequences inside a relatively compact set, then A should be compact. Wait, but A is a bounded operator. Wait, no. If A's range is within a compact set, then the image of the unit ball under A is contained in a compact set, hence precompact. Therefore, A would be compact. Wait, is that correct? If the range of A is contained in a compact set, then A is compact? Because compact operators are those that map bounded sets to relatively compact sets. So if A's range is inside a compact set, then the image of any bounded set is in a compact set, hence precompact. But in a compact set, every subset is precompact. Therefore, A would be compact. Wait, but the problem states that Ran(A) is a subset of Ran(K). However, Ran(K) is not necessarily compact, but K is a compact operator, so K maps bounded sets to relatively compact sets. But the entire range of K might not be compact. For example, the range could be infinite-dimensional, but in that case, the range cannot be closed. Wait, but even so, if A is a bounded operator with range inside Ran(K), then for any bounded sequence x_n, A x_n is in Ran(K), so there exists y_n with K y_n = A x_n. But the user's problem was that y_n might not be bounded. So maybe the step where you get y_n is where the issue is. But if A is bounded and K is compact, perhaps there's a way to bound y_n in terms of x_n. Suppose there's a constant C such that ||y_n|| ≤ C ||A x_n||. Since A is bounded, ||A x_n|| ≤ ||A|| ||x_n||. If x_n is bounded, then ||A x_n|| is bounded, hence ||y_n|| is bounded. But how to get such a C? That would require that K has a bounded inverse on its range. Which would be true if K is injective and has closed range. But K is compact, and if it's injective, then in infinite-dimensional spaces, its range cannot be closed, so the inverse isn't bounded. Therefore, maybe that's not the case. So the user's approach might be missing something. Maybe the problem needs an additional assumption, like K being injective or having closed range. But according to the problem statement, the only assumptions are that A is bounded, K is compact, and Ran(A) ⊂ Ran(K). So perhaps there's another approach. Maybe using the fact that if K is compact, then any operator that factors through K is compact. But to factor A as K composed with some other operator. If such an operator exists and is bounded, then A is compact. So the key is to show that there exists a bounded operator B: X → X such that K B = A. If that's possible, then since K is compact and B is bounded, K B is compact. But how to construct B? Since Ran(A) ⊂ Ran(K), for each x in X, there exists some y in X such that K y = A x. The problem is to choose y in a linear and bounded way. If the mapping from A x to y is linear and bounded, then B exists. But how to ensure that? This is similar to lifting operators through a quotient or something. Maybe using the open mapping theorem. Suppose we consider the restriction of K to a subspace. If K is surjective onto Ran(K), then by the open mapping theorem, if Ran(K) is a Banach space (which it is if it's closed), then K is open. But since K is compact, Ran(K) is not closed unless it's finite-dimensional. So maybe that's not applicable. Alternatively, since X is a Banach space and K is compact, the image of K is a quotient space modulo the kernel of K. But without knowing more about K's kernel, it's hard. Wait, but perhaps the user can use the closed graph theorem. Suppose we define B: X → X by B x = y where K y = A x. To check if B is bounded. Suppose x_n → x and B x_n → y. Then K B x_n = A x_n → A x, and K B x_n → K y. So A x = K y, which means that y = B x by definition. Hence, the graph is closed, so by the closed graph theorem, B is bounded. Therefore, A = K B is compact. Wait, but this requires that B is defined everywhere and linear. But how do we know B is linear? Because if for each x, we choose a y such that K y = A x, but there might be multiple y's (if K has a nontrivial kernel). So to make B linear, we need to choose y in a linear way, which requires selecting a specific y for each x, perhaps by using a linear selector. If K is injective, then y is unique, and B is linear. But if K is not injective, then we have to choose a linear section. This might require the axiom of choice, but in practice, in Banach spaces, you can use the Bartle-Graves theorem to get a continuous linear right inverse if K is surjective and has a complemented kernel. But we don't have surjectivity here. Hmm. This seems complicated. But the problem statement doesn't mention any other conditions, so maybe there's a simpler way. Alternatively, perhaps the user's initial approach is correct, and we can use the fact that if K is compact, then it's \"bounded below\" on some subspace. But I'm not sure. Alternatively, the key insight is that since K is compact, then any operator with range contained in Ran(K) is compact. But that doesn't sound right. For example, the identity operator on an infinite-dimensional space isn't compact, but if Ran(K) is the whole space (which can't happen for compact operators in infinite dimensions), but that's impossible. So I think the problem must be using the fact that A factors through K, and the closed graph theorem gives the boundedness of the factor, hence A is compact. Therefore, the user was on the right path, but needed to use the closed graph theorem to show that the mapping from A x to y is bounded. So, in conclusion, the first problem can be solved by defining B as above, proving it's bounded via closed graph theorem, hence A is compact.\n\nNow for the second problem: The user showed that if I - K is compact, then the unit sphere is compact, contradicting infinite dimensionality. But they didn't use the assumption that K is one-to-one. The user is worried they made a mistake. Let me check their steps. They took any sequence x_n in the unit sphere. Since I - K is compact, there's a subsequence x_{n_k} such that (I - K)x_{n_k} converges. Then, since K is compact, there's a sub-subsequence x_{n_{k_j}} such that K x_{n_{k_j}} converges. Then, they write x_{n_{k_j}} = (I - K)x_{n_{k_j}} + K x_{n_{k_j}}, which converges, so x_{n_{k_j}} converges. Hence, the unit sphere is compact, which is a contradiction. But where was the injectivity of K used? If K is not injective, then maybe I - K is not injective, but in the argument, the user didn't use that. Wait, maybe the mistake is in assuming that (I - K) being compact allows taking a convergent subsequence. Wait, compact operators map bounded sequences to those with convergent subsequences. So (I - K) is compact, hence (I - K)x_n has a convergent subsequence. Then K is compact, so Kx_n has a convergent subsubsequence. Then adding them gives x_n converging. Wait, but in the argument, they first take a subsequence for (I - K)x_{n_k} converging, then from that subsequence take a subsubsequence where Kx_{n_{k_j}} converges. Then x_{n_{k_j}} = (I - K)x_{n_{k_j}} + Kx_{n_{k_j}}} converges. Therefore, every bounded sequence has a convergent subsequence, so unit sphere is compact. But why is K being injective needed? Maybe because if K is not injective, then I - K could have finite-dimensional kernel or something, but in their proof, they didn't need injectivity. Wait, but perhaps the mistake is that (I - K) being compact doesn't necessarily allow you to extract such a subsequence unless you have additional properties. Wait, no. The logic is: Take any bounded sequence x_n. Then (I - K)x_n has a convergent subsequence. Then in that subsequence, Kx_n has a convergent subsubsequence. Then adding gives x_n convergent. Therefore, every bounded sequence has a convergent subsequence, hence the space is finite-dimensional. But the user's proof didn't use that K is injective. But the problem states that K is injective. So maybe there is a case where without K being injective, the argument fails. For example, suppose K is not injective. Then there exists some x ≠ 0 with Kx = 0. Then (I - K)x = x, so if we take a sequence x_n = x for all n, then (I - K)x_n = x, which is convergent. Then Kx_n = 0, so x_{n_{k_j}} = x + 0 = x, which converges. But in this case, the sequence x_n is just constant, so it converges. But this doesn't contradict anything. Wait, but the user is considering sequences in the unit sphere. If K is not injective, then there exists a non-trivial kernel. Take a sequence x_n in Ker(K) ∩ unit sphere. Then (I - K)x_n = x_n. So if we apply the argument: (I - K)x_n = x_n. Since I - K is compact, then x_n must have a convergent subsequence. But x_n is in the unit sphere, so the limit must have norm 1. But in infinite dimensions, the unit sphere is not compact, so this would lead to a contradiction even if K is not injective. Wait, but that suggests that the injectivity of K is not needed. So why does the problem state that K is injective? Maybe there's a flaw in the user's argument. Let me think. Suppose K is not injective. Then, in the user's proof, they take any sequence x_n in the unit sphere. Then (I - K)x_n has a convergent subsequence. Then Kx_n has a convergent subsubsequence. Then x_n = (I - K)x_n + Kx_n converges. Therefore, every sequence in the unit sphere has a convergent subsequence, which is impossible in infinite dimensions. So the conclusion holds even if K is not injective. But the problem says \"if K is a compact operator and is one to one, then I - K must not be compact\". But according to the user's proof, even if K is not injective, I - K cannot be compact. Therefore, the assumption that K is injective is redundant. Hence, the user must have made a mistake in their proof. Wait, but how? Because if K is not injective, then I - K might not be injective either. But the user's argument doesn't depend on K being injective. So the problem must have a mistake in its statement, or the user's proof is incorrect. Alternatively, maybe when K is injective, I - K cannot be compact, but when K is not injective, it's possible. Wait, but in the user's proof, they claim that if I - K is compact, then the unit sphere is compact, hence the space is finite-dimensional, regardless of K being injective. Therefore, the injectivity of K is not necessary. Therefore, the user's proof is correct, and the problem's assumption that K is injective is superfluous. Therefore, the user might have a mistake in their first problem but not the second. Wait, but the user is concerned because they didn't use the injectivity in their proof, but the problem statement requires it. So either the problem statement is incorrect, or the user's proof is missing something. Let me check again. Suppose K is not injective. Then there exists x ≠ 0 with Kx = 0. Then (I - K)x = x. If we take a sequence x_n = x/||x|| in the unit sphere. Then (I - K)x_n = x/||x||, which is in the unit sphere. Since I - K is compact, the image of the unit sphere under I - K is precompact. But x/||x|| is a constant sequence, which converges. But the problem is that if K is not injective, maybe I - K has a non-trivial kernel. Suppose x is in Ker(I - K). Then (I - K)x = 0 ⇒ x = Kx. If K is compact and x = Kx, then the identity operator on the infinite-dimensional space would be compact, which is a contradiction unless x = 0. Therefore, Ker(I - K) must be trivial. Wait, that's true. If K is compact and λ ≠ 0, then (λI - K) is Fredholm with index 0. In particular, if λ = 1, then (I - K) is Fredholm with index 0, so injective implies surjective, etc. But even if K is not injective, (I - K) could have a kernel. However, if K is injective, then (I - K) must have a trivial kernel? Wait, no. For example, take K = 0, which is compact and injective (if K is the zero operator, then it's injective only if the space is {0}). But in general, if K is injective, (I - K) might still have a non-trivial kernel. Wait, let's take an example. Let X be l^2, and K be a compact injective operator, like K(x_n) = (x_n / n). Then (I - K)x = 0 implies x_n = x_n / n for all n, so x_n = 0. So in this case, Ker(I - K) is trivial. So if K is injective and compact, then (I - K) is injective. But if K is not injective, then (I - K) could still be injective. For example, take K = 0, then (I - K) = I, which is injective. So injectivity of K doesn't directly relate to injectivity of (I - K). But in the user's proof, they didn't use injectivity of K. Their argument was: If I - K is compact, then every bounded sequence has a convergent subsequence, which contradicts infinite dimensionality. But this seems to hold regardless of K's injectivity. Therefore, the problem's assumption that K is injective might be a red herring, or perhaps the problem is misstated. Alternatively, the user's proof is missing a step where injectivity is required. For example, maybe when K is injective, then (I - K) cannot be compact, but if K is not injective, maybe (I - K) can be compact. But according to the user's proof, even if K is not injective, (I - K) being compact would lead to a contradiction. So perhaps the injectivity is not needed. Hence, the user might have correctly proved a stronger statement, and the problem's inclusion of \"K is one to one\" is unnecessary. Therefore, the user didn't make a mistake, but the problem's assumption is redundant. But then why does the problem include it? Maybe in their proof, the user implicitly used that K is injective. Let me check again. The user wrote: \"Choose any sequence in X that is of norm 1. Then suppose I - K is compact. It follows there must exist a subsequence x_{n_k} that (I - K)(x_{n_k}) converges. And since K is compact, there exists a sub-subsequence x_{n_{k_j}} that K(x_{n_{k_j}}) converges. Now I claim that in fact x_{n_{k_j}} converges in X. Indeed, x_{n_{k_j}} = (I - K)(x_{n_{k_j}}) + K(x_{n_{k_j}}). Hence, for any sequence on the unit sphere, I've found a subsequence that converges. This means the unit sphere is compact, which contradicts X being infinitely dimensional.\" \n\nBut wait, the step where they take a subsequence x_{n_k} such that (I - K)x_{n_k} converges requires that I - K is compact. Then from that subsequence, take a subsubsequence where Kx_{n_{k_j}} converges. Then x_{n_{k_j}} is the sum of two convergent sequences, hence converges. Therefore, every bounded sequence has a convergent subsequence. Hence, the space is finite-dimensional. So this argument doesn't use the injectivity of K. Therefore, the user's proof is correct, and the problem's requirement that K is injective is unnecessary. So the user didn't make a mistake, but the problem had an extra assumption. Therefore, the user's answer is correct, and the injectivity was a distractor.\n\nSo, to summarize the formatted problems:\n\nFor the first problem:\nAssumptions: \n- X and Y are Banach spaces.\n- A is a bounded linear operator from X to Y.\n- K is a compact operator from X to Y.\n- The range of A is contained within the range of K.\n\nProblem: Prove that A is a compact operator.\n\nFor the second problem:\nAssumptions:\n- X is infinitely dimensional.\n- K is a compact operator from X to X.\n- K is injective (one-to-one).\n\nProblem: Prove that I - K is not compact.\n\nEven though the user's proof for the second problem didn't use the injectivity, the problem statement includes it. Therefore, the formatted problem should include all the assumptions given, even if some might be redundant. So in the second problem's assumptions, we list that K is injective as per the original problem.",
    "Original_Problem": "Assumption: \n$X$ and $Y$ are Banach spaces,\n$A$ is a bounded linear operator from $X$ to $Y$,\n$K$ is a compact operator from $X$ to $Y$,\nThe range of $A$ is contained in the range of $K$.\nProblem: \nProve that $A$ is a compact operator.\n\n---\n\nAssumption: \n$X$ is infinitely dimensional,\n$K$ is a compact operator from $X$ to $X$,\n$K$ is injective (one-to-one).\nProblem: \nProve that $I - K$ is not compact.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $X$ and $Y$ are Banach spaces,\nAssumption 2: $A$ is a bounded linear operator from $X$ to $Y$,\nAssumption 3: $K$ is a compact operator from $X$ to $Y$,\nAssumption 4: The range of $A$ is contained in the range of $K$.\nAssumption 5:  \nAssumption 6: Prove that $A$ is a compact operator.\nAssumption 7: ---\nAssumption 8:  \nAssumption 9: $X$ is infinitely dimensional,\nAssumption 10: $K$ is a compact operator from $X$ to $X$,\nAssumption 11: $K$ is injective (one-to-one).\nProblem: \nProve that $A$ is a compact operator.\n\n---\n\nAssumption: \n$X$ is infinitely dimensional,\n$K$ is a compact operator from $X$ to $X$,\n$K$ is injective (one-to-one).\nProblem: \nProve that $I - K$ is not compact.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$ \\|T^*\\alpha\\| \\leq M\\|S^*\\alpha\\| \\tag{1}$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $X$ and $Y$ are Banach spaces,\nAssumption 2: $A$ is a bounded linear operator from $X$ to $Y$,\nAssumption 3: $K$ is a compact operator from $X$ to $Y$,\nAssumption 4: The range of $A$ is contained in the range of $K$.\nAssumption 5:  \nAssumption 6: Prove that $A$ is a compact operator.\nAssumption 7: ---\nAssumption 8:  \nAssumption 9: $X$ is infinitely dimensional,\nAssumption 10: $K$ is a compact operator from $X$ to $X$,\nAssumption 11: $K$ is injective (one-to-one).\nAssumption 12: $$ \\|T^*\\alpha\\| \\leq M\\|S^*\\alpha\\| \\tag{1}$$\nProblem: \nProve that $A$ is a compact operator.\n\n---\n\nAssumption: \n$X$ is infinitely dimensional,\n$K$ is a compact operator from $X$ to $X$,\n$K$ is injective (one-to-one).\nProblem: \nProve that $I - K$ is not compact."
}