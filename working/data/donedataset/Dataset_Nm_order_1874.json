{
    "Link_API": "https://api.stackexchange.com/2.3/questions/314167",
    "Title": "How to prove summation, multiplication, subtraction of two roots of $1+x+\\frac{x^2}{2!}+\\cdots+\\frac{x^p}{p!}=0$ aren&#39;t rationals?",
    "Score": 17,
    "Category": "Chứng minh",
    "Tags": "polynomials, algebraic-number-theory, galois-theory",
    "Link": "https://math.stackexchange.com/questions/314167/how-to-prove-summation-multiplication-subtraction-of-two-roots-of-1x-fracx",
    "Content": "Assume $a$, $b$ are distinct roots of the following equation: $$1+x+\\frac{x^2}{2!}+\\cdots+\\frac{x^p}{p!}=0,$$ where $p$ is a prime number and $p \\gt 2$. How to prove that $ab$, $a+b$, $a-b$ are not rational numbers. Thanks in advance",
    "AcceptedAnswer": "This is an expansion of @achille hui's hint in the comments. I just show that $a+b$ cannot be rational; the other cases are simple modifications to this approach. I must thank @achille hui again for a helpful correction to this solution. Multiply the polynomial through by $p!$ to get a monic polynomial. Note that $p$ divides each term after the leading $x^n$ term and that $p^2$ does not divide the constant term. This means we can apply Eisenstein's criterion to show the polynomial (call it $f(x)$) is irreducible. Suppose $a$ and $b$ are roots of the polynomial $a+b=r\\in\\mathbb Q$. Note that $f(r-x)$ is irreducible, because $x\\rightarrow r-x$ is an isomorphism of $\\mathbb Q[x]$. Because $f$ is irreducible and has $a$ as a root, it is the minimal polynomial for $a$. Because $f(r-a)=f(b)=0$, $a$ is a root of $f(r-x)$, so $f(x)$ must divide $f(r-x)$. In a similar fashion, we see that $f(r-x)$ must divide $f$, so $f(x)=f(r-x)$ up to a unit. By comparing leading coefficients, we see $f(x)=-f(x-r)$. Since the degree of $f(x)$ is odd and all roots are distinct, there must be a root $c$ of $f(x)$ with $c=r-c$. Hence $c=\\frac{r}{2} \\in \\mathbb Q$, a contradiction, as the irreducibility of $f$ over $\\mathbb Q$ implies in particular that it has no rational roots.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$a$ and $b$ are distinct roots of the equation $1 + x + \\frac{x^2}{2!} + \\cdots + \\frac{x^p}{p!} = 0$,\n$p$ is a prime number,\n$p > 2$.\nProblem: \nProve that $ab$, $a + b$, and $a - b$ are not rational numbers.\n###END_OF_FORMAT###",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem step by step. So, the problem is about two distinct roots a and b of the equation 1 + x + x²/2! + ... + x^p/p! = 0, where p is a prime number greater than 2. We need to prove that ab, a + b, a - b are not rational numbers.\n\nFirst, I need to recall some properties of polynomials and their roots. The given equation is a truncated exponential series. For a prime p, this polynomial might have some interesting properties. Let me note that the polynomial is of degree p, so there are p roots, and since the coefficients are real (in fact, rational), the complex roots should come in conjugate pairs. But here, a and b are distinct roots; they could be complex or real. But the problem states they are distinct, so they might be complex conjugates or two different real roots.\n\nBut wait, the equation 1 + x + x²/2! + ... + x^p/p! = 0. Let me think about the roots. For example, if p is an odd prime, then the polynomial has an odd degree, so there must be at least one real root. But since the coefficients are all positive except the constant term (which is 1), all the coefficients are positive. So for x > 0, the polynomial is definitely positive. For x = 0, the value is 1. For x approaching negative infinity, the leading term is x^p/p!, which for even p would be positive as x approaches -infty, but p is a prime greater than 2, so p is odd. Wait, p is prime and greater than 2, so p is odd. Therefore, as x approaches negative infinity, x^p/p! tends to negative infinity because x^p is negative (since p is odd). So the polynomial tends to negative infinity as x approaches -infty and is positive at x=0. Therefore, by the Intermediate Value Theorem, there is at least one real root in (-infty, 0). The other roots are complex conjugates.\n\nTherefore, if a and b are two distinct roots, they could either be both complex conjugates or one real and one complex. Wait, but complex roots come in conjugate pairs. So if the polynomial has one real root, the rest must come in complex conjugate pairs. So if a and b are both complex, they could be conjugates. If one is real and the other is complex, but since the coefficients are real, complex roots must come in pairs. So the problem states that a and b are distinct roots. So possibilities: both are complex conjugates, or both are real? Wait, but if p is prime and greater than 2 (so odd), then there is exactly one real root (since the polynomial tends to -infty as x approaches -infty and tends to +infty as x approaches +infty, but wait, p is prime greater than 2, so p is odd. Wait, the leading term is x^p/p!, so as x approaches +infty, the polynomial tends to +infty, and as x approaches -infty, it tends to -infty. Therefore, the polynomial crosses the x-axis at least once. But with all the positive coefficients except the leading term? Wait, no. The polynomial is 1 + x + x²/2! + ... + x^p/p!. All coefficients are positive. So for x positive, all terms are positive, so the polynomial is positive. For x = 0, it's 1. For x negative, some terms are negative. So the real root(s) must be negative. Since the polynomial is of odd degree, there is at least one real root, and the others are complex conjugates. So for p being an odd prime, there is exactly one real root and (p-1)/2 complex conjugate pairs. Therefore, if a and b are distinct roots, then either they are both complex conjugates or one is real and the other is complex. But if one is real and the other is complex, then a - b would be complex, which cannot be rational unless it's real. But if a is real and b is complex, then a - b is complex, which is not a real number, hence not rational. So in that case, a - b would automatically be non-rational. Similarly, a + b would be complex unless b is the conjugate of a. Wait, if a and b are complex conjugates, then a + b is real (twice the real part) and a*b is real (the modulus squared). So if a and b are complex conjugates, then a + b and a*b are real numbers, but we need to prove they are not rational. If a is real and b is complex, then a + b is complex, hence not rational, and a*b is complex, hence not rational. So the problem reduces to two cases: either a and b are complex conjugates or both are real. Wait, but the polynomial of odd degree has only one real root, so there can't be two real roots. Therefore, all other roots are complex and come in conjugate pairs. Therefore, if a and b are distinct roots, they must be a complex conjugate pair, since the only real root is unique. Therefore, in this problem, a and b are complex conjugates. Therefore, a + b is twice the real part of a, and a*b is the modulus squared of a, both real numbers. The problem claims that these are not rational. Also, a - b would be 2i times the imaginary part of a, which is purely imaginary, so a - b is not real, hence not rational. Therefore, in that case, a - b is automatically non-rational. But the problem states to prove that ab, a + b, a - b are not rational. So even if a and b are complex conjugates, we have to show that their sum and product are irrational, and their difference is not rational (which it isn't because it's imaginary, but maybe in the problem's context, they consider complex numbers as not rational even if the imaginary part is zero? Wait, no. The problem is about whether ab, a + b, a - b are rational numbers. Since rational numbers are real, if any of these expressions is complex (non-real), then it's not rational. Therefore, for a and b being complex conjugates, a + b is real, a*b is real, but a - b is purely imaginary (hence non-real). Therefore, a - b is automatically not rational. So the main challenge is to show that a + b and a*b are not rational. \n\nTherefore, the key part of the problem is to show that for the complex conjugate roots a and b of the given polynomial, the sum a + b and product a*b are irrational real numbers. And since a - b is purely imaginary, it's automatically not rational. So the problem reduces to proving that for any complex conjugate pair of roots of the equation, their sum and product are irrational.\n\nNow, how to approach this? Let me consider the polynomial. The polynomial is P(x) = 1 + x + x²/2! + ... + x^p/p! where p is a prime greater than 2. Let me note that this is similar to the expansion of e^x truncated at the x^p term. The roots of this polynomial are the solutions to the equation P(x) = 0.\n\nLet me consider that if a is a root, then its conjugate is also a root. Let me denote a and b = \\overline{a} as complex conjugates. Then, their sum is 2 Re(a) and their product is |a|². We need to show these are irrational.\n\nFirst, perhaps we can consider the properties of the polynomial. The polynomial is of prime degree p, which is greater than 2. The coefficients are all rational numbers because factorials are integers, so 1/k! is rational for each k. Therefore, the polynomial has rational coefficients. Therefore, the sum of the roots, product of the roots, etc., can be related to the coefficients via Vieta's formulas.\n\nWait, Vieta's formulas for a polynomial of degree p: P(x) = x^p/p! + x^{p-1}/(p-1)! + ... + x + 1 = 0. Let me write it in standard form:\n\nP(x) = (1/p!)x^p + (1/(p-1)!)x^{p-1} + ... + (1/2!)x^2 + x + 1 = 0.\n\nTo apply Vieta's formulas, it's easier if the leading coefficient is 1. Let me multiply both sides by p! to make the polynomial monic:\n\np! P(x) = x^p + p x^{p-1} + p(p-1) x^{p-2} + ... + p! x + p! = 0.\n\nSo the monic polynomial is Q(x) = x^p + p x^{p-1} + p(p-1) x^{p-2} + ... + p! x + p!.\n\nTherefore, the roots of Q(x) = 0 are the same as the roots of P(x) = 0. Now, using Vieta's formulas on Q(x):\n\nThe sum of the roots (with multiplicity) is -p (since the coefficient of x^{p-1} is p, and in Vieta's formula, the sum is -coeff of x^{p-1}/coeff of x^p, which is -p/1 = -p.\n\nSimilarly, the product of the roots is (-1)^p * constant term / leading coefficient. The constant term is p! and leading coefficient is 1, so product is (-1)^p * p!.\n\nSince p is an odd prime, (-1)^p = -1, so the product of all roots is -p!.\n\nBut in our case, the roots are one real root and (p-1)/2 complex conjugate pairs. So for each conjugate pair, their product is |a|², and their sum is 2 Re(a). The sum of all roots is -p, and the product of all roots is -p!.\n\nLet me denote the real root as r, and the complex roots as a_1, \\overline{a_1}, a_2, \\overline{a_2}, ..., a_{(p-1)/2}, \\overline{a_{(p-1)/2}}.\n\nThen, the sum of all roots is r + 2 Re(a_1) + 2 Re(a_2) + ... + 2 Re(a_{(p-1)/2}}) = -p.\n\nSimilarly, the product of all roots is r * |a_1|² * |a_2|² * ... * |a_{(p-1)/2}|² = -p!.\n\nBut since p is prime and greater than 2, and p! is divisible by p (by definition), so -p! is divisible by p. However, the product of the roots includes the real root r and the moduli squared of the complex roots. If any of these moduli squared or r were rational, perhaps we can find a contradiction.\n\nBut we need to focus on a single pair of complex roots, say a and b = \\overline{a}. We need to show that a + b and ab are irrational.\n\nAssume, for contradiction, that a + b is rational. Then, since a and b are roots of the polynomial Q(x) = 0, which has integer coefficients (after multiplying by p!), then the minimal polynomial of a over Q would have degree 2 if a is not real. Therefore, if a and b are conjugates, then the minimal polynomial is (x - a)(x - b) = x² - (a + b)x + ab. If both a + b and ab are rational, then this quadratic would have rational coefficients. Therefore, Q(x) must be divisible by this quadratic factor with rational coefficients. But Q(x) is irreducible over Q? Not necessarily. Wait, but Q(x) has degree p, a prime. If Q(x) factors into a product of polynomials over Q, then one of the factors must be degree 1 or degree p. But since all roots are either real or complex conjugates, and there is exactly one real root, then Q(x) must factor into (x - r) times a product of quadratic polynomials with rational coefficients. Therefore, Q(x) = (x - r) * product_{i=1}^{(p-1)/2} (x² - s_i x + t_i), where s_i, t_i are rational numbers (sum and product of conjugate pairs).\n\nBut Q(x) is a monic polynomial with integer coefficients. Therefore, the coefficients of these quadratic factors must be integers because the coefficients of Q(x) are integers. Therefore, s_i and t_i must be integers. Because when you multiply out (x - r)(x² - s_1 x + t_1)...(x² - s_k x + t_k), all coefficients must be integers.\n\nTherefore, if a and b are complex conjugate roots, their sum s = a + b and product t = ab must be integers. Wait, but the problem states that these are not rational. But according to this, they must be integers. So there is a contradiction here, unless our assumption that s and t are rational leads to some impossibility.\n\nWait, but the problem is to show that s and t are not rational. However, according to the above, if the polynomial factors into quadratics with integer coefficients, then s and t must be integers. But the problem states that they are not rational. So perhaps in reality, the polynomial is irreducible over Q, so it cannot be factored into lower-degree polynomials with integer coefficients, which would mean that the sum and product of any conjugate pair cannot be rational.\n\nTherefore, the key is to show that Q(x) is irreducible over Q. If Q(x) is irreducible, then it cannot have any quadratic factors with rational coefficients, which would imply that for any conjugate pair, their sum and product are not rational. Hence, proving the irreducibility of Q(x) over Q would suffice.\n\nAlternatively, if Q(x) is reducible, then it must have a linear factor or a quadratic factor. Since there is only one real root r, the linear factor is (x - r). Then, the remaining factor is a product of quadratic polynomials. If any of these quadratic polynomials have integer coefficients, then their roots (the conjugate pairs) would have integer sums and products, which would contradict the problem's conclusion. Therefore, if we can show that Q(x) is irreducible over Q, then there are no such quadratic factors, hence the sums and products of any conjugate pairs cannot be rational.\n\nThus, the crux is to prove that the polynomial Q(x) = x^p + p x^{p-1} + p(p-1) x^{p-2} + ... + p! x + p! is irreducible over Q. If we can establish this, then it cannot be factored into lower-degree polynomials with integer coefficients, which would imply that the sums and products of conjugate pairs are not rational.\n\nTo prove the irreducibility of Q(x), we can use the Eisenstein's criterion. However, Eisenstein's criterion requires a prime number that divides all coefficients except the leading one, and whose square does not divide the constant term. Let's see.\n\nBut Q(x) is x^p + p x^{p-1} + p(p-1) x^{p-2} + ... + p! x + p!.\n\nLet's check the coefficients. The coefficient of x^{p-k} is p(p-1)...(p - k + 1) for k from 0 to p. For example, coefficient of x^p is 1 (after multiplying by p!), but in Q(x), the leading coefficient is 1. The next coefficient is p, then p(p-1), then p(p-1)(p-2), etc., down to the constant term p!.\n\nNow, consider applying Eisenstein's criterion with the prime p. Let's check divisibility:\n\nThe coefficients are:\n\n- Leading term: 1 (not divisible by p)\n- x^{p-1} coefficient: p (divisible by p)\n- x^{p-2} coefficient: p(p-1) (divisible by p)\n- ...\n- Constant term: p! (divisible by p, but p! is divisible by p^2 when p >= 2, since p! = p*(p-1)*...*1, which includes p and 2p if p >= 2, but wait, for p prime, p! includes p once and other terms. For example, p=5, 5! = 120, which is divisible by 5^2=25? No, 120/25=4.8, which is not integer. Wait, p! is divisible by p but not by p^2 when p is prime. Because in p!, the exponent of p in the prime factorization is 1. Therefore, p^2 does not divide p!.\n\nTherefore, if we apply Eisenstein's criterion with the prime p, then:\n\n- All coefficients except the leading one are divisible by p (since coefficient of x^{p-k} is p(p-1)...(p -k +1), which is divisible by p for k >=1)\n- The constant term is p! which is divisible by p but not by p^2 (as p is prime)\n- The leading coefficient is 1, not divisible by p.\n\nTherefore, Eisenstein's criterion applies, and Q(x) is irreducible over Q. Therefore, Q(x) cannot be factored into lower-degree polynomials with integer coefficients. Hence, the polynomial is irreducible, meaning it cannot have any roots that are roots of lower-degree polynomials with integer (or rational) coefficients. Therefore, the minimal polynomial of any root a is Q(x) itself, which has degree p, a prime. Therefore, the degree of the field extension Q(a) over Q is p. If there were a quadratic polynomial with rational coefficients dividing Q(x), then the degree would be 2, but p is prime and greater than 2, which would contradict the irreducibility. Therefore, no such quadratic factors exist, implying that for any pair of conjugate roots a and b, the sum a + b and product ab cannot be rational. Because if they were, then (x - a)(x - b) would be a quadratic polynomial with rational coefficients dividing Q(x), contradicting its irreducibility.\n\nTherefore, this shows that ab and a + b cannot be rational. As for a - b, since a and b are complex conjugates, a - b is 2i Im(a), which is purely imaginary. Since rational numbers are real, a - b cannot be rational.\n\nTherefore, all three quantities ab, a + b, and a - b are not rational numbers, which is what we needed to prove.\n\nSo, summarizing the key steps:\n\n1. The polynomial Q(x) = p! P(x) has integer coefficients and is monic.\n2. Applying Eisenstein's criterion with prime p shows Q(x) is irreducible over Q.\n3. Therefore, Q(x) cannot have any quadratic factors with rational coefficients.\n4. Hence, for any pair of complex conjugate roots a and b, their sum a + b and product ab cannot be rational.\n5. The difference a - b is purely imaginary, hence not rational.",
    "Original_Problem": "Assumption: \n$a$ and $b$ are distinct roots of the equation $1 + x + \\frac{x^2}{2!} + \\cdots + \\frac{x^p}{p!} = 0$,\n$p$ is a prime number,\n$p > 2$.\nProblem: \nProve that $ab$, $a + b$, and $a - b$ are not rational numbers.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $a$ and $b$ are distinct roots of the equation $1 + x + \\frac{x^2}{2!} + \\cdots + \\frac{x^p}{p!} = 0$,\nAssumption 2: $p$ is a prime number,\nAssumption 3: $p > 2$.\nProblem: \nProve that $ab$, $a + b$, and $a - b$ are not rational numbers.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$f(r-a)=f(b)=0$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $a$ and $b$ are distinct roots of the equation $1 + x + \\frac{x^2}{2!} + \\cdots + \\frac{x^p}{p!} = 0$,\nAssumption 2: $p$ is a prime number,\nAssumption 3: $p > 2$.\nAssumption 4: $f(r-a)=f(b)=0$\nProblem: \nProve that $ab$, $a + b$, and $a - b$ are not rational numbers."
}