{
    "Link_API": "https://api.stackexchange.com/2.3/questions/1454892",
    "Title": "Does the inverse of the matrix always rely on the determinant of a matrix?",
    "Score": 14,
    "Category": "Chứng minh",
    "Tags": "abstract-algebra, matrices, group-theory, inverse",
    "Link": "https://math.stackexchange.com/questions/1454892/does-the-inverse-of-the-matrix-always-rely-on-the-determinant-of-a-matrix",
    "Content": "I always thought that if the determinant of a matrix $A$ is $0$ then it has no inverse, $(A^{-1})$, until I saw an exercise in Contemporary Abstract Algebra by Gallian. This asks me to prove that the set of the $2\\times2$ matrices of the form\n$$\\begin{bmatrix}\na&a\\\\\na&a\\\\\n\\end{bmatrix}\\,,$$\nwhere $a \\neq 0$ and $a \\in \\mathbb R$. is a group under matrix multiplication. The determinant of the above set of matrices is $0$, but still the inverse exists for each matrix which is nothing but\n$$\\begin{bmatrix}\n\\frac{a}{2} & \\frac{a}{2} \\\\\n\\frac{a}{2} & \\frac{a}{2} \\\\\n\\end{bmatrix}\\,.$$ How is this possible? What makes these type of matrices escape from satisfying determinants? What's the logic behind that?",
    "AcceptedAnswer": "It's a different notion of inverse. In linear algebra, the inverse of a $2\\times 2$ matrix $A$ is the matrix $A'$ such that\n$$A\\,A' = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix}\\,,$$\nif any such matrix exists.  However, the group inverse is the matrix $A''$ such that\n$$A\\,A'' = \\begin{pmatrix}i & i \\\\ i & i\\end{pmatrix}\\,,$$\nfor whatever value of $i$ makes\n$$\\begin{pmatrix}x & x\\\\x & x\\end{pmatrix}\\,\\begin{pmatrix}i & i\\\\i & i\\end{pmatrix} = \\begin{pmatrix}x & x\\\\x & x\\end{pmatrix}$$\ntrue for all $x$ (the other answers say that we need $i=\\tfrac12$). $A'$ and $A''$ are clearly different matrices and there's no reason that the existence of $A''$ for a particular matrix $A$ should imply the existence of $A'$.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \nThe set consists of $2 \\times 2$ real matrices of the form $\\begin{bmatrix} a & a \\\\ a & a \\end{bmatrix}$ where $a \\neq 0$,\nMatrix multiplication is the group operation,\nThe identity element for the group is $\\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}$,\nEach matrix in the set has an inverse within the set relative to the group's identity element.\nProblem: \nProve that the set of $2 \\times 2$ matrices of the form $\\begin{bmatrix} a & a \\\\ a & a \\end{bmatrix}$ (where $a \\neq 0$ and $a \\in \\mathbb{R}$) forms a group under matrix multiplication, despite each matrix having a determinant of $0$.\n###",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem. The user is confused because they've learned that a matrix with a determinant of zero doesn't have an inverse. But in this exercise from Gallian's book, there's a set of 2x2 matrices of a specific form that supposedly form a group under matrix multiplication, which would require each element (matrix) to have an inverse within the set. However, each of these matrices has a determinant of zero, which seems contradictory.\n\nFirst, let me recall the basic properties. A matrix is invertible if and only if its determinant is non-zero. So if the determinant is zero, the matrix shouldn't have an inverse. But here, they claim that each matrix in the set has an inverse, which is another matrix of the same form. Let me verify the example given.\n\nTake a matrix A = [[a, a], [a, a]] where a ≠ 0. The determinant is (a)(a) - (a)(a) = a² - a² = 0. So determinant is indeed zero. According to the problem, the inverse is [[a/2, a/2], [a/2, a/2]]. Let's multiply them:\n\nA * inverse = [[a, a], [a, a]] * [[a/2, a/2], [a/2, a/2]] \n\nCalculating the first entry: a*(a/2) + a*(a/2) = (a²/2 + a²/2) = a²\n\nSimilarly, all entries will be a². So the product is [[a², a²], [a², a²]]. For this to be the identity matrix, we need a² = 1 and the off-diagonal entries to be zero. But here, all entries are a². The only way this can be the identity matrix is if a² = 1 and a² = 0, which is impossible. Wait, this seems like a problem. Did I compute the multiplication correctly?\n\nWait, maybe the inverse is supposed to be [[1/(4a), 1/(4a)], [1/(4a), 1/(4a)]]? Let me check again. Maybe the user made a mistake in the inverse matrix. Alternatively, perhaps the inverse in the problem is defined differently. Let me recast.\n\nLet me denote the inverse matrix as B = [[b, b], [b, b]]. Then, A * B should be the identity matrix. Let's compute A*B:\n\nFirst entry: a*b + a*b = 2ab\n\nSecond entry: same as first, 2ab\n\nThird entry: same as first, 2ab\n\nFourth entry: same as first, 2ab\n\nSo the product is [[2ab, 2ab], [2ab, 2ab]]. For this to be the identity matrix, we need 2ab = 1 and the off-diagonal entries to be zero. But the off-diagonal entries here are also 2ab, so they can't be zero unless ab = 0, but a ≠ 0 and b would have to be zero, which would make 2ab = 0, not 1. This is a contradiction. Therefore, the inverse as claimed cannot exist. \n\nWait, this suggests that there's a mistake either in the problem statement or in the user's understanding. But the user says the inverse is [[a/2, a/2], [a/2, a/2]]. Let me plug that in again. If B is [[a/2, a/2], [a/2, a/2]], then A*B is [[a*(a/2) + a*(a/2), ...], which is [[a², a²], [a², a²]]. So unless a² = 1 and a² = 0, which is impossible, this can't be the identity matrix. Therefore, the inverse as stated is incorrect. \n\nBut the problem says \"prove that the set is a group under matrix multiplication\". If the inverse as claimed doesn't work, then either the problem is incorrect, or there's a misunderstanding. Wait, perhaps the inverse is not in the general linear group, but within the restricted set. Let's see. Let me suppose that the inverse is another matrix of the same form, [[c, c], [c, c]], such that [[a, a], [a, a]] * [[c, c], [c, c]] = [[2ac, 2ac], [2ac, 2ac]]. For this to equal the identity matrix, we would need 2ac = 1 and 0 elsewhere, but all entries are 2ac. So it's impossible. Therefore, such an inverse cannot exist in the set, which would mean the set isn't a group under multiplication. This contradicts the problem's assertion. \n\nWait, maybe the problem is not using the usual matrix multiplication identity? But the identity element for matrix multiplication is the identity matrix, which isn't in the set given (since all entries must be equal and non-zero). Therefore, the group must have a different identity element. But in a group, the identity element must satisfy E*A = A*E = A for all A in the group. Let me check if there's a matrix E = [[e, e], [e, e]] such that E*A = A. Compute E*A:\n\n[[e, e], [e, e]] * [[a, a], [a, a]] = [[2ea, 2ea], [2ea, 2ea]]. For this to equal A = [[a, a], [a, a]], we need 2ea = a, so 2e = 1, hence e = 1/2. So the identity element would be [[1/2, 1/2], [1/2, 1/2]]. But wait, this matrix has determinant (1/2)(1/2) - (1/2)(1/2) = 0. So the identity element is a matrix with determinant zero? That's not part of the general linear group, but maybe in this specific set, they are defining a group with a different identity. \n\nIf the identity element is E = [[1/2, 1/2], [1/2, 1/2]], then for each matrix A = [[a, a], [a, a]], we need an inverse B such that A*B = E. Let's compute A*B = [[2ab, 2ab], [2ab, 2ab]]. For this to equal E, we need 2ab = 1/2, so ab = 1/4. Therefore, if we take b = 1/(4a), then B = [[b, b], [b, b]] = [[1/(4a), 1/(4a)], [1/(4a), 1/(4a)]]. But then B must be in the set, which requires that b ≠ 0, which is true since a ≠ 0. So the inverse would be [[1/(4a), 1/(4a)], [1/(4a), 1/(4a)]], which is of the required form. \n\nWait, so the user might have made a mistake in stating the inverse. The inverse isn't [[a/2, a/2], [a/2, a/2]], but rather [[1/(4a), 1/(4a)], [1/(4a), 1/(4a)]]. Let me check this. Let’s take a specific example, say a = 1. Then A = [[1,1],[1,1]]. The inverse should be [[1/4, 1/4], [1/4, 1/4]]. Multiplying them gives [[1*(1/4)+1*(1/4), ...], which is [[0.5, 0.5], [0.5, 0.5]], which is the identity element E. So in this case, the inverse exists within the set, but the identity element is E, not the usual identity matrix. Therefore, this set forms a group under matrix multiplication with identity element E and inverses as [[1/(4a), ...]]. \n\nBut the user mentioned the inverse as [[a/2, a/2], ...]]. That seems incorrect unless there's a different setup. Wait, if the identity element is E = [[1/2, 1/2], [1/2, 1/2]], then perhaps the problem is using a different operation, but the user says it's under matrix multiplication. So maybe the problem is correct, but the user miscalculated the inverse. \n\nSo the key points here are: \n\n1. The group in question has a different identity element, not the standard identity matrix.\n2. The inverse is defined with respect to this new identity element.\n3. The determinant being zero doesn't prevent the existence of an inverse within this specific set because the operation is not the standard general linear group operation, since the identity is different.\n\nHowever, in standard linear algebra, a matrix with determinant zero is not invertible in the general linear group. But in this problem, they are forming a group structure with a subset of singular matrices by redefining the identity element and the inverse operation within that subset. This is possible because the group axioms don't require the identity to be the standard identity matrix; it just needs to act as an identity within the set. Similarly, inverses are defined relative to this new identity.\n\nTherefore, the confusion arises because the user is conflating the inverse in the general linear group (which requires determinant non-zero) with the inverse within this specific monoid (which turns out to be a group) structure defined on a subset of singular matrices. The key is that the group operation here is closed within the set, and the inverse is defined with respect to the group's identity element, not the standard matrix inverse.\n\nSo the assumptions are:\n\n- The set consists of 2x2 real matrices of the form [[a,a],[a,a]] where a ≠ 0.\n- The group operation is standard matrix multiplication.\n- The identity element for this group is [[1/2, 1/2], [1/2, 1/2]].\n- Inverses are taken with respect to this identity element, not the standard identity matrix.\n\nBut in the original problem statement, the user might not have realized that the identity element is different, leading to confusion about how an inverse exists despite a zero determinant.",
    "Original_Problem": "Assumption: \nThe set consists of $2 \\times 2$ real matrices of the form $\\begin{bmatrix} a & a \\\\ a & a \\end{bmatrix}$ where $a \\neq 0$,\nMatrix multiplication is the group operation,\nThe identity element for the group is $\\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}$,\nEach matrix in the set has an inverse within the set relative to the group's identity element.\nProblem: \nProve that the set of $2 \\times 2$ matrices of the form $\\begin{bmatrix} a & a \\\\ a & a \\end{bmatrix}$ (where $a \\neq 0$ and $a \\in \\mathbb{R}$) forms a group under matrix multiplication, despite each matrix having a determinant of $0$.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: The set consists of $2 \\times 2$ real matrices of the form $\\begin{bmatrix} a & a \\\\ a & a \\end{bmatrix}$ where $a \\neq 0$,\nAssumption 2: Matrix multiplication is the group operation,\nAssumption 3: The identity element for the group is $\\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}$,\nAssumption 4: Each matrix in the set has an inverse within the set relative to the group's identity element.\nProblem: \nProve that the set of $2 \\times 2$ matrices of the form $\\begin{bmatrix} a & a \\\\ a & a \\end{bmatrix}$ (where $a \\neq 0$ and $a \\in \\mathbb{R}$) forms a group under matrix multiplication, despite each matrix having a determinant of $0$.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$A\\,A' = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix}\\,,$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: The set consists of $2 \\times 2$ real matrices of the form $\\begin{bmatrix} a & a \\\\ a & a \\end{bmatrix}$ where $a \\neq 0$,\nAssumption 2: Matrix multiplication is the group operation,\nAssumption 3: The identity element for the group is $\\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}$,\nAssumption 4: Each matrix in the set has an inverse within the set relative to the group's identity element.\nAssumption 5: $$A\\,A' = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix}\\,,$$\nProblem: \nProve that the set of $2 \\times 2$ matrices of the form $\\begin{bmatrix} a & a \\\\ a & a \\end{bmatrix}$ (where $a \\neq 0$ and $a \\in \\mathbb{R}$) forms a group under matrix multiplication, despite each matrix having a determinant of $0$."
}