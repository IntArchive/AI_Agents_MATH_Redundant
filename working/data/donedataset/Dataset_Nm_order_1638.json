{
    "Link_API": "https://api.stackexchange.com/2.3/questions/345517",
    "Title": "Why is it true that $\\mathrm{adj}(A)A = \\det(A) \\cdot I$?",
    "Score": 19,
    "Category": "Chứng minh",
    "Tags": "linear-algebra, determinant",
    "Link": "https://math.stackexchange.com/questions/345517/why-is-it-true-that-mathrmadjaa-deta-cdot-i",
    "Content": "This is a statement in linear algebra that I can't seem to understand the proof behind. For a square matrix $A$, why is:\n$$\\mathrm{adj}(A)A = \\det(A) \\cdot I$$ Any explanation would be greatly appreciated.",
    "AcceptedAnswer": "There is a nice short explanation. You probably know that the determinant of any matrix can be expanded row or column-wise using the minors: $$\\det A=\\sum_{i=1}^n a_{ij}(-1)^{i+j}\\det A(i\\mid j)$$ or $$\\det A=\\sum_{j=1}^n a_{ij}(-1)^{i+j}\\det A(i\\mid j)$$ for any $j$ (resp. $i$) or your liking where we obtain $A(i\\mid j)$ by striking out the $i$-th row and the $j$-th column. We define the coefficients of the adjoint $\\hat A$ by $$(\\hat A)_{ij}=(-1)^{{i+j}}\\det A(j\\mid i)$$ Now, upon matrix multiplication, we have $$(A\\cdot\\hat A)_{k\\ell}=\\sum_{i=1}^n (-1)^{i+\\ell}a_{ki} \\det A(\\ell\\mid i)$$ If $k=\\ell$, then $$(A\\cdot \\hat A)_{\\ell\\ell}=\\sum_{i=1}^n(-1)^{i+\\ell}a_{\\ell i}\\det A(\\ell \\mid i)=\\det A$$ since we're expanding the determinant through the $\\ell$-th row. If $k\\neq \\ell$ $$(A\\cdot\\hat A)_{k\\ell}=\\sum_{i=1}^n (-1)^{i+\\ell}a_{ki} \\det A(\\ell\\mid i)=0$$ for it is the expansion of the determinant of the matrix $A^{k\\ell}$ defined by $$(A^{k\\ell})=\\begin{cases} a_{ij} \\text{ if }i\\neq \\ell\\\\a_{kj}\\text{ if }i=\\ell\\end{cases}$$ which has two equal rows.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$A$ is a square matrix,\nThe adjugate matrix $\\mathrm{adj}(A)$ is the transpose of the cofactor matrix of $A$.\nProblem: \nProve that $$\\mathrm{adj}(A)A = \\det(A) \\cdot I$$.\n###END_OF_FORMAT###",
    "reasoning_create_structured_problem": "Okay, let's try to figure out why adj(A) multiplied by A gives det(A) times the identity matrix. Hmm, I remember that the adjugate matrix, sometimes called the classical adjoint, is the transpose of the cofactor matrix. Each entry of the adjugate is the cofactor of the corresponding element in the original matrix. But how does multiplying them together lead to the determinant times the identity?\n\nWait, maybe I should start by recalling the definition of the cofactor. The cofactor C_ij of an element a_ij is (-1)^(i+j) times the determinant of the (n-1)x(n-1) matrix that remains after removing row i and column j from A. Then, the adjugate matrix is the transpose of the cofactor matrix, so adj(A) has entries C_ji.\n\nSo when we multiply adj(A) by A, the entry in the (i,k) position of the product is the sum over j of C_ji * a_jk. Let's think about this sum. For the diagonal entries where i = k, this sum should be the determinant of A, right? Because expanding the determinant along row i would give the sum of a_ij * C_ij, which is the same as the sum of a_ji * C_ji if we transpose. Wait, maybe not. Let me check that again.\n\nActually, when you compute the product adj(A) * A, the diagonal entries are the dot product of the i-th row of adj(A) (which is the i-th column of the cofactor matrix) with the i-th column of A. But the cofactor expansion of the determinant along column i is exactly the sum of a_ji * C_ji, which equals det(A). So each diagonal entry of the product matrix is det(A).\n\nWhat about the off-diagonal entries where i ≠ k? In that case, the entry should be the sum over j of C_ji * a_jk. But this is equivalent to taking the cofactor expansion of a matrix where the i-th column is replaced by the k-th column. Since a matrix with two identical columns has determinant zero, this sum should be zero. Therefore, all off-diagonal entries are zero, and the product is det(A) times the identity matrix.\n\nBut wait, let me make sure. If we have a matrix B where we replace column i with column k, then the determinant of B is zero because of duplicate columns. The cofactor expansion along column i of matrix B would be the sum over j of a_jk * C_ji, which is exactly the same as the off-diagonal entry (i,k) in adj(A)*A. Since det(B) = 0, that sum is zero. So yeah, that explains why off-diagonal entries are zero. Therefore, adj(A)*A equals det(A)I.\n\nI think that covers it. The key idea is that multiplying the adjugate by A results in the determinant on the diagonal because of the cofactor expansion, and zero elsewhere because it's like expanding a matrix with duplicate columns. This makes the entire product matrix a scalar multiple of the identity matrix, scaled by det(A).",
    "Original_Problem": "Assumption: \n$A$ is a square matrix,\nThe adjugate matrix $\\mathrm{adj}(A)$ is the transpose of the cofactor matrix of $A$.\nProblem: \nProve that $$\\mathrm{adj}(A)A = \\det(A) \\cdot I$$.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $A$ is a square matrix,\nAssumption 2: The adjugate matrix $\\mathrm{adj}(A)$ is the transpose of the cofactor matrix of $A$.\nProblem: \nProve that $$\\mathrm{adj}(A)A = \\det(A) \\cdot I$$.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$(A\\cdot\\hat A)_{k\\ell}=\\sum_{i=1}^n (-1)^{i+\\ell}a_{ki} \\det A(\\ell\\mid i)=0$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $A$ is a square matrix,\nAssumption 2: The adjugate matrix $\\mathrm{adj}(A)$ is the transpose of the cofactor matrix of $A$.\nAssumption 3: $$(A\\cdot\\hat A)_{k\\ell}=\\sum_{i=1}^n (-1)^{i+\\ell}a_{ki} \\det A(\\ell\\mid i)=0$$\nProblem: \nProve that $$\\mathrm{adj}(A)A = \\det(A) \\cdot I$$."
}