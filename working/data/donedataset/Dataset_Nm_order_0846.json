{
    "Link_API": "https://api.stackexchange.com/2.3/questions/347408",
    "Title": "Prove that if the sum of each row of $A$ equals $s$, then $s$ is an eigenvalue of $A$.",
    "Score": 26,
    "Category": "Chứng minh",
    "Tags": "matrices, eigenvalues-eigenvectors",
    "Link": "https://math.stackexchange.com/questions/347408/prove-that-if-the-sum-of-each-row-of-a-equals-s-then-s-is-an-eigenvalue-o",
    "Content": "Let $A$ be an $n \\times n$ matrix. $i)$Prove that if the sum of each row of $A$ equals $s$, then $s$ is an eigenvalue of $A$. $ii)$Prove that if the sum of each column of $A$ equals $s$, then $s$ is an eigenvalue of $A$. I think that being an eigenvalue of $A$ implies that $sv=Av$ for some vector $v$. Furthermore, I know that $[a_i] = s$ if we let $a_i$ denote the i-th row of $A$. However, I do not seem to be able to find a link between these two facts. Could anyone please help me out?",
    "AcceptedAnswer": "HINT: Calculate $Av$ when $v=(1,1,\\ldots ,1,1)^t$, what can you say?",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nassumption: \n$A$ is an $n \\times n$ matrix,\nThe sum of each row of $A$ equals $s$,\nThe sum of each column of $A$ equals $s$.\nproblem: \nProve that if the sum of each row of $A$ equals $s$, then $s$ is an eigenvalue of $A$. \nProve that if the sum of each column of $A$ equals $s$, then $s$ is an eigenvalue of $A$.\n###END_OF_FORMAT###\n\n**Answer:**\n\n(i) **When each row sums to $s$:**  \nLet $\\mathbf{v} = \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}$ be the $n \\times 1$ vector of ones. Then:  \n$$\nA\\mathbf{v} = \\begin{pmatrix} \\text{Sum of row 1} \\\\ \\text{Sum of row 2} \\\\ \\vdots \\\\ \\text{Sum of row } n \\end{pmatrix} = \\begin{pmatrix} s \\\\ s \\\\ \\vdots \\\\ s \\end{pmatrix} = s\\mathbf{v}.\n$$  \nThus, $s$ is an eigenvalue of $A$ with eigenvector $\\mathbf{v}$.\n\n(ii) **When each column sums to $s$:**  \nConsider the transpose matrix $A^T$. The rows of $A^T$ correspond to the columns of $A$, which sum to $s$. By part (i), $s$ is an eigenvalue of $A^T$. Since $A$ and $A^T$ share the same eigenvalues, $s$ is also an eigenvalue of $A$.  \n\nAlternatively, let $\\mathbf{u}^T = \\begin{pmatrix} 1 & 1 & \\cdots & 1 \\end{pmatrix}$ be a row vector. Then:  \n$$\n\\mathbf{u}^T A = \\begin{pmatrix} \\text{Sum of column 1} & \\text{Sum of column 2} & \\cdots & \\text{Sum of column } n \\end{pmatrix} = s\\mathbf{u}^T.\n$$  \nThus, $s$ is a left eigenvalue of $A$, which coincides with its right eigenvalues.  \n\n**Conclusion:** In both cases, $s$ is an eigenvalue of $A$.",
    "reasoning_create_structured_problem": "Okay, let's try to tackle this problem step by step. The user wants me to prove that if the sum of each row of a square matrix A is equal to s, then s is an eigenvalue of A. Similarly, if the sum of each column is s, then s is also an eigenvalue. \n\nFirst, I need to recall what an eigenvalue is. An eigenvalue λ of a matrix A satisfies the equation Av = λv for some non-zero vector v. So, to show that s is an eigenvalue, I need to find a vector v such that Av = sv. \n\nStarting with part (i), where each row sums to s. Let's consider the vector v. If I can find a vector v that when multiplied by A gives sv, that would do it. Hmm, the rows of A sum to s, so maybe using a vector that's all ones? Because when you multiply a matrix by a vector of ones, you're essentially summing each row. Let me test this.\n\nSuppose v is a column vector with all entries equal to 1. Then, the product Av would result in a vector where each entry is the sum of the corresponding row of A. Since each row sums to s, Av would be a vector where every entry is s. That's the same as s times the vector v (since v is all ones). So Av = sv, which means v is an eigenvector corresponding to eigenvalue s. Therefore, s is indeed an eigenvalue of A. That seems straightforward.\n\nNow, part (ii) where each column sums to s. This is a bit trickier. The columns sum to s, so maybe using a different vector? If I use the vector of ones again, but this time as a row vector, multiplying A on the left? Wait, eigenvalues are associated with column vectors. Alternatively, maybe I need to consider the transpose of A. Because the columns of A are the rows of the transpose matrix A^T. If each column of A sums to s, then each row of A^T sums to s. From part (i), we know that s is an eigenvalue of A^T. But eigenvalues of A and A^T are the same because the determinant of (A - λI) is the same as the determinant of (A^T - λI). Therefore, if s is an eigenvalue of A^T, it's also an eigenvalue of A. \n\nAlternatively, maybe there's a direct approach without using the transpose. If I take a row vector with all entries equal to 1 and multiply it by A, that would sum the columns. But that gives a row vector, and eigenvalues are usually associated with column vectors. However, in this case, the left eigenvectors are row vectors such that vA = λv. So, if the sum of each column is s, then the row vector of ones multiplied by A gives s times the row vector of ones. Therefore, the row vector of ones is a left eigenvector corresponding to eigenvalue s. But eigenvalues are the same for left and right eigenvectors, so s is indeed an eigenvalue of A. \n\nTherefore, both parts can be proven by considering the vector of ones as an eigenvector (right eigenvector for row sums, left eigenvector for column sums). \n\nWait, but the problem statement in part (ii) says \"if the sum of each column of A equals s\", then s is an eigenvalue. So, using the left eigenvector argument, but since eigenvalues are the same for left and right, s must be an eigenvalue. Alternatively, since A and A^T have the same eigenvalues, part (ii) follows from part (i) applied to A^T. \n\nEither way, the conclusion is that s is an eigenvalue in both cases. The key was to use the vector of ones as the eigenvector for the row sums, and either use the transpose or a left eigenvector for the column sums.",
    "Original_Problem": "assumption: \n$A$ is an $n \\times n$ matrix,\nThe sum of each row of $A$ equals $s$,\nThe sum of each column of $A$ equals $s$.\nproblem: \nProve that if the sum of each row of $A$ equals $s$, then $s$ is an eigenvalue of $A$. \nProve that if the sum of each column of $A$ equals $s$, then $s$ is an eigenvalue of $A$.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $A$ is an $n \\times n$ matrix,\nAssumption 2: The sum of each row of $A$ equals $s$,\nAssumption 3: The sum of each column of $A$ equals $s$.\nProblem: \nProve that if the sum of each row of $A$ equals $s$, then $s$ is an eigenvalue of $A$. \nProve that if the sum of each column of $A$ equals $s$, then $s$ is an eigenvalue of $A$.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$v=(1,1,\\ldots ,1,1)^t$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $A$ is an $n \\times n$ matrix,\nAssumption 2: The sum of each row of $A$ equals $s$,\nAssumption 3: The sum of each column of $A$ equals $s$.\nAssumption 4: $v=(1,1,\\ldots ,1,1)^t$\nProblem: \nProve that if the sum of each row of $A$ equals $s$, then $s$ is an eigenvalue of $A$. \nProve that if the sum of each column of $A$ equals $s$, then $s$ is an eigenvalue of $A$."
}