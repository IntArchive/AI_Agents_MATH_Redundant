{
    "Link_API": "https://api.stackexchange.com/2.3/questions/2029707",
    "Title": "Entropy of the multivariate Gaussian",
    "Score": 17,
    "Category": "Chứng minh",
    "Tags": "multivariable-calculus, entropy, gaussian-integral",
    "Link": "https://math.stackexchange.com/questions/2029707/entropy-of-the-multivariate-gaussian",
    "Content": "Show that the entropy of the multivariate Gaussian $N(x|\\mu,\\Sigma)$ is given by\n  \\begin{align}\nH[x] = \\frac12\\ln|\\Sigma| + \\frac{D}{2}(1 + \\ln(2\\pi))\n\\end{align}\n  where $D$ is the dimensionality of $x$. My solution. Entropy for normal distribution: \\begin{align}\nH[x] = -\\int_{-\\infty}^{+\\infty}N(x|\\mu,\\Sigma)\\ln(N(x|\\mu,\\Sigma)) dx = &&\\text{by definition of entropy}\\\\\n= -E[\\ln(N(x|\\mu,\\Sigma))] =\\\\\n= -E[\\ln((2\\pi)^{-\\frac{D}{2}} |\\Sigma|^{-\\frac12} e^{-\\frac12(x - \\mu)^T\\Sigma^{-1}(x - \\mu)})] = &&\\text{definition of multivariable gaussian}\\\\\n= \\frac{D}{2}\\ln(2\\pi) + \\frac12\\ln |\\Sigma| + \\frac12E[(x - \\mu)^T\\Sigma^{-1}(x - \\mu)] &&\\text{the log of a product is the sum of the logs}.\n\\end{align} Consider the third term: \\begin{align}\n\\frac12E[(x - \\mu)^T\\Sigma^{-1}(x - \\mu)] = \\\\\n= \\frac12E[x^T\\Sigma^{-1}x - x^T\\Sigma^{-1}\\mu - \\mu^T\\Sigma^{-1}x + \\mu^T\\Sigma^{-1}\\mu] = \\\\\n= \\frac12E[x^T\\Sigma^{-1}x] - \\frac12E[2\\mu^T\\Sigma^{-1}x] + \\frac12E[\\mu^T\\Sigma^{-1}\\mu] = \\\\\n= \\frac12E[x^T\\Sigma^{-1}x] - \\mu^T\\Sigma^{-1}E[x] + \\frac12\\mu^T\\Sigma^{-1}\\mu = \\\\\n= \\frac12E[x^T\\Sigma^{-1}x] - \\mu^T\\Sigma^{-1}\\mu + \\frac12\\mu^T\\Sigma^{-1}\\mu = &&\\text{Since $E[x] = \\mu$}\\\\\n= \\frac12E[x^T\\Sigma^{-1}x] - \\frac12\\mu^T\\Sigma^{-1}\\mu\n\\end{align} How can I simplify the term: $E[x^T\\Sigma^{-1}x]$ ?",
    "AcceptedAnswer": "It's better to simplify the term $\\mathbb{E}[(x-\\mu)^T \\Sigma^{-1}(x-\\mu)]$ directly: $$\n\\begin{align}\n  \\mathbb{E}[(x-\\mu)^T \\Sigma^{-1}(x-\\mu)]\n       &= \\mathbb{E}[\\mathrm{tr}((x-\\mu)^T \\Sigma^{-1}(x-\\mu))]\\\\\n       &= \\mathbb{E}[\\mathrm{tr}(\\Sigma^{-1}(x-\\mu)(x-\\mu)^T)]\\\\\n       &= \\mathrm{tr}(\\mathbb{E}[\\Sigma^{-1}(x-\\mu)(x-\\mu)^T])\\\\\n       &= \\mathrm{tr}(\\Sigma^{-1}\\mathbb{E}[(x-\\mu)(x-\\mu)^T])\\\\\n       &= \\mathrm{tr}(\\Sigma^{-1}\\Sigma)\\\\\n       &= \\mathrm{tr}(I)=D\n\\end{align}\n$$",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$x$ is a random vector,\nThe dimensionality of $x$ is $D$,\n$x$ follows a multivariate Gaussian distribution with mean $\\mu$ and covariance matrix $\\Sigma$,\nThe entropy $H[x]$ is defined as $H[x] = -\\int_{-\\infty}^{+\\infty} N(x|\\mu,\\Sigma) \\ln(N(x|\\mu,\\Sigma)) dx$.\nProblem:\nShow that the entropy of the multivariate Gaussian $N(x|\\mu,\\Sigma)$ is given by  \n$$H[x] = \\frac{1}{2}\\ln|\\Sigma| + \\frac{D}{2}(1 + \\ln(2\\pi)).$$\n###",
    "reasoning_create_structured_problem": "Okay, so I need to help the user structure this problem according to the specified format. Let me first read through the original question and the example provided. The user wants me to extract the assumptions and the problem statement, ensuring each assumption is a single property applied to one object.\n\nThe original problem is about finding the entropy of a multivariate Gaussian distribution. The user has shown their steps and is stuck on simplifying the term E[x^T Σ^{-1} x]. \n\nFirst, let me identify all the assumptions. The problem mentions the multivariate Gaussian N(x|μ, Σ), so the assumptions here would relate to the properties of this distribution. \n\n1. The random variable x follows a multivariate Gaussian distribution with mean μ and covariance matrix Σ. That's one assumption.\n2. The dimensionality of x is D. That's another assumption since D is used in the formula.\n3. The entropy is defined as the expectation of the negative log-likelihood. The user starts with the definition H[x] = -∫ N(x) ln N(x) dx, which is the standard definition, so that's an assumption about the entropy's definition.\n4. The expectation E is taken with respect to the distribution of x. This is implied but should be stated as an assumption.\n\nWait, the problem says \"Show that the entropy...\" so the main assumptions are the properties of the multivariate Gaussian. The problem doesn't state any additional conditions, like Σ being positive definite, which is usually an assumption for covariance matrices. But in the example provided, the assumptions were about n being an integer and divisible by 7. Here, perhaps the key assumptions are that x is multivariate Gaussian with mean μ and covariance Σ, and D is the dimension.\n\nSo listing the assumptions:\n\n- x is a D-dimensional random vector.\n- x follows a multivariate Gaussian distribution with mean vector μ and covariance matrix Σ.\n- Σ is a positive definite matrix (since covariance matrices must be positive definite for the Gaussian to be defined).\n- The entropy H[x] is defined as the expectation of -ln(N(x|μ, Σ)).\n\nBut the original problem statement doesn't explicitly mention Σ being positive definite; maybe that's implicit. However, for the problem to make sense, Σ has to be invertible, which requires it being positive definite. Should that be considered an assumption? The example given by the user included an assumption that n is divisible by 7, which was part of the problem's original statement. Here, the problem states \"multivariate Gaussian N(x|μ, Σ)\", so Σ is a valid covariance matrix, hence positive definite. So maybe that's an implicit assumption.\n\nBut the user's example only listed the assumptions given in the problem. The original problem here doesn't state any conditions on Σ, but it's necessary for the existence of the entropy. Should I include that as an assumption? The problem says \"multivariate Gaussian\", which inherently requires Σ to be positive definite. So perhaps it's better to list:\n\nAssumptions:\n- x is a D-dimensional random vector.\n- x follows a multivariate Gaussian distribution with mean μ and covariance matrix Σ.\n- Σ is a positive definite matrix.\n- The entropy H[x] is defined as H[x] = -E[ln(N(x|μ, Σ))].\n\nBut wait, the problem says \"Show that the entropy...\", so maybe the definition of entropy is part of the problem's given, not an assumption. Wait, in the example, the assumptions were about the problem's conditions. The problem here is asking to show the entropy formula given that the distribution is multivariate Gaussian. So the main assumptions are:\n\n- x ~ N(μ, Σ), a multivariate Gaussian.\n- D is the dimensionality of x.\n- The entropy is defined as the integral of -N ln N.\n\nBut the problem statement already includes the definition of entropy in the question. So perhaps the assumptions are:\n\n- x is a D-dimensional random vector.\n- x follows a multivariate Gaussian distribution with mean μ and covariance matrix Σ.\n- The entropy H[x] is defined by H[x] = -∫ N(x|μ,Σ) ln(N(x|μ,Σ)) dx.\n\nBut the problem says \"Show that...\", so the assumptions are the given conditions. The user is trying to compute H[x] under these assumptions. The problem statement doesn't mention anything else, like specific constraints on Σ or μ. So the assumptions should include the properties of x (multivariate Gaussian, dimensionality D) and the definition of entropy. However, in the example, the assumptions included n being an integer and divisible by 7. Here, the equivalent would be x being multivariate Gaussian, D-dimensional, and the entropy defined as per the integral. But since the problem explicitly states the definition of entropy as part of the question, maybe that's part of the problem statement, not an assumption. Wait, the original problem's question is to show the entropy formula, so the assumptions are the given conditions, which are:\n\n1. x is distributed as multivariate Gaussian N(μ, Σ).\n2. D is the dimensionality of x.\n3. Entropy is defined as H[x] = -∫ N(x|μ,Σ) ln N(x|μ,Σ) dx.\n\nBut in the example, the assumption included the divisibility by 7, which was part of the original problem's condition. Here, the problem's given is that x is multivariate Gaussian, D is the dimension, and entropy is defined as such. Therefore, the assumptions should list each of these. Each as separate lines. Let me check the example again:\n\nIn the example, the original problem had an assumption that n is an integer and that n is divisible by 7. So each assumption is a single property on one object. Here:\n\nAssumption 1: x is a D-dimensional random vector.\n\nAssumption 2: x follows a multivariate Gaussian distribution with mean μ and covariance matrix Σ.\n\nAssumption 3: The entropy H[x] is defined as H[x] = -∫_{-∞}^{+∞} N(x|μ,Σ) ln(N(x|μ,Σ)) dx.\n\nAssumption 4: Σ is a positive definite matrix.\n\nWait, but the original problem may not state that Σ is positive definite; it's implicit. But for the formula to hold, Σ must be invertible, hence positive definite. So perhaps that's an implicit assumption. However, the problem as stated on Math Stack Exchange may not mention it, but it's necessary. However, the user's example included an assumption that was part of the original problem (n divisible by 7). If the original problem here doesn't mention positive definiteness, should I include it? The user's instruction is to filter unrelated information and structure the problem. Since the original problem didn't state it, maybe it's considered implicit and not listed. The original problem's title is \"Entropy of the multivariate Gaussian\", so the necessary assumptions are that x is multivariate Gaussian, D-dimensional, and the entropy is defined as given. So:\n\nAssumptions:\n- x is a D-dimensional random vector.\n- x follows a multivariate Gaussian distribution with parameters μ (mean) and Σ (covariance matrix).\n- The entropy H[x] is defined as the expectation of -ln(N(x|μ, Σ)).\n\nBut the problem statement in the question includes the definition of entropy, so maybe that's part of the problem, not an assumption. Wait, the example given by the user:\n\nOriginal problem: Prove that for every integer n, the number A(n) is divisible by 91.\n\nFormatted assumptions: n is an integer, n is divisible by 7.\n\nWait, in that case, the original problem says \"for every integer n\", but the formatted assumption added \"n is divisible by 7\". Wait, that seems contradictory. Wait, the original problem was:\n\nOriginal problem: Prove that for every integer n, the number A(n) = 5^n (5^n +1) - 6^n(3^n +2^n) is divisible by 91.\n\nBut the formatted problem's assumption includes \"n is divisible by 7\". Wait, that's a mistake. Wait, looking back, maybe I misread the example. Let me check again.\n\nWait, the example's original problem says \"for every integer n\", but the formatted assumption says \"n is an integer, n is divisible by 7\". That seems incorrect. Wait, perhaps there was an error in the example. Because if the original problem is to prove for every integer n, then the assumption should not restrict n to be divisible by 7. Wait, this might be a mistake in the example provided. So perhaps the user made a mistake in their example. Alternatively, maybe the original problem had a condition that n is divisible by 7, but the user wrote it as \"for every integer n\". That would be a contradiction. Therefore, perhaps the example is faulty. But assuming the example is correct as per the user's instruction, I need to follow the structure.\n\nBut given that, for the current problem, the user's original question is: Show that the entropy of the multivariate Gaussian N(x|μ,Σ) is given by H[x] = (1/2) ln|Σ| + (D/2)(1 + ln(2π)) where D is the dimensionality of x.\n\nSo the problem's assumptions would be:\n\n- x is a D-dimensional random vector.\n\n- x follows a multivariate Gaussian distribution N(x|μ,Σ).\n\n- The entropy is defined as H[x] = -∫ N(x|μ,Σ) ln(N(x|μ,Σ)) dx.\n\nEach of these is a separate assumption. The problem is to show the entropy formula.\n\nAdditionally, Σ must be positive definite for the Gaussian to be non-degenerate, but if the original problem doesn't state that, perhaps it's considered implicit and not listed. However, in mathematical problems, sometimes key assumptions are listed even if they are standard. But following the example's approach, which included an assumption that n is divisible by 7 even if the original problem said \"for every integer n\", perhaps there was a mistake. Alternatively, maybe the original problem in the example had a typo. But in this case, since the user's example includes assumptions that may not be in the original problem, but in our current problem, the original question does state the necessary conditions. So I'll proceed to list the assumptions as:\n\n1. x is a D-dimensional random vector.\n\n2. x follows a multivariate Gaussian distribution N(x|μ, Σ).\n\n3. The entropy H[x] is defined as H[x] = -E[ln(N(x|μ, Σ))].\n\nEach on separate lines. Then the problem is to show that H[x] equals the given formula.\n\nAlternatively, since the problem statement in the question includes the definition of entropy as part of the problem, maybe the assumption is only about the distribution of x and its dimensionality.\n\nSo perhaps:\n\nAssumptions:\n\n- x is a D-dimensional random vector following a multivariate Gaussian distribution N(μ, Σ).\n\nBut to split into single properties:\n\n- x is a random vector.\n\n- The dimensionality of x is D.\n\n- x follows a multivariate Gaussian distribution with mean μ and covariance matrix Σ.\n\nThen the problem is to show the entropy formula using the given definition.\n\nTherefore, structuring it as:\n\nAssumption:\n\nx is a random vector,\n\nThe dimensionality of x is D,\n\nx follows a multivariate Gaussian distribution with mean μ and covariance matrix Σ,\n\nThe entropy H[x] is defined as H[x] = -∫_{-∞}^{+∞} N(x|μ,Σ) ln(N(x|μ,Σ)) dx.\n\nProblem:\n\nShow that the entropy of the multivariate Gaussian N(x|μ,Σ) is given by\n\nH[x] = (1/2) ln|Σ| + (D/2)(1 + ln(2π)).\n\nYes, that seems correct. Each assumption is a single property applied to one object.",
    "Original_Problem": "Assumption: \n$x$ is a random vector,\nThe dimensionality of $x$ is $D$,\n$x$ follows a multivariate Gaussian distribution with mean $\\mu$ and covariance matrix $\\Sigma$,\nThe entropy $H[x]$ is defined as $H[x] = -\\int_{-\\infty}^{+\\infty} N(x|\\mu,\\Sigma) \\ln(N(x|\\mu,\\Sigma)) dx$.\nProblem:\nShow that the entropy of the multivariate Gaussian $N(x|\\mu,\\Sigma)$ is given by  \n$$H[x] = \\frac{1}{2}\\ln|\\Sigma| + \\frac{D}{2}(1 + \\ln(2\\pi)).$$",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $x$ is a random vector,\nAssumption 2: The dimensionality of $x$ is $D$,\nAssumption 3: $x$ follows a multivariate Gaussian distribution with mean $\\mu$ and covariance matrix $\\Sigma$,\nAssumption 4: The entropy $H[x]$ is defined as $H[x] = -\\int_{-\\infty}^{+\\infty} N(x|\\mu,\\Sigma) \\ln(N(x|\\mu,\\Sigma)) dx$.\nProblem:\nShow that the entropy of the multivariate Gaussian $N(x|\\mu,\\Sigma)$ is given by  \n$$H[x] = \\frac{1}{2}\\ln|\\Sigma| + \\frac{D}{2}(1 + \\ln(2\\pi)).$$",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$\n\\begin{align}\n  \\mathbb{E}[(x-\\mu)^T \\Sigma^{-1}(x-\\mu)]\n       &= \\mathbb{E}[\\mathrm{tr}((x-\\mu)^T \\Sigma^{-1}(x-\\mu))]\\\\\n       &= \\mathbb{E}[\\mathrm{tr}(\\Sigma^{-1}(x-\\mu)(x-\\mu)^T)]\\\\\n       &= \\mathrm{tr}(\\mathbb{E}[\\Sigma^{-1}(x-\\mu)(x-\\mu)^T])\\\\\n       &= \\mathrm{tr}(\\Sigma^{-1}\\mathbb{E}[(x-\\mu)(x-\\mu)^T])\\\\\n       &= \\mathrm{tr}(\\Sigma^{-1}\\Sigma)\\\\\n       &= \\mathrm{tr}(I)=D\n\\end{align}\n$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $x$ is a random vector,\nAssumption 2: The dimensionality of $x$ is $D$,\nAssumption 3: $x$ follows a multivariate Gaussian distribution with mean $\\mu$ and covariance matrix $\\Sigma$,\nAssumption 4: The entropy $H[x]$ is defined as $H[x] = -\\int_{-\\infty}^{+\\infty} N(x|\\mu,\\Sigma) \\ln(N(x|\\mu,\\Sigma)) dx$.\nAssumption 5: $$\n\\begin{align}\n  \\mathbb{E}[(x-\\mu)^T \\Sigma^{-1}(x-\\mu)]\n       &= \\mathbb{E}[\\mathrm{tr}((x-\\mu)^T \\Sigma^{-1}(x-\\mu))]\\\\\n       &= \\mathbb{E}[\\mathrm{tr}(\\Sigma^{-1}(x-\\mu)(x-\\mu)^T)]\\\\\n       &= \\mathrm{tr}(\\mathbb{E}[\\Sigma^{-1}(x-\\mu)(x-\\mu)^T])\\\\\n       &= \\mathrm{tr}(\\Sigma^{-1}\\mathbb{E}[(x-\\mu)(x-\\mu)^T])\\\\\n       &= \\mathrm{tr}(\\Sigma^{-1}\\Sigma)\\\\\n       &= \\mathrm{tr}(I)=D\n\\end{align}\n$$\nProblem:\nShow that the entropy of the multivariate Gaussian $N(x|\\mu,\\Sigma)$ is given by  \n$$H[x] = \\frac{1}{2}\\ln|\\Sigma| + \\frac{D}{2}(1 + \\ln(2\\pi)).$$"
}