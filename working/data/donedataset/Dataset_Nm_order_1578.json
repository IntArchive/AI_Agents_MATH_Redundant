{
    "Link_API": "https://api.stackexchange.com/2.3/questions/105418",
    "Title": "very elementary proof of Maxwell&#39;s theorem",
    "Score": 20,
    "Category": "Chứng minh",
    "Tags": "probability-distributions, functional-equations",
    "Link": "https://math.stackexchange.com/questions/105418/very-elementary-proof-of-maxwells-theorem",
    "Content": "Maxwell's theorem (after James Clerk Maxwell) says that if a function $f(x_1,\\ldots,x_n)$ of $n$ real variables is a product $f_1(x_1)\\cdots f_n(x_n)$ and is rotation-invariant in the sense that the value of the function depends on $x_1,\\ldots,x_n$ only through $x_1^2+\\cdots+x_n^2$, then it's an exponential function of that sum of squares (so $f$ is a \"Gaussian function\"). Say a class of undergraduates knows only enough mathematics to understand what the theorem says (so maybe they've never heard of inner products or orthogonal matrices), but they're bright and can understand mathematical arguments.  What proof of Maxwell's theorem do you show them?  Can you keep it short and simple?",
    "AcceptedAnswer": "I assume the $C^1$ regularity of all functions and the fact that $f$ is never zero. I think that it can be proved that if $f$ is somewhere zero, then it is everywhere zero. The idea I came up with is the following: $$f(x_1,\\ldots,x_n)=f_1(x_1)\\cdots f_n(x_n)=\\phi(x_1^2+\\cdots+x_n^2)$$ Denote $r^2=x_1^2+\\cdots+x_n^2$ . Differentiate with respect to $x_i$ and get $$f_1(x_1)\\cdots f_i'(x_i)\\cdots f_n(x_n)=\\phi'(r^2)2x_i$$ Divide by $f$ and obtain $$\\frac{f_i'(x_i)}{f_i(x_i)}\\frac{1}{2x_i}=\\frac{\\phi'(r^2)}{f(x_1,\\ldots,x_n)}$$ Therefore the LHS is independent of $i$ . Since each $f_i$ depends only of $x_i$ it follows that there exists a constant $C_i$ such that $$\\frac{f_i'(x_i)}{f_i(x_i)}\\frac{1}{2x_i} =C_i$$ From here it is easy to get $f_i=C_ie^{C_i x_i^2}$ from where the conclusion follows. $\\ $ $\\ $",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$f(x_1,\\ldots,x_n)$ is a product of functions $f_1(x_1)\\cdots f_n(x_n)$,\n$f$ is rotation-invariant (depends on $x_1,\\ldots,x_n$ only through $x_1^2 + \\cdots + x_n^2)$.\nProblem: \nProve that $f$ must be an exponential function of $x_1^2 + \\cdots + x_n^2$ (a Gaussian function).\n###END_OF_FORMAT###",
    "reasoning_create_structured_problem": "Okay, let's tackle this problem. The user wants me to act as a knowledgeable bilingual math professor and structure the given problem from Math Stack Exchange into the specified format. The example provided shows that the assumptions should be listed line by line, each addressing one property or condition applied to one object, followed by the problem statement.\n\nLooking at the original question about Maxwell's theorem, the key points are:\n\n1. The function f(x₁,…,xₙ) is a product of functions f₁(x₁)…fₙ(xₙ).\n2. The function is rotation-invariant, meaning it depends only on the sum of squares x₁² + … + xₙ².\n3. The conclusion is that f must be an exponential function of that sum (a Gaussian).\n\nThe task is to present a proof suitable for undergraduates who haven't studied inner products or orthogonal matrices but can follow mathematical arguments. The user wants a short and simple proof.\n\nSo, the assumptions here are about the function's form (product of individual variable functions) and its rotational invariance (depends only on the sum of squares). The problem is to prove it's a Gaussian.\n\nI need to list each assumption separately. Let me check:\n\n- First assumption: The function f is a product of functions each depending on a single variable.\n- Second assumption: The function f is rotation-invariant, depending only on the sum of squares of the variables.\n\nThe problem is to prove f is an exponential function of the sum of squares, i.e., a Gaussian.\n\nI need to ensure that each assumption is one line, addressing one property. The original problem mentions the function is rotation-invariant and a product of individual functions. That's two separate conditions. So the assumptions should list these two points.\n\nNow, structuring it according to the format:\n\nAssumption:\nf(x₁,…,xₙ) is a product of functions f₁(x₁)…fₙ(xₙ),\nf is rotation-invariant, i.e., depends on x₁,…,xₙ only through x₁² + … + xₙ².\n\nProblem:\nProve that f must be an exponential function of x₁² + … + xₙ² (a Gaussian function).\n\nI think that's correct. Each assumption is a single condition, applied to the function f. The problem is to show the conclusion based on these assumptions. The example given in the user's message also combined multiple conditions into separate lines, so this should fit.",
    "Original_Problem": "Assumption: \n$f(x_1,\\ldots,x_n)$ is a product of functions $f_1(x_1)\\cdots f_n(x_n)$,\n$f$ is rotation-invariant (depends on $x_1,\\ldots,x_n$ only through $x_1^2 + \\cdots + x_n^2)$.\nProblem: \nProve that $f$ must be an exponential function of $x_1^2 + \\cdots + x_n^2$ (a Gaussian function).",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $f(x_1,\\ldots,x_n)$ is a product of functions $f_1(x_1)\\cdots f_n(x_n)$,\nAssumption 2: $f$ is rotation-invariant (depends on $x_1,\\ldots,x_n$ only through $x_1^2 + \\cdots + x_n^2)$.\nProblem: \nProve that $f$ must be an exponential function of $x_1^2 + \\cdots + x_n^2$ (a Gaussian function).",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$f_1(x_1)\\cdots f_i'(x_i)\\cdots f_n(x_n)=\\phi'(r^2)2x_i$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $f(x_1,\\ldots,x_n)$ is a product of functions $f_1(x_1)\\cdots f_n(x_n)$,\nAssumption 2: $f$ is rotation-invariant (depends on $x_1,\\ldots,x_n$ only through $x_1^2 + \\cdots + x_n^2)$.\nAssumption 3: $$f_1(x_1)\\cdots f_i'(x_i)\\cdots f_n(x_n)=\\phi'(r^2)2x_i$$\nProblem: \nProve that $f$ must be an exponential function of $x_1^2 + \\cdots + x_n^2$ (a Gaussian function)."
}