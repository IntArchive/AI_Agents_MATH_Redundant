{
    "Link_API": "https://api.stackexchange.com/2.3/questions/570088",
    "Title": "Prove that if positive-definite $f$ is continuous at $0$, it is continuous on $\\mathbb{R}$",
    "Score": 13,
    "Category": "Chứng minh",
    "Tags": "linear-algebra, matrices",
    "Link": "https://math.stackexchange.com/questions/570088/prove-that-if-positive-definite-f-is-continuous-at-0-it-is-continuous-on",
    "Content": "Long story short, the question I'm stuck on is as follows: Let $f$ be a positive-definite function.  Prove that if $f$ is continuous at $0$, then it is continuous everywhere. Here's the long version: We say that a function $f:\\mathbb{R}\\to \\mathbb{C}$ is positive definite if the matrix $A_f[\\{t_1,t_2,\\dots,t_n\\}]$, whose entries are given by \n$$\nA_f[\\{t_1,t_2,\\dots,t_n\\}]=[f(t_i-t_j)]_{i,j=1}^n\n$$\nIs positive semidefinite for all choices of $t_1,\\dots,t_n \\in \\mathbb{R}$.  In the whole problem, we are meant to show that $f$ has the following properties: $f(-t) = \\overline{f(t)}$ $f(0) \\in \\mathbb{R}$ and $f(0) \\geq 0$ $|f(t)|\\leq f(0)$ for all $t \\in \\mathbb{R}$ if $f$ is continuous at $0$, then it is continuous everywhere The first three parts may all be solved by considering the $2\\times 2$ matrix $A_f[0,t]$ where $t\\in \\mathbb{R}$ is arbitrary. Because $A_f[0,t]$ is Hermitian, the first statement holds.  Because $A_f[0,t]$ must have non-negative trace, we conclude that the second statement holds.  Becuase $A_f[0,t]$ has a non-negative determinant, we conclude that the third statement holds.  That fourth statement, however, has me stumped. As far as I can tell, there is no more insight to be gleaned from $2\\times 2$ matrices.  Presumably, I need to find an upper bound for $|f(t) - f(t+\\delta)|$ given that $|f(\\delta) - f(0)|$ can be made arbitrarily small.  I've noticed that $\\det A_f[0,t,t+\\delta]$ can be finagled into something like $f(0)|f(t) - f(t+\\delta)|^2$.  However, it's not clear to me how I would use this to the desired ends. There's also a good chance that I've managed to think myself into a hole, given that this one small part of one problem has given me more trouble than the rest of the assignment. The question claims that this problem can be solved using the fact that a semi-definite matrix has a non-negative trace and determinant, and that all principal submatrices have a non-negative determinant. I think that just about covers it.  If you've made it this far, thank you for your time; I tried not to make this a wall of text.  Any helpful nudges in the right direction would be very much appreciated; an attempt at an answer doubly so.",
    "AcceptedAnswer": "Hint: The matrix\n$$\nA=\\pmatrix{\nf(0)   &f(-t) &f(-t-h)\\\\\nf(t)   &f(0)  &f(-h)\\\\\nf(t+h) &f(h)  &f(0)}\n$$\nis congruent to\n$$\nB=\\pmatrix{\nf(0)        &f(-t)      &f(-t-h)-f(-t)\\\\\nf(t)        &f(0)       &f(-h)-f(0)\\\\\nf(t+h)-f(t) &f(h)-f(0)  &2f(0)-f(h)-f(-h)}.\n$$\nNow consider the $2\\times2$ submatrix taken from the entries at the four corners of $B$.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$f:\\mathbb{R}\\to \\mathbb{C}$ is a positive-definite function,\n$f$ is continuous at $0$.\nProblem: \nProve that $f$ is continuous everywhere on $\\mathbb{R}$.\n###",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem step by step. The user wants to prove that if a positive-definite function f is continuous at 0, then it is continuous everywhere on ℝ. \n\nFirst, let me recall the definitions and properties given. A function f: ℝ → ℂ is positive-definite if for any finite set of points t₁, t₂, ..., tₙ in ℝ, the matrix A_f with entries [f(t_i - t_j)] is positive semidefinite. From previous parts of the problem, we already know that f must satisfy certain properties: f(-t) is the complex conjugate of f(t), f(0) is real and non-negative, and |f(t)| ≤ f(0) for all t. \n\nThe user is stuck on the fourth part: showing continuity at 0 implies continuity everywhere. Their approach involved considering 3x3 matrices with points 0, t, and t + δ, and they mentioned that the determinant might relate to |f(t) - f(t + δ)|². Let me see if I can formalize that.\n\nSuppose we take three points: 0, t, and t + δ. The matrix A_f would be:\n\n[ f(0)       f(-t)         f(-t - δ) ]\n[ f(t)       f(0)          f(-δ)     ]\n[ f(t + δ)   f(δ)          f(0)      ]\n\nSince this matrix is positive semidefinite, all its principal minors must be non-negative. The determinant of this 3x3 matrix should be non-negative. But calculating this determinant directly might be complicated. Alternatively, perhaps considering a 2x2 matrix involving t and δ could help. Wait, the user mentioned that the determinant of the 3x3 matrix can be manipulated into something involving |f(t) - f(t + δ)|². Let me try to compute that determinant.\n\nAlternatively, maybe there's a smarter choice of points. Let's think about taking specific points to create a matrix that relates to the difference f(t + δ) - f(t). Let me try choosing points 0, δ, and t + δ. Then the matrix would be:\n\n[ f(0)       f(-δ)        f(-t - δ) ]\n[ f(δ)       f(0)         f(-t)     ]\n[ f(t + δ)   f(t)         f(0)      ]\n\nBut I'm not sure if this setup helps. Alternatively, maybe take points 0, δ, and t. Then the matrix is:\n\n[ f(0)    f(-δ)     f(-t)    ]\n[ f(δ)    f(0)      f(δ - t) ]\n[ f(t)    f(t - δ)  f(0)     ]\n\nHmm, not sure. Let's go back to the user's thought. They considered the determinant of A_f[0, t, t + δ], which they said can be manipulated into f(0)|f(t) - f(t + δ)|². If that's the case, then since the determinant is non-negative (because the matrix is positive semidefinite), this would imply that f(0)|f(t) - f(t + δ)|² ≤ something. Wait, but determinants of larger matrices being non-negative might not directly give an inequality for the difference. Maybe the user was referring to a specific expansion where the determinant expression simplifies to include |f(t) - f(t + δ)|² multiplied by f(0), and then other terms. If that's the case, perhaps by using the fact that the determinant must be non-negative, we can bound |f(t) - f(t + δ)|² in terms of f(0) and other terms related to continuity at 0.\n\nAlternatively, maybe there's a different approach. Since we know |f(t)| ≤ f(0), maybe we can use some form of the Cauchy-Schwarz inequality related to the positive semidefinite matrices. For instance, if we take vectors in ℂⁿ, the positive semidefiniteness implies that for any vector v, v* A_f v ≥ 0. Perhaps choosing specific vectors v that relate to the differences f(t + δ) - f(t).\n\nAnother idea: using the property that f is continuous at 0, we can make |f(δ) - f(0)| small when δ is small. The goal is to relate this to |f(t + δ) - f(t)|. Since the function is positive-definite, perhaps we can find a relationship between these differences using the positive semidefinite condition.\n\nLet me consider a 2x2 matrix with points 0 and δ. The matrix is:\n\n[ f(0)    f(-δ) ]\n[ f(δ)    f(0)  ]\n\nThis matrix must be positive semidefinite. Therefore, its determinant must be non-negative: f(0)² - |f(δ)|² ≥ 0, which we already know gives |f(δ)| ≤ f(0). But since f is continuous at 0, as δ → 0, f(δ) → f(0). So |f(δ) - f(0)| → 0. Now, how to connect this to continuity at an arbitrary point t.\n\nPerhaps take a vector v = [1, -1] applied to the matrix with points t and t + δ. Wait, but the matrix entries are f(t_i - t_j). Let me try constructing a matrix with points t and t + δ. Then the matrix would be:\n\n[ f(0)        f(-δ) ]\n[ f(δ)        f(0)  ]\n\nWait, that's the same as before. Alternatively, perhaps take points 0 and t + δ - t = δ. Wait, maybe another approach.\n\nConsider the 2x2 matrix with points t and t + δ. The matrix entries are f(0), f(-δ), f(δ), f(0). But actually, for points t and t + δ, the differences would be (t - (t + δ)) = -δ, and (t + δ - t) = δ. So the matrix would be:\n\n[ f(0)       f(-δ) ]\n[ f(δ)       f(0)  ]\n\nSame as before. But this doesn't directly involve t. Hmm. Maybe we need to consider a different set of points. Let's consider three points: 0, δ, and t. The matrix A_f[0, δ, t] would be:\n\n[ f(0)       f(-δ)       f(-t)    ]\n[ f(δ)       f(0)        f(δ - t) ]\n[ f(t)       f(t - δ)    f(0)     ]\n\nThis matrix is positive semidefinite. Therefore, all principal minors must be non-negative. The determinant of the entire 3x3 matrix must be non-negative, but calculating that might be complex. Alternatively, consider a specific vector to apply to this matrix to get an inequality involving f(t) and f(t - δ).\n\nAlternatively, let's try using the positive semidefinite property with a specific vector. Let's take a vector v = [1, e^{iθ}, 0], but maybe that's not helpful. Alternatively, take v = [1, -1, 0] and apply it to the 3x3 matrix. But I'm not sure. \n\nWait, the user mentioned that they tried looking at the determinant of the 3x3 matrix A_f[0, t, t + δ] and found it relates to f(0)|f(t) - f(t + δ)|². Let's try to compute that determinant. Let's denote s = t + δ. Then the matrix is:\n\n[ f(0)       f(-t)        f(-s)    ]\n[ f(t)       f(0)         f(t - s) ]\n[ f(s)       f(s - t)     f(0)     ]\n\nBut since s = t + δ, s - t = δ. And t - s = -δ. So the matrix becomes:\n\n[ f(0)       f(-t)        f(-t - δ) ]\n[ f(t)       f(0)         f(-δ)     ]\n[ f(t + δ)   f(δ)         f(0)      ]\n\nNow, compute the determinant of this 3x3 matrix. Let's denote the matrix as M. Then det(M) should be non-negative. Let's compute it:\n\ndet(M) = f(0)[f(0)*f(0) - f(-δ)f(δ)] - f(-t)[f(t)*f(0) - f(-δ)f(t + δ)] + f(-t - δ)[f(t)f(δ) - f(0)f(t + δ)]\n\nThis seems complicated. But maybe using the properties of f: f(-t) = \\overline{f(t)}, f(0) is real. Let's substitute f(-t) with \\overline{f(t)}, and f(-δ) with \\overline{f(δ)}, etc. So:\n\ndet(M) = f(0)[f(0)^2 - |f(δ)|²] - \\overline{f(t)}[f(t)f(0) - \\overline{f(δ)}f(t + δ)] + \\overline{f(t + δ)}[f(t)f(δ) - f(0)f(t + δ)]\n\nHmm. This still looks messy. Maybe there's a simplification. Let's focus on the terms involving f(t + δ). Suppose we expand the determinant. Alternatively, maybe there's a different approach.\n\nAnother idea: since f is positive-definite, the function is Bochner's theorem states that a continuous positive-definite function is the Fourier transform of a finite measure. But the user might not be assuming Bochner's theorem, especially since they are working on an exercise that likely doesn't require advanced theorems.\n\nAlternatively, use the fact that |f(t + δ) - f(t)|² can be related to the positive-definite property. Let's consider expanding |f(t + δ) - f(t)|²:\n\n|f(t + δ) - f(t)|² = |f(t + δ)|² + |f(t)|² - 2 Re(f(t + δ)\\overline{f(t)})\n\nBut how does this relate to the positive-definite condition? Maybe consider the matrix with entries for points 0, δ, t, t + δ. But this might get too complex.\n\nWait, the user mentioned that they thought the determinant could be manipulated into f(0)|f(t) - f(t + δ)|². Suppose that's the case. Then if the determinant is non-negative, and f(0) is positive (since f(0) ≥ 0 and if f is not identically zero, f(0) > 0), then |f(t) - f(t + δ)|² ≤ something involving the determinant. But if the determinant also involves terms that can be controlled by continuity at 0, then as δ approaches 0, those terms go to zero, forcing |f(t) - f(t + δ)|² to go to zero, hence continuity.\n\nLet me try to see if this determinant approach works. Suppose det(A_f[0, t, t + δ]) = f(0)|f(t) - f(t + δ)|² - [something else]. If the determinant is non-negative, then f(0)|f(t) - f(t + δ)|² ≥ [something else]. If [something else] can be bounded using the continuity at 0, then maybe we can show that |f(t) - f(t + δ)|² is small when δ is small.\n\nAlternatively, perhaps there's a more straightforward inequality. Since we know that |f(t)| ≤ f(0), and f is continuous at 0, maybe we can use the positive-definite property to write an inequality involving |f(t + δ) - f(t)| and |f(δ) - f(0)|.\n\nAnother approach: using the fact that for any a, b ∈ ℝ, the matrix:\n\n[ f(0)      f(a - b) ]\n[ f(b - a)  f(0)    ]\n\nis positive semidefinite, so its determinant f(0)^2 - |f(a - b)|^2 ≥ 0, which gives |f(a - b)| ≤ f(0). But this is already known.\n\nAlternatively, consider the function's continuity via the positive-definite property. Suppose we want to bound |f(t + δ) - f(t)|. Let's consider the 2x2 matrix with points t and t + δ. The matrix is:\n\n[ f(0)        f(-δ) ]\n[ f(δ)        f(0)  ]\n\nWait, that's the same as before. The difference here is that we're looking at the function's behavior at t and t + δ, but the matrix entries only involve δ and 0. Maybe this isn't directly helpful.\n\nWait, perhaps consider using the 3x3 matrix as the user suggested. If we can show that |f(t) - f(t + δ)|² is bounded by something involving |f(δ) - f(0)|, then since f is continuous at 0, as δ → 0, |f(δ) - f(0)| → 0, hence |f(t) - f(t + δ)| → 0, proving continuity at t.\n\nLet me try to make this precise. Suppose that the determinant of the 3x3 matrix A_f[0, t, t + δ] is non-negative. If this determinant can be expressed as f(0)|f(t) - f(t + δ)|² - [terms involving |f(δ) - f(0)|], then since the determinant is ≥ 0, we have f(0)|f(t) - f(t + δ)|² ≥ [those terms]. If the [terms] can be bounded by, say, C|f(δ) - f(0)| for some constant C, then dividing both sides by f(0) (assuming f(0) > 0, which it is unless f is identically zero, in which case continuity is trivial) gives |f(t) - f(t + δ)|² ≤ (C/f(0))|f(δ) - f(0)|. Taking square roots, we get |f(t) - f(t + δ)| ≤ sqrt(C/f(0)) sqrt(|f(δ) - f(0)|). As δ → 0, |f(δ) - f(0)| → 0, so the right-hand side goes to 0, proving continuity at t.\n\nBut how to derive this expression for the determinant. Let me attempt the computation again. Let's take the matrix with rows and columns corresponding to 0, t, t+δ:\n\nRow 0: [f(0), f(-t), f(-t - δ)]\nRow t: [f(t), f(0), f(-δ)]\nRow t+δ: [f(t + δ), f(δ), f(0)]\n\nThe determinant is:\n\nf(0)*[f(0)*f(0) - f(-δ)*f(δ)] - f(-t)*[f(t)*f(0) - f(-δ)*f(t + δ)] + f(-t - δ)*[f(t)*f(δ) - f(0)*f(t + δ)]\n\nUsing f(-x) = conjugate(f(x)), this becomes:\n\nf(0)*(f(0)^2 - |f(δ)|^2) - conjugate(f(t))*(f(t)f(0) - conjugate(f(δ))f(t + δ)) + conjugate(f(t + δ))*(f(t)f(δ) - f(0)f(t + δ))\n\nThis is still complicated. Let's try to simplify term by term.\n\nFirst term: f(0)^3 - f(0)|f(δ)|^2\n\nSecond term: - conjugate(f(t)) [f(t)f(0) - conjugate(f(δ))f(t + δ)] = -f(0)|f(t)|^2 + conjugate(f(t)) conjugate(f(δ)) f(t + δ)\n\nThird term: conjugate(f(t + δ)) [f(t)f(δ) - f(0)f(t + δ)] = f(t)f(δ) conjugate(f(t + δ)) - f(0)|f(t + δ)|^2\n\nNow, combine all three terms:\n\ndet(M) = f(0)^3 - f(0)|f(δ)|^2 - f(0)|f(t)|^2 + conjugate(f(t)) conjugate(f(δ)) f(t + δ) + f(t)f(δ) conjugate(f(t + δ)) - f(0)|f(t + δ)|^2\n\nThis seems messy. Let's look for terms that can be grouped. Notice that conjugate(f(t)) conjugate(f(δ)) f(t + δ) + f(t)f(δ) conjugate(f(t + δ)) = 2 Re [f(t)f(δ) conjugate(f(t + δ))]\n\nBut I'm not sure. Alternatively, perhaps recognize that the expression involves |f(t) - f(t + δ)|². Let's compute that:\n\n|f(t) - f(t + δ)|² = |f(t)|² + |f(t + δ)|² - 2 Re(f(t) conjugate(f(t + δ)))\n\nCompare this with the terms in det(M). If we can express det(M) in terms of |f(t) - f(t + δ)|² and other terms involving |f(δ)| and |f(t + δ)|, etc., then maybe we can isolate the desired term.\n\nLooking at the expression for det(M):\n\ndet(M) = f(0)^3 - f(0)|f(δ)|² - f(0)|f(t)|^2 - f(0)|f(t + δ)|^2 + 2 Re [f(t) conjugate(f(δ)) f(t + δ)]\n\nWait, that's still not matching. Alternatively, perhaps rearrange terms:\n\ndet(M) = f(0)[f(0)^2 - |f(δ)|² - |f(t)|² - |f(t + δ)|²] + 2 Re [f(t) conjugate(f(δ)) f(t + δ)]\n\nThis doesn't seem directly related to |f(t) - f(t + δ)|². Maybe this approach isn't leading anywhere. Let's think differently.\n\nGiven that f is continuous at 0, for any ε > 0, there exists δ > 0 such that |δ| < δ implies |f(δ) - f(0)| < ε. We need to show that for any t, |f(t + h) - f(t)| → 0 as h → 0.\n\nConsider the positive-definite property with points 0, h, and t + h. The matrix A_f[0, h, t + h] is positive semidefinite. Perhaps using the fact that the quadratic form for this matrix is non-negative for any vector v. Let's choose a specific vector to get an inequality involving |f(t + h) - f(t)|.\n\nLet’s take v = [a, b, c] and compute v* A_f v ≥ 0. To target the difference f(t + h) - f(t), maybe choose coefficients a, b, c such that when multiplied by the matrix, we get terms involving this difference. \n\nAlternatively, consider a vector v = [1, -1, 0]. Then:\n\nv* A_f v = [1, -1, 0] A_f [1; -1; 0] = f(0)(1) + f(0)(-1)(-1) + ... Wait, maybe this isn't the right approach. Let me compute it properly.\n\nThe quadratic form is:\n\nRow 1: f(0)*1*1 + f(-h)*1*(-1) + f(-t - h)*1*0\n\nRow 2: f(h)*(-1)*1 + f(0)*(-1)*(-1) + f(-t)*(-1)*0\n\nRow 3: f(t + h)*0*1 + f(t + h - h)*0*(-1) + f(0)*0*0\n\nSo summing up:\n\n= f(0) - f(-h) - f(h) + f(0) + 0 + 0 + 0 + 0 + 0\n\n= 2f(0) - [f(h) + f(-h)]\n\nBut since f(-h) = conjugate(f(h)), so this becomes 2f(0) - 2 Re(f(h)). Since the quadratic form must be ≥ 0:\n\n2f(0) - 2 Re(f(h)) ≥ 0 ⇒ Re(f(h)) ≤ f(0)\n\nBut we already knew that |f(h)| ≤ f(0), so this doesn't add much. \n\nAlternatively, try a different vector. Let's take v = [1, 0, -1]. Then:\n\nv* A_f v = [1, 0, -1] A_f [1; 0; -1]\n\nCompute each term:\n\nRow 1: f(0)*1*1 + f(-h)*1*0 + f(-t - h)*1*(-1)\n\nRow 2: f(h)*0*1 + f(0)*0*0 + f(-t)*0*(-1)\n\nRow 3: f(t + h)*(-1)*1 + f(t + h - h)*(-1)*0 + f(0)*(-1)*(-1)\n\nSo summing up:\n\n= f(0) - f(-t - h) - f(t + h) + f(0)\n\n= 2f(0) - [f(t + h) + f(-t - h)]\n\nBut f(-t - h) = conjugate(f(t + h)), so this becomes 2f(0) - 2 Re(f(t + h)) ≥ 0 ⇒ Re(f(t + h)) ≤ f(0), which again we already knew.\n\nHmm, not helpful. Let's try a vector that combines t and t + h. For example, take points 0, t, t + h and use a vector that relates to the difference f(t + h) - f(t). Let's try v = [0, 1, -1]. Then:\n\nv* A_f v = [0, 1, -1] A_f [0; 1; -1]\n\nCompute each term:\n\nRow 1: f(0)*0*0 + f(-t)*0*1 + f(-t - h)*0*(-1)\n\nRow 2: f(t)*1*0 + f(0)*1*1 + f(-h)*1*(-1)\n\nRow 3: f(t + h)*(-1)*0 + f(h)*(-1)*1 + f(0)*(-1)*(-1)\n\nSo summing up:\n\n= 0 + [f(0) - f(-h)] + [ -f(h) + f(0) ]\n\n= 2f(0) - [f(h) + f(-h)]\n\nAgain, same as before. This gives 2f(0) - 2 Re(f(h)) ≥ 0, which is redundant.\n\nPerhaps a different approach is needed. Let's recall that for any t, the function f is bounded by f(0), and we want to show that the difference |f(t + δ) - f(t)| can be controlled by |f(δ) - f(0)|.\n\nConsider the following identity:\n\nf(t + δ) - f(t) = [f(t + δ) - f(0)] - [f(t) - f(0)]\n\nBut this might not help directly. Alternatively, use the positive-definite property with a specific set of points. Let's take four points: 0, δ, t, and t + δ. The corresponding 4x4 matrix is complicated, but maybe using a 2x2 matrix with points t and t + δ, but as before, the entries are f(0) and f(±δ).\n\nWait, perhaps use the fact that for any complex number a, the matrix:\n\n[ f(0)      a        ]\n[ \\overline{a} f(0) ]\n\nis positive semidefinite if and only if |a| ≤ f(0). But this is the 2x2 case, which we already know.\n\nAlternatively, think of the function f as being of positive type, and use the fact that such functions satisfy |f(t) - f(s)|² ≤ 2f(0)(f(0) - Re(f(t - s))). This is a known inequality for positive-definite functions. If this is the case, then since f is continuous at 0, Re(f(t - s)) can be made close to f(0) when t - s is small, thereby making |f(t) - f(s)| small.\n\nBut how to derive this inequality. Let's consider two points t and s, and set τ = t - s. Then consider the matrix:\n\n[ f(0)      f(τ)     ]\n[ f(-τ)     f(0)     ]\n\nThis matrix is positive semidefinite, so for any complex numbers a and b, we have:\n\na \\overline{a} f(0) + a \\overline{b} f(τ) + b \\overline{a} f(-τ) + b \\overline{b} f(0) ≥ 0\n\nLet’s choose a = 1 and b = -1. Then:\n\nf(0) + (-1)f(τ) + (-1)f(-τ) + f(0) ≥ 0 ⇒ 2f(0) - (f(τ) + f(-τ)) ≥ 0 ⇒ 2f(0) - 2 Re(f(τ)) ≥ 0 ⇒ Re(f(τ)) ≤ f(0)\n\nWhich we already knew. But if we choose different a and b, maybe we can get a different inequality. Let's set a = 1 and b = e^{iθ}, and find θ that maximizes the expression. Alternatively, set a = 1 and b = -e^{iθ} where θ is the argument of f(τ). Then:\n\nThe expression becomes:\n\nf(0) + (-e^{iθ}) f(τ) + (-e^{-iθ}) f(-τ) + |b|² f(0)\n\nSince |b|² = 1, this is:\n\nf(0) - e^{iθ} f(τ) - e^{-iθ} \\overline{f(τ)} + f(0) = 2f(0) - [e^{iθ} f(τ) + e^{-iθ} \\overline{f(τ)}]\n\nIf we choose θ such that e^{iθ} f(τ) is real and positive, then this becomes 2f(0) - 2|f(τ)|. Since the expression must be ≥ 0, this gives |f(τ)| ≤ f(0), which we already know.\n\nAlternatively, choose a = 1 and b = -1, leading to:\n\n2f(0) - (f(τ) + \\overline{f(τ)}) = 2(f(0) - Re(f(τ))) ≥ 0 ⇒ Re(f(τ)) ≤ f(0)\n\nStill not helpful for the difference.\n\nWait, maybe consider the following approach inspired by the Cauchy-Schwarz inequality for positive-definite functions. For any t, s ∈ ℝ,\n\n|f(t) - f(s)|² ≤ 2f(0)(f(0) - Re(f(t - s)))\n\nIf this inequality holds, then as t - s → 0, Re(f(t - s)) → f(0) due to continuity at 0, hence |f(t) - f(s)|² → 0, proving continuity.\n\nBut how to derive this inequality. Let's attempt it. Take points 0 and τ = t - s. Construct a vector v = [1, -1]. Then:\n\nv* A_f v = f(0)(1)(1) + f(τ)(1)(-1) + f(-τ)(-1)(1) + f(0)(-1)(-1)\n\n= f(0) - f(τ) - f(-τ) + f(0)\n\n= 2f(0) - (f(τ) + f(-τ))\n\nSince A_f is positive semidefinite, this expression must be ≥ 0. Thus,\n\n2f(0) - 2 Re(f(τ)) ≥ 0 ⇒ Re(f(τ)) ≤ f(0)\n\nBut we need an inequality involving |f(t) - f(s)|. Let's express |f(t) - f(s)|²:\n\n|f(t) - f(s)|² = |f(τ) - f(0)|² = |f(τ) - f(0)|²\n\nWait, no. If τ = t - s, then f(t) - f(s) = f(τ + s) - f(s). Wait, perhaps I'm getting confused.\n\nWait, if we set s = 0, then |f(t) - f(0)|² ≤ 2f(0)(f(0) - Re(f(t))). But this isn't directly helpful unless we relate it to continuity away from 0.\n\nAlternatively, consider points t and t + δ. Let τ = δ. Then:\n\n|f(t + δ) - f(t)|² = |f(t + δ) - f(t)|²\n\nTo relate this to the positive-definite property, perhaps consider three points: 0, δ, and t. Construct a suitable quadratic form. \n\nLet me try using the 3x3 matrix again but focus on a specific quadratic form. Let’s take vector v = [a, b, c] and choose a, b, c to target the difference f(t + δ) - f(t). For example, set a = 0, b = 1, c = -1. Then:\n\nv* A_f v = [0, 1, -1] A_f [0; 1; -1]\n\nWhich we computed earlier as 2f(0) - [f(δ) + f(-δ)] = 2f(0) - 2 Re(f(δ)). But this doesn't involve t. \n\nAlternatively, set v = [1, e^{-iθ}, e^{-iθ}], but I’m not sure. \n\nPerhaps there's a different inequality. Since f is positive-definite, it satisfies the Cauchy-Schwarz inequality: |f(t) - f(s)|² ≤ 2f(0)(f(0) - Re(f(t - s))). If this holds, then because f is continuous at 0, as δ → 0, Re(f(δ)) → f(0), so the right-hand side goes to 0, proving continuity at any t.\n\nBut how to derive this inequality. Let’s take two points, t and s, and consider the matrix:\n\n[ f(0)      f(t - s) ]\n[ f(s - t)  f(0)    ]\n\nThis matrix is positive semidefinite. For any complex numbers a, b, we have:\n\n|a|² f(0) + a \\overline{b} f(t - s) + \\overline{a} b f(s - t) + |b|² f(0) ≥ 0\n\nLet’s set a = 1 and b = -1. Then:\n\nf(0) + (-1)f(t - s) + (-1)f(s - t) + f(0) ≥ 0 ⇒ 2f(0) - [f(t - s) + f(s - t)] ≥ 0\n\nBut f(s - t) = \\overline{f(t - s)}, so this becomes 2f(0) - 2 Re(f(t - s)) ≥ 0 ⇒ Re(f(t - s)) ≤ f(0). Again, we knew this.\n\nBut to get an inequality involving |f(t) - f(s)|, perhaps use different a and b. Let’s set a = 1 and b = e^{iθ}, and optimize over θ. The expression becomes:\n\nf(0) + e^{-iθ} f(t - s) + e^{iθ} \\overline{f(t - s)} + |b|² f(0) ≥ 0\n\nSince |b|² = 1, this is:\n\n2f(0) + 2 Re(e^{iθ} \\overline{f(t - s)}) ≥ 0\n\nTo find the maximum possible value of |f(t) - f(s)|, relate it to this inequality. Alternatively, consider that for any θ,\n\nRe(e^{iθ} \\overline{f(t - s)}) ≥ -f(0)\n\nBut this seems not directly helpful.\n\nPerhaps another route. Since we have |f(t)| ≤ f(0) for all t, the function is bounded. To show continuity at t, note that:\n\n|f(t + δ) - f(t)| ≤ |f(t + δ) - f(0)| + |f(0) - f(t)|\n\nBut this is using the triangle inequality and doesn't use the positive-definite property. Moreover, we need to relate the difference at t to the continuity at 0.\n\nAlternatively, use the positive-definite property to write:\n\n|f(t + δ) - f(t)|² ≤ 2f(0)(f(0) - Re(f(δ)))\n\nThis inequality would directly relate the difference at t to the behavior at δ, which is controlled by continuity at 0. If this inequality holds, then as δ → 0, Re(f(δ)) → f(0), hence the right-hand side tends to 0, and so does |f(t + δ) - f(t)|.\n\nBut how to derive this inequality. Let’s consider the matrix for points 0, δ, and t + δ. Then use the positive semidefinite condition with a specific vector. Let’s take v = [1, -1, 0]. Then:\n\nv* A_f v = [1, -1, 0] A_f [1; -1; 0]\n\nWe computed this earlier as 2f(0) - 2 Re(f(δ)) ≥ 0. But this doesn't involve t. \n\nAlternatively, take a vector that includes t. Let’s take v = [1, -e^{iθ}, -e^{iφ}], but this might get too complex. Alternatively, let's use the 3x3 matrix determinant approach again. If the determinant is non-negative, then:\n\nf(0)|f(t) - f(t + δ)|² ≤ (other terms)\n\nIf the other terms can be bounded using |f(δ) - f(0)|, then we can proceed. However, the determinant expression is complicated. Let’s assume that after simplifying, the determinant yields an inequality like:\n\nf(0)|f(t) - f(t + δ)|² ≤ (f(0)^2 - |f(δ)|^2)(f(0) - |f(t)|^2)\n\nBut since |f(δ)| ≤ f(0) and |f(t)| ≤ f(0), the right-hand side involves terms like f(0)^2 - |f(δ)|^2, which is ≤ f(0)^2. But this doesn't directly help unless we can relate it to |f(δ) - f(0)|. \n\nAlternatively, note that f(0)^2 - |f(δ)|^2 = (f(0) - |f(δ)|)(f(0) + |f(δ)|) ≤ 2f(0)(f(0) - |f(δ)|). Since |f(δ)| ≤ f(0), and f is continuous at 0, we have f(0) - |f(δ)| ≤ |f(0) - |f(δ)|| ≤ |f(0) - f(δ)| → 0 as δ → 0. \n\nThus, if the determinant inequality gives:\n\nf(0)|f(t) - f(t + δ)|² ≤ 2f(0)(f(0) - |f(δ)|) * (f(0) - |f(t)|^2)\n\nAssuming f(0) > 0, divide both sides by f(0):\n\n|f(t) - f(t + δ)|² ≤ 2(f(0) - |f(δ)|)(f(0) - |f(t)|^2)\n\nAs δ → 0, f(δ) → f(0), so f(0) - |f(δ)| → 0, hence the right-hand side → 0, proving continuity. But this requires that the determinant indeed gives such an inequality, which I'm not sure about.\n\nAlternatively, maybe use the fact that for any ε > 0, since f is continuous at 0, there exists δ > 0 such that |f(δ)| ≥ f(0) - ε. Then using the inequality Re(f(δ)) ≤ f(0), we can bound the difference.\n\nBut I'm not making progress here. Let me look for a different approach. Since we have the property that |f(t)| ≤ f(0), and f is positive-definite, perhaps use the fact that the function is uniformly continuous. However, we need to prove continuity everywhere using continuity at 0.\n\nWait, here's a standard result in harmonic analysis: a positive-definite function is continuous everywhere if it is continuous at 0. The proof usually involves Bochner's theorem, but since we might not have that, let's think of another way.\n\nAnother approach: use the fact that the positive-definite functions are Fourier transforms of finite measures (Bochner's theorem), but since the problem doesn't assume this, let's try to proceed without it.\n\nAlternatively, use the inequality that for any h, |f(t + h) - f(t)|² ≤ 2f(0)(f(0) - Re(f(h))). This is a known inequality for positive-definite functions. If this holds, then since f is continuous at 0, as h → 0, Re(f(h)) → f(0), so the right-hand side tends to 0, implying continuity at t.\n\nTo derive this inequality, consider the matrix:\n\n[ f(0)      f(t)        f(t + h) ]\n[ f(-t)     f(0)        f(h)     ]\n[ f(-t - h) f(-h)       f(0)     ]\n\nThis matrix is positive semidefinite. Take the determinant of the 2x2 matrix formed by the first and third rows and columns. Wait, but how.\n\nAlternatively, use the fact that for any complex numbers a and b, the expression:\n\na \\overline{a} f(0) + a \\overline{b} f(t) + b \\overline{a} f(-t) + b \\overline{b} f(0) ≥ 0\n\nLet’s set a = 1 and b = -e^{iθ}, then:\n\nf(0) - e^{iθ} f(t) - e^{-iθ} f(-t) + f(0) ≥ 0 ⇒ 2f(0) - 2 Re(e^{iθ} f(t)) ≥ 0\n\nThis holds for any θ. Choose θ such that e^{iθ} f(t) = |f(t)|. Then,\n\n2f(0) - 2|f(t)| ≥ 0 ⇒ |f(t)| ≤ f(0), which we already know.\n\nNot helpful. \n\nAlternatively, consider the function g(h) = f(t + h) - f(t). We want to show that g(h) → 0 as h → 0. Note that g(0) = 0. If we can relate g(h) to the continuity at 0, perhaps via the positive-definite property.\n\nConsider the matrix for points 0, h, and t + h. The positive semidefinite condition might allow us to bound |g(h)|².\n\nAlternatively, use the fact that the sum of positive-definite functions is positive-definite, and products as well under certain conditions, but this might not help here.\n\nWait, let's go back to the user's idea involving the determinant. They mentioned that det(A_f[0, t, t + δ]) can be written as f(0)|f(t) - f(t + δ)|². If that's the case, then since the determinant is non-negative, and f(0) ≥ 0, this implies that |f(t) - f(t + δ)|² ≥ 0, which is always true. But perhaps there are other terms in the determinant that must also be considered. Maybe the user was incorrect in their simplification, but let's assume for a moment that the determinant is approximately f(0)|f(t) - f(t + δ)|² minus something else, which must be less than or equal to f(0)|f(t) - f(t + δ)|². Then the non-negativity of the determinant would imply that the something else is bounded by f(0)|f(t) - f(t + δ)|². But this seems circular.\n\nAlternatively, suppose that the determinant expression includes f(0)|f(t) - f(t + δ)|² plus other non-negative terms. Then the non-negativity of the determinant would imply that f(0)|f(t) - f(t + δ)|² must be greater than or equal to the negative of those other terms. But since all terms in a positive semidefinite matrix's determinant are non-negative (?), this might not hold. \n\nI think I'm stuck here. Let me try to look for a different approach inspired by the properties we have.\n\nWe know that f is continuous at 0. We need to show it's continuous everywhere. Given that |f(t + δ) - f(t)| ≤ |f(t + δ) - f(0)| + |f(t) - f(0)|. But since f is continuous at 0, this would require that f is continuous at t, but this is what we need to prove, so this approach isn't valid.\n\nAlternatively, use the fact that the positive-definite function's continuity at 0 implies uniform continuity. But how?\n\nWait, here's a key insight: for positive-definite functions, continuity at 0 implies uniform continuity. The standard proof uses the inequality |f(t + h) - f(t)|² ≤ 2f(0)(f(0) - Re(f(h))), which I mentioned earlier. Given that f is continuous at 0, for any ε > 0, there exists δ > 0 such that |h| < δ implies |f(0) - Re(f(h))| < ε. Then the inequality gives |f(t + h) - f(t)|² ≤ 2f(0)ε, which can be made arbitrarily small, proving uniform continuity.\n\nBut to derive this inequality, let's consider the positive-definite property with points 0 and h. The matrix:\n\n[ f(0)      f(t)        f(t + h) ]\n[ f(-t)     f(0)        f(h)     ]\n[ f(-t - h) f(-h)       f(0)     ]\n\nIs positive semidefinite. Therefore, the quadratic form for any vector v must be non-negative. Let's choose v = [1, -1, 0]. Then:\n\nv* A_f v = [1, -1, 0] A_f [1; -1; 0] = f(0) - f(t) - f(-t) + f(0) = 2f(0) - 2 Re(f(t)) ≥ 0\n\nThis gives Re(f(t)) ≤ f(0), which we already knew. Not helpful.\n\nAlternatively, choose v = [1, 0, -1]. Then:\n\nv* A_f v = [1, 0, -1] A_f [1; 0; -1] = f(0) - f(t + h) - f(-t - h) + f(0) = 2f(0) - 2 Re(f(t + h)) ≥ 0\n\nAgain, Re(f(t + h)) ≤ f(0). Not helpful.\n\nAnother vector: v = [0, 1, -1]. Then:\n\nv* A_f v = [0, 1, -1] A_f [0; 1; -1] = f(0) - f(h) - f(-h) + f(0) = 2f(0) - 2 Re(f(h)) ≥ 0 ⇒ Re(f(h)) ≤ f(0)\n\nBut how to get the desired inequality involving |f(t + h) - f(t)|.\n\nLet’s finally try to consider the following approach inspired by the user’s mention of the 3x3 determinant. Suppose that the determinant of the matrix A_f[0, t, t + δ] can be written as f(0)|f(t) - f(t + δ)|² minus other terms, and since the determinant is non-negative, this implies that f(0)|f(t) - f(t + δ)|² is at least as large as those other terms. If those other terms can be bounded by something that goes to zero as δ approaches 0 due to continuity at 0, then |f(t) - f(t + δ)| must also go to zero.\n\nAssume that after expanding the determinant, we have:\n\ndet(A_f[0, t, t + δ]) = f(0)|f(t) - f(t + δ)|² - B,\n\nwhere B is some expression involving terms that can be controlled by the continuity at 0. Since the determinant is non-negative, we have:\n\nf(0)|f(t) - f(t + δ)|² ≥ B.\n\nIf B is non-negative, then this inequality gives a lower bound on |f(t) - f(t + δ)|². But we need an upper bound. Hence, this approach might not work unless B can be expressed in a way that relates to the continuity at 0.\n\nAlternatively, suppose that the determinant expression includes f(0)|f(t) - f(t + δ)|² plus other non-negative terms. Then, since the determinant is non-negative, those terms must be non-negative, implying that f(0)|f(t) - f(t + δ)|² must be less than or equal to the determinant plus the other terms. But without knowing the exact form, it's hard to proceed.\n\nGiven the time I've spent and the lack of progress, I think I need to recall that in the theory of positive-definite functions, continuity at 0 implies continuity everywhere, and this is typically proven using the inequality involving the real part of f(h). Specifically, the key step is to show that |f(t + h) - f(t)|² ≤ 2f(0)(f(0) - Re(f(h))), which then allows one to use the continuity at 0 to establish continuity at t.\n\nTo derive this inequality, let's consider the positive-definite function property with points 0, h, and t. The matrix:\n\n[ f(0)      f(-h)      f(-t)     ]\n[ f(h)      f(0)       f(h - t)  ]\n[ f(t)      f(t - h)   f(0)      ]\n\nThis matrix is positive semidefinite. Consider the following quadratic form with vector v = [1, -1, 0]:\n\nv* A_f v = f(0) - f(-h) - f(h) + f(0) = 2f(0) - 2 Re(f(h)) ≥ 0\n\nBut this again just gives Re(f(h)) ≤ f(0).\n\nAlternatively, use a different vector. Let’s set v = [1, -e^{iθ}, -e^{iφ}} and choose θ and φ to target the desired terms. This might be too vague.\n\nGiven that I'm stuck, I'll concede that the key inequality must be |f(t + h) - f(t)|² ≤ 2f(0)(f(0) - Re(f(h))), and since Re(f(h)) approaches f(0) as h → 0 due to continuity at 0, the right-hand side approaches 0, proving continuity at t.\n\nTherefore, the formatted problem should capture the assumptions from the original question and present the problem succinctly.",
    "Original_Problem": "Assumption: \n$f:\\mathbb{R}\\to \\mathbb{C}$ is a positive-definite function,\n$f$ is continuous at $0$.\nProblem: \nProve that $f$ is continuous everywhere on $\\mathbb{R}$.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $f:\\mathbb{R}\\to \\mathbb{C}$ is a positive-definite function,\nAssumption 2: $f$ is continuous at $0$.\nProblem: \nProve that $f$ is continuous everywhere on $\\mathbb{R}$.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$\nA=\\pmatrix{\nf(0)   &f(-t) &f(-t-h)\\\\\nf(t)   &f(0)  &f(-h)\\\\\nf(t+h) &f(h)  &f(0)}\n$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $f:\\mathbb{R}\\to \\mathbb{C}$ is a positive-definite function,\nAssumption 2: $f$ is continuous at $0$.\nAssumption 3: $$\nA=\\pmatrix{\nf(0)   &f(-t) &f(-t-h)\\\\\nf(t)   &f(0)  &f(-h)\\\\\nf(t+h) &f(h)  &f(0)}\n$$\nProblem: \nProve that $f$ is continuous everywhere on $\\mathbb{R}$."
}