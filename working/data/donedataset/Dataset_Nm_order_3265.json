{
    "Link_API": "https://api.stackexchange.com/2.3/questions/1618",
    "Title": "Is the natural map $L^p(X) \\otimes L^p(Y) \\to L^p(X \\times Y)$ injective?",
    "Score": 12,
    "Category": "Chứng minh",
    "Tags": "linear-algebra, real-analysis, functional-analysis",
    "Link": "https://math.stackexchange.com/questions/1618/is-the-natural-map-lpx-otimes-lpy-to-lpx-times-y-injective",
    "Content": "Let $X,Y$ be $\\sigma$-finite measure spaces, and let $L^p(X) \\otimes L^p(Y)$ be the algebraic tensor product.  The product has a natural map into $L^p(X \\times Y)$ which takes $\\sum a_{ij} f_i \\otimes g_j$ to the function $F(x,y) = \\sum a_{ij} f_i(x) g_j(y)$.  A moment's thought shows that this map is well-defined.  Is it also injective? It seems that this should be true, but I can't see how to prove it.  Intuitively, one needs to show that if $\\sum a_{ij} f_i(x) g_j(y) = 0$ a.e., then one should be able to cancel all the terms in the sum using bilinearity.  It is not quite clear how to do this without knowing anything about the terms.",
    "AcceptedAnswer": "The previous version of this answer was incorrect. It has generously been accepted by Nate Eldredge on the ground that \"it definitely contains the right idea\". This previous version has better remain forgotten forever. The reader should consult Nate's answer , which is correct and complete. I'll just try here to spell out the underlying linear algebra lemma (which is trivial, but which I failed to see). UNDERLYING LEMMA. Let $U,V,W$ vector spaces over some field $K$, and $\\alpha:U\\otimes V\\to W$ a linear map. Assume that for each nonzero vector $u_0$ in $U$ there are linear maps $\\beta:W\\to V$ and $\\gamma:U\\to K$ such that $\\gamma(u_0)\\not=0$ and \n  $$\\beta(\\alpha(u\\otimes v))=\\gamma(u)v\\ \\forall\\ u,v.$$ Then $\\alpha$ is injective. The proof can be very easily extracted from Nate's answer . Here is the most standard application: APPLICATION. Let $U,V,W$ be respectively the spaces of $K$-valued functions on the sets $X,Y,X\\times Y$, and $\\beta,\\gamma$ are given by $(\\beta(w))(y)=w(x_0,y)$, $\\gamma(u)=u(x_0)$ where $x_0$ is chosen so that $u_0(x_0)\\not=0$. EDIT. Here is a mild generalization. Let $X$ be a measure space, let $\\mathcal V(X)$ be the vector space of all measurable complex valued functions on $X$, let $\\mathcal N$ be the subspace of functions vanishing almost everywhere, and let $V(X)$ be the quotient. [Is there a standard notation for these spaces?] Let $Y$ be another measure space. The bilinear map from $\\mathcal V(X)\\times\\mathcal V(Y)$ to $\\mathcal V(X\\times Y)$ sending $(f,g)$ to $(x,y)\\mapsto f(x)g(y)$ induces a linear map $\\Phi$ from $V(X)\\otimes V(Y)$ to $V(X\\times Y)$. THEOREM. Assume $X$ and $Y$ are $\\sigma$-finite. Then $\\Phi$ is injective. This slightly more general than the statement proved in Nate's answer because no integrability assumptions are made on the functions. LEMMA. Let $f_i,\\dots,f_n$ be in $\\mathcal V(X)$, and $S\\subset X^n$ the set of $x\\in X^n$ such that $\\det(f_i(x_j))\\not=0$. Then the $f_i$ are linearly independent in $V(X)$ if and only if the measure of $S$ is positive. Denote by $|A|$ the measure of $A$, and by $S_g$ the support of the function $g$, that is the set of points where it is nonzero. Put $d(x):=\\det(f_i(x_j))$ for $x\\in X^n$. The above set $S$ is now $S_d$. To prove the if part of the lemma, assume the $f_i$ are linearly dependent in $V(X)$ and check $|S_d|=0$ as follows. Let $\\lambda$ be a nonzero vector of $\\mathbb C^n$ such that $g:=\\sum \\lambda_i f_i$ satisfies $|S_g|=0$. Denote again by $\\lambda$ the 1 by $n$ matrix formed by the $\\lambda_i$, and by $A(x)$ the matrix $(f_i(x_j))$. For $x$ in $(S_g^c)^n$, where the superscript c mean \"complement\", we have $\\lambda A(x)=0$. Multiplying on the right by the adjugate of $A(x)$ we get $d(x)=0$. This shows that $S_d$ is contained in the measure zero subset $((S_g^c)^n)^c$ of $X^n$. To prove the only if part of the lemma, assume $|S_d|=0$ and check that the $f_i$ are linearly dependent in $V(X)$ as follows. Expand $d(x)$ as $$d(x)=\\sum\\ d_i(x')\\ f_i(x_n)$$ with $x':=(x_1,\\dots,x_{n-1})$. Arguing by induction, we can assume $|S_{d_i}|>0$ for all $i$. Let $U$ be the union of the $S_{d_i}$. Denoting by $d(x',\\bullet)$ the function $x_n\\mapsto d(x)$, we have\n$$S_d=\\bigcup_{x'\\in X^{n-1}}\\ \\{x'\\}\\times S_{d(x',\\bullet)}.$$ Fubini yields\n$$0=|S_d|=\\int_{X^{n-1}}\\ |S_{d(x',\\bullet)}|\\ dx'.$$\nIf the $f_i$ were linearly independent in $V(X)$, we would have $|S_{d(x',\\bullet)}|>0$ for all $x'$ in $U$, a contradiction. The lemma is proved. Let's prove the theorem. In the next lines, $i,j,k$ will lie between 1 and $m$, whereas $p,q,r$ will lie between 1 and $n$. Let $f_1,\\dots,f_m$ be in $\\mathcal V(X)$; let $g_1,\\dots,g_n$ be in $\\mathcal V(Y)$; and put $F_{ip}(x,y):=f_i(x)g_p(y)$. The theorem is equivalent to the statement that the linear independence of the $f_i$ and $g_p$ in $V(X)$ and $V(Y)$ implies that of the $F_{ip}$ in $V(X\\times Y)$. Let $S\\subset X^m$ and $T\\subset Y^n$ be defined by the conditions $\\det(f_i(x_j))\\not=0$ and $\\det(g_p(y_q))\\not=0$. Embedd $U:=S^n\\times T^m$ into $(X\\times Y)^{mn}$ in the obvious way, and denote the $(i,p)$-th coordinate of $z\\in(X\\times Y)^{mn}$ by $z_{ip}=(x_{pi},y_{ip})$. Then $z$ is in $U$ iff $x_p\\in S$ and $y_i\\in T$ for all $(i,p)$, that is iff\n$$\\det\\Big(f_j(x_{pk})\\Big)_{jk}\\not=0\\not\n=\\det\\Big(g_q(y_{ir})\\Big)_{qr}$$\nfor all $(i,p)$. We claim that the validity of this double nonequality for all $(i,p)$ implies the nonequality\n$$\\det\\Big(f_i(x_{qj})\\ g_p(y_{jq})\\Big)_{(i,p)(j,q)}\\not=0.$$\nIn view of the lemma, the theorem is equivalent to the claim. But the claim doesn't depend on the measures defined on $X$ and $Y$. As the theorem holds when $X$ and $Y$ are equipped with the counting measure (see the application of the \"underlying lemma\" at the beginning of the post), we are done.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$X$ is a $\\sigma$-finite measure space,\n$Y$ is a $\\sigma$-finite measure space,\n$L^p(X)$ is the space of $p$-integrable functions on $X$,\n$L^p(Y)$ is the space of $p$-integrable functions on $Y$,\n$L^p(X) \\otimes L^p(Y)$ is the algebraic tensor product,\nThe natural map $L^p(X) \\otimes L^p(Y) \\to L^p(X \\times Y)$ is defined by $\\sum a_{ij} f_i \\otimes g_j \\mapsto \\sum a_{ij} f_i(x)g_j(y)$.\nProblem: \nProve that the natural map $L^p(X) \\otimes L^p(Y) \\to L^p(X \\times Y)$ is injective.\n###END_OF_FORMAT###",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem. The user is asking whether the natural map from the algebraic tensor product of L^p(X) and L^p(Y) into L^p(X × Y) is injective. Both X and Y are σ-finite measure spaces.\n\nFirst, I need to recall some basic facts about tensor products and L^p spaces. The algebraic tensor product L^p(X) ⊗ L^p(Y) consists of finite linear combinations of elements of the form f ⊗ g, where f is in L^p(X) and g is in L^p(Y). The map in question sends these to functions on X × Y by multiplying f(x) and g(y). The question is whether this map is injective, meaning that if a tensor is mapped to the zero function in L^p(X × Y), then the tensor itself must be zero.\n\nThe user mentions that the map is well-defined, which makes sense because the product of L^p functions on product spaces should be in L^p again due to Hölder's inequality, but injectivity is the main concern here.\n\nSo, to rephrase the problem: If a finite sum Σ a_{ij} f_i(x)g_j(y) equals zero almost everywhere on X × Y, does it follow that the tensor Σ a_{ij} f_i ⊗ g_j is zero in the algebraic tensor product? That is, can we conclude that all coefficients a_{ij} are zero, or that the combination can be simplified to zero via the bilinear relations?\n\nMy initial thought is that for the algebraic tensor product, injectivity would require that the functions f_i and g_j are linearly independent in their respective spaces. However, since we are dealing with equivalence classes of functions (L^p spaces), there might be issues with functions being zero almost everywhere but not identically zero. But the tensor product is algebraic, so we consider them as vectors in the vector space, not accounting for measure zero differences. Wait, but in L^p spaces, functions are equivalence classes, so equality is almost everywhere. Hmm, this might complicate things.\n\nWait, the algebraic tensor product here is probably of the vector spaces L^p(X) and L^p(Y), treating them as vector spaces, not as Banach spaces. But since L^p spaces are vector spaces over ℝ or ℂ, the algebraic tensor product is well-defined. However, the map into L^p(X × Y) is defined by sending f ⊗ g to the function F(x,y) = f(x)g(y). But since in L^p, functions are equal if they agree almost everywhere, the question is whether distinct tensors can map to the same equivalence class in L^p(X × Y).\n\nBut injectivity here would mean that if two different tensors are mapped to the same function in L^p(X × Y), then they must be the same in the tensor product. But since the algebraic tensor product is a quotient of the free vector space, injectivity would require that the map doesn't collapse distinct tensors to the same function.\n\nAlternatively, suppose that the sum Σ a_{ij} f_i(x)g_j(y) = 0 a.e. on X × Y. We need to show that Σ a_{ij} f_i ⊗ g_j = 0 in L^p(X) ⊗ L^p(Y). In the tensor product, this would mean that the sum can be written as a combination of bilinear relations, i.e., the coefficients a_{ij} are such that they can be expressed as combinations that vanish due to the bilinear structure.\n\nBut how do we go from the function being zero a.e. to the coefficients being zero? For finite linear combinations, if the functions f_i and g_j are linearly independent, then the product functions f_i(x)g_j(y) would be linearly independent in L^p(X × Y), which would imply that the coefficients a_{ij} must all be zero. But are they linearly independent?\n\nWait, but in general, even if f_i are linearly independent in L^p(X) and g_j are linearly independent in L^p(Y), their tensor products might not be linearly independent in L^p(X × Y) due to possible overlaps in their supports or other relations. Hmm, but maybe not. If {f_i} is a linearly independent set in L^p(X) and {g_j} is a linearly independent set in L^p(Y), then {f_i ⊗ g_j} is linearly independent in L^p(X) ⊗ L^p(Y), right? Because in the algebraic tensor product, the tensor product of linearly independent sets is linearly independent.\n\nBut when we map this into L^p(X × Y), which is a space of equivalence classes, the question is whether the images remain linearly independent. If they do, then the map would be injective.\n\nHowever, linear independence in the algebraic tensor product doesn't automatically translate to linear independence in L^p(X × Y) because equivalence in L^p is up to measure zero. For example, two different tensor products could produce functions that are equal almost everywhere, hence equivalent in L^p, but different in the algebraic tensor product.\n\nBut the question is about the injectivity of the map from the algebraic tensor product into L^p(X × Y). So, if the image of a non-zero tensor is the zero function in L^p(X × Y), then the map is not injective. So, we need to check whether such a non-zero tensor can map to zero.\n\nSuppose we have a non-zero tensor in L^p(X) ⊗ L^p(Y). This tensor can be written as a finite sum Σ a_{ij} f_i ⊗ g_j, where not all a_{ij} are zero. If the image of this sum is zero in L^p(X × Y), then Σ a_{ij} f_i(x)g_j(y) = 0 a.e. in X × Y. The question is: does this imply that all a_{ij} are zero, i.e., that the tensor is zero?\n\nIf we can show that the functions f_i ⊗ g_j are linearly independent in L^p(X × Y), then this would be true. But as they are equivalence classes, it's possible that even if f_i and g_j are non-zero, f_i ⊗ g_j could be zero in L^p(X × Y) if, say, f_i is zero almost everywhere or g_j is zero almost everywhere. But if f_i and g_j are non-zero in their respective spaces, then f_i ⊗ g_j is non-zero in L^p(X × Y) because the product would be non-zero on a set of positive measure (since X and Y are σ-finite).\n\nWait, but even if f_i and g_j are non-zero, their product might vanish on a set of full measure. But how? For example, if f_i is non-zero on A ⊆ X and g_j is non-zero on B ⊆ Y, then f_i ⊗ g_j is non-zero on A × B. Since f_i is non-zero a.e. (as an element of L^p), then A is conull in X, and similarly B is conull in Y. Therefore, A × B is conull in X × Y, so f_i ⊗ g_j is non-zero a.e. on X × Y. Hence, if all the f_i and g_j are non-zero in their respective spaces, then their tensor products are non-zero in L^p(X × Y).\n\nTherefore, if we have a linear combination Σ a_{ij} f_i ⊗ g_j that maps to zero in L^p(X × Y), then each coefficient a_{ij} must be zero. But this is under the assumption that the f_i and g_j are linearly independent. However, in the algebraic tensor product, we can have expressions where f_i or g_j are not linearly independent. But in that case, the tensor product can be rewritten in terms of a basis.\n\nWait, perhaps we need to use the fact that in L^p spaces, we can choose representatives of the equivalence classes such that they are actually functions, and then use Fubini's theorem or some kind of argument where we fix x or y and integrate.\n\nSuppose F(x,y) = Σ a_{ij} f_i(x) g_j(y) = 0 a.e. on X × Y. Then, for almost every x, F(x, y) = 0 for almost every y. Fix such an x where this holds. Then, for that x, Σ a_{ij} f_i(x) g_j(y) = 0 for almost every y. Since the g_j are in L^p(Y), and assuming they are linearly independent, this would imply that for each j, Σ_i a_{ij} f_i(x) = 0. But this holds for almost every x. Then, since the f_i are in L^p(X), and if they are linearly independent, this would imply that each coefficient Σ_i a_{ij} f_i(x) = 0 almost everywhere, hence a_{ij} = 0.\n\nBut wait, this requires that the f_i and g_j are linearly independent. However, the original problem does not specify that the f_i or g_j are linearly independent. The problem is stated for the algebraic tensor product, so the sum is a finite linear combination. If we have that Σ a_{ij} f_i ⊗ g_j maps to zero in L^p(X × Y), then we need to show that the tensor itself is zero, which would require that the coefficients can be expressed as combinations that vanish due to the bilinear relations.\n\nBut perhaps the key here is to use the fact that if the functions are zero almost everywhere on the product space, then their coefficients must be zero, provided that the f_i and g_j are chosen appropriately. Wait, but the problem is stated for any elements in the algebraic tensor product. So maybe we can use a basis argument.\n\nAlternatively, think about the case when p=2. Then L^2 is a Hilbert space, and the tensor product corresponds to the Hilbert space tensor product. In that case, the map is isometric, hence injective. But for p ≠ 2, L^p is not a Hilbert space, but maybe the injectivity still holds.\n\nAlternatively, consider the case where X and Y are finite sets with counting measure. Then L^p(X) is just ℝ^n or ℂ^n, and the tensor product would be matrices, and the map would be the flattening of the matrix into a vector. In that case, the map is injective because the matrix entries are uniquely determined by the function on the product space. So in the finite case, it's injective. Maybe the same idea extends to σ-finite measure spaces.\n\nAlternatively, use the fact that the algebraic tensor product is dense in the projective tensor product, but I'm not sure if that helps here.\n\nAnother approach: suppose that Σ a_{ij} f_i(x)g_j(y) = 0 a.e. in X × Y. Then, for almost every x, the function y ↦ Σ a_{ij} f_i(x) g_j(y) is zero in L^p(Y). Since the g_j are in L^p(Y), if they are linearly independent, then for each x, the coefficients Σ_i a_{ij} f_i(x) must be zero for all j. Then, since this holds for almost every x, and the f_i are in L^p(X), if they are linearly independent, then a_{ij} must be zero for all i,j. But this requires that both {f_i} and {g_j} are linearly independent sets.\n\nHowever, in the algebraic tensor product, any element can be written as a finite sum where the f_i and g_j are taken from some bases. But L^p spaces are infinite-dimensional, so we can't necessarily have a basis in the algebraic sense. But since the sum is finite, we can always choose the f_i and g_j to be linearly independent.\n\nWait, no. In the algebraic tensor product, an element is a finite sum, but the f_i and g_j don't have to be linearly independent. For example, you could have f1 ⊗ g1 + f1 ⊗ g2, which is f1 ⊗ (g1 + g2). But the point is, if you have a tensor that's written as a sum with linearly dependent terms, you can rewrite it in terms of a linearly independent basis.\n\nBut maybe we can assume without loss of generality that the f_i are linearly independent and the g_j are linearly independent. Because any tensor can be expressed using linearly independent elements. If the original sum has linearly dependent f_i or g_j, we can rewrite the tensor using a basis.\n\nSo suppose that {f_i} and {g_j} are each linearly independent sets. Then, if Σ a_{ij} f_i ⊗ g_j maps to zero, then the function Σ a_{ij} f_i(x) g_j(y) = 0 a.e. on X × Y. Then, for almost every x, Σ_j (Σ_i a_{ij} f_i(x)) g_j(y) = 0 for almost every y. Since the g_j are linearly independent, this implies that for each j, Σ_i a_{ij} f_i(x) = 0 for almost every x. Then, since the f_i are linearly independent, this implies that a_{ij} = 0 for all i, j. Therefore, the tensor is zero.\n\nHence, the map is injective.\n\nTherefore, the answer should be yes, the natural map is injective.\n\nBut wait, this requires that both {f_i} and {g_j} are linearly independent. But in the algebraic tensor product, any element can be represented in terms of linearly independent {f_i} and {g_j}, because if they are dependent, you can rewrite the tensor to use independent ones. Therefore, the conclusion holds.\n\nSo the key assumptions are that X and Y are σ-finite measure spaces, and that we're considering the algebraic tensor product with the natural map into L^p(X × Y). The problem is to show that this map is injective, i.e., if a tensor maps to the zero function, then the tensor must be zero.\n\nTherefore, in the formatted problem, the assumptions would include the σ-finiteness of X and Y, and that the tensor product is algebraic. The problem is to prove injectivity.",
    "Original_Problem": "Assumption: \n$X$ is a $\\sigma$-finite measure space,\n$Y$ is a $\\sigma$-finite measure space,\n$L^p(X)$ is the space of $p$-integrable functions on $X$,\n$L^p(Y)$ is the space of $p$-integrable functions on $Y$,\n$L^p(X) \\otimes L^p(Y)$ is the algebraic tensor product,\nThe natural map $L^p(X) \\otimes L^p(Y) \\to L^p(X \\times Y)$ is defined by $\\sum a_{ij} f_i \\otimes g_j \\mapsto \\sum a_{ij} f_i(x)g_j(y)$.\nProblem: \nProve that the natural map $L^p(X) \\otimes L^p(Y) \\to L^p(X \\times Y)$ is injective.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $X$ is a $\\sigma$-finite measure space,\nAssumption 2: $Y$ is a $\\sigma$-finite measure space,\nAssumption 3: $L^p(X)$ is the space of $p$-integrable functions on $X$,\nAssumption 4: $L^p(Y)$ is the space of $p$-integrable functions on $Y$,\nAssumption 5: $L^p(X) \\otimes L^p(Y)$ is the algebraic tensor product,\nAssumption 6: The natural map $L^p(X) \\otimes L^p(Y) \\to L^p(X \\times Y)$ is defined by $\\sum a_{ij} f_i \\otimes g_j \\mapsto \\sum a_{ij} f_i(x)g_j(y)$.\nProblem: \nProve that the natural map $L^p(X) \\otimes L^p(Y) \\to L^p(X \\times Y)$ is injective.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$\\det\\Big(f_i(x_{qj})\\ g_p(y_{jq})\\Big)_{(i,p)(j,q)}\\not=0.$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $X$ is a $\\sigma$-finite measure space,\nAssumption 2: $Y$ is a $\\sigma$-finite measure space,\nAssumption 3: $L^p(X)$ is the space of $p$-integrable functions on $X$,\nAssumption 4: $L^p(Y)$ is the space of $p$-integrable functions on $Y$,\nAssumption 5: $L^p(X) \\otimes L^p(Y)$ is the algebraic tensor product,\nAssumption 6: The natural map $L^p(X) \\otimes L^p(Y) \\to L^p(X \\times Y)$ is defined by $\\sum a_{ij} f_i \\otimes g_j \\mapsto \\sum a_{ij} f_i(x)g_j(y)$.\nAssumption 7: $$\\det\\Big(f_i(x_{qj})\\ g_p(y_{jq})\\Big)_{(i,p)(j,q)}\\not=0.$$\nProblem: \nProve that the natural map $L^p(X) \\otimes L^p(Y) \\to L^p(X \\times Y)$ is injective."
}