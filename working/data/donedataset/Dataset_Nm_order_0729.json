{
    "Link_API": "https://api.stackexchange.com/2.3/questions/245871",
    "Title": "The inverse of a lower triangular matrix is lower triangular",
    "Score": 28,
    "Category": "Chá»©ng minh",
    "Tags": "linear-algebra, matrices, proof-writing, inverse",
    "Link": "https://math.stackexchange.com/questions/245871/the-inverse-of-a-lower-triangular-matrix-is-lower-triangular",
    "Content": "The inverse of a non-singular lower triangular matrix is lower triangular. Construct a proof of this fact as follows. Suppose that $L$ is a non-singular lower triangular matrix. If $b \\in \\mathbb{R^n}$ is such that $b_i = 0$ for $i = 1, . . . , k \\leq n$ , and $y$ solves $Ly = b$ , then $y_i = 0$ for $i = 1, . . . , k \\leq n$ . Hint : partition $L$ by the first $k$ rows and columns. Can someone tell me what exactly we are showing here and why it will prove that the inverse of any non-singular lower triangular matrix is lower triangular?",
    "AcceptedAnswer": "Let's write $$L^{-1}=[y_1\\:\\cdots\\:y_n],$$ where each $y_k$ is an $n\\times 1$ matrix. Now, by definition, $$LL^{-1}=I=[e_1\\:\\cdots\\:e_n],$$ where $e_k$ is the $n\\times 1$ matrix with a $1$ in the $k$ th row and $0$ s everywhere else. Observe, though, that $$LL^{-1}=L[y_1\\:\\cdots\\:y_n]=[Ly_1\\:\\cdots\\: Ly_n],$$ so $$Ly_k=e_k\\qquad(1\\leq k\\leq n)$$ By the proposition, since $e_k$ has only $0$ s above the $k$ th row and $L$ is lower triangular and $Ly_k=e_k$ , then $y_k$ has only $0$ s above the $k$ th row. This is true for all $1\\leq k\\leq n$ , so since $$L^{-1}=[y_1\\:\\cdots\\:y_n],$$ then $L^{-1}$ is lower triangular, too. $$********$$ Here's an alternative (but related) approach. Observe that a lower triangular matrix is nonsingular if and only if it has all nonzero entries on the diagonal. Let's proceed by induction on $n$ . The base case ( $n=1$ ) is simple, as all scalars are trivially \"lower triangular\". Now, let's suppose that all nonsingular $n\\times n$ lower triangular matrices have lower triangular inverses, and let $A$ be any nonsingular $(n+1)\\times(n+1)$ lower triangular matrix. In block form, then, we have $$A=\\left[\\begin{array}{c|c}L & 0_n\\\\\\hline x^T & \\alpha\\end{array}\\right],$$ where $L$ is a nonsingular $n\\times n$ lower triangular matrix, $0_n$ is the $n\\times 1$ matrix of $0$ s, $x$ is some $n\\times 1$ matrix, and $\\alpha$ is some nonzero scalar. (Can you see why this is true?) Now, in compatible block form, we have $$A^{-1}=\\left[\\begin{array}{c|c}M & b\\\\\\hline y^T & \\beta\\end{array}\\right],$$ where $M$ is an $n\\times n$ matrix, $b,y$ are $n\\times 1$ matrices, and $\\beta$ some scalar. Letting $I_n$ and $I_{n+1}$ denote the $n\\times n$ and $(n+1)\\times(n+1)$ identity matrices, respectively, we have $$I_{n+1}=\\left[\\begin{array}{c|c}I_n & 0_n\\\\\\hline 0_n^T & 1\\end{array}\\right].$$ Hence, $$\\left[\\begin{array}{c|c}I_n & 0_n\\\\\\hline 0_n^T & 1\\end{array}\\right]=I_{n+1}=A^{-1}A=\\left[\\begin{array}{c|c}ML+bx^T & M0_n+b\\alpha\\\\\\hline y^TL+\\alpha x^T & y^T0_n+\\beta\\alpha\\end{array}\\right]=\\left[\\begin{array}{c|c}ML+bx^T & \\alpha b\\\\\\hline y^TL+\\alpha x^T & \\beta\\alpha\\end{array}\\right].$$ Since $\\alpha$ is a nonzero scalar and $\\alpha b=0_n$ , then we must have $b=0_n$ . Thus, $$A^{-1}=\\left[\\begin{array}{c|c}M & 0_n\\\\\\hline y^T & \\beta\\end{array}\\right],$$ and $$\\left[\\begin{array}{c|c}I_n & 0_n\\\\\\hline 0_n^T & 1\\end{array}\\right]=\\left[\\begin{array}{c|c}ML & 0_n\\\\\\hline y^TL+\\alpha x^T & \\beta\\alpha\\end{array}\\right].$$ Since $ML=I_n$ , then $M=L^{-1}$ , and by inductive hypothesis, we have that $M$ is then lower triangular. Therefore, $$A^{-1}=\\left[\\begin{array}{c|c}M & 0_n\\\\\\hline y^T & \\beta\\end{array}\\right]$$ is lower triangular, too, as desired.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$L$ is a non-singular matrix,\n$L$ is a lower triangular matrix,\n$b \\in \\mathbb{R}^n$ satisfies $b_i = 0$ for $i = 1, \\ldots, k \\leq n$.\nProblem: \nShow that if $Ly = b$, then $y_i = 0$ for $i = 1, \\ldots, k \\leq n$, and explain why this proves $L^{-1}$ is lower triangular.\n###END_OF_FORMAT###\n\n**Explanation:**  \nThe problem requires proving that the solution $y$ to $Ly = b$ inherits the zero-pattern of $b$ in its first $k$ entries. This directly relates to the structure of $L^{-1}$:  \n1. The $j$-th column of $L^{-1}$ solves $Ly = e_j$, where $e_j$ has its first $j-1$ entries as $0$.  \n2. By the proven result, the solution $y$ (the $j$-th column of $L^{-1}$) must have its first $j-1$ entries as $0$.  \n3. Thus, every column of $L^{-1}$ has zeros above the diagonal, confirming $L^{-1}$ is lower triangular.",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem step by step. So the original question is about proving that the inverse of a non-singular lower triangular matrix is also lower triangular. The user is asking for an explanation of why showing that if a vector b has its first k entries zero, then the solution y to Ly = b also has its first k entries zero would prove that the inverse matrix is lower triangular. \n\nFirst, I need to recall some linear algebra concepts. A lower triangular matrix is one where all the entries above the main diagonal are zero. If a matrix is non-singular, that means it's invertible, so its determinant is non-zero. The key point here is that the inverse of such a matrix should retain the lower triangular structure. \n\nThe problem suggests using a proof approach where we consider solving Ly = b when b has zeros in the first k positions. Let me try to unpack that. If L is lower triangular, then each equation in the system Ly = b only involves the variables y1 up to yi for the ith equation. That's because all the entries above the diagonal are zero, so each row i of L only has non-zero entries from column 1 up to column i. \n\nSo if we take a vector b where the first k entries are zero, then when we solve Ly = b, maybe we can show by induction or substitution that the first k entries of y must also be zero. Let's think about k=1 first. If b1 = 0, then the first equation is L11 y1 = 0. Since L is non-singular, L11 can't be zero, so y1 must be zero. Then for the second equation, L21 y1 + L22 y2 = 0. But since y1 is already zero, this reduces to L22 y2 = 0, which implies y2=0 if we proceed similarly. Wait, but in the problem statement, they mention partitioning the matrix by the first k rows and columns. Maybe partitioning here means breaking the matrix into blocks. Let's say we split L into a block matrix where the top-left block is k x k lower triangular, and the bottom-right block is (n-k)x(n-k) lower triangular. Then the system Ly = b can be written in blocks. If b has zeros in the first k entries, then solving the first block equation would give the first k components of y as zero, and then the next block would involve the remaining components. \n\nBut how does this relate to the inverse being lower triangular? The inverse matrix L^{-1} is such that L L^{-1} = I. The columns of L^{-1} are the solutions y to Ly = e_j, where e_j is the jth standard basis vector. So if we can show that when solving Ly = e_j, the solution y (which is the jth column of L^{-1}) has zeros above a certain position, that would imply that L^{-1} is lower triangular. For example, the first column of L^{-1} solves Ly = e1, which has b1=1 and the rest zero. But wait, the problem here talks about b having the first k entries zero. Maybe considering different cases where the non-zero entry starts at position k+1. \n\nWait, let's structure this. Suppose we want the jth column of L^{-1} to be lower triangular. That would mean that all entries above the jth position in that column are zero. So for the jth column, which corresponds to solving Ly = e_j, the vector e_j has zeros everywhere except the jth entry. So if we can show that in solving Ly = e_j, the solution y has y1=0, y2=0, ..., y_{j-1}=0, then that column is lower triangular. \n\nBut the problem's approach is more general: if b has zeros in the first k entries, then y has zeros in the first k entries. How does that help? Well, if we take e_j, which has zeros in the first j-1 entries and a 1 in the jth entry. If we apply the problem's statement with k = j-1, then b has zeros in the first j-1 entries, so the solution y (the jth column of L^{-1}) must also have zeros in the first j-1 entries. That exactly means that the jth column of L^{-1} has zeros above the jth entry, making the inverse matrix lower triangular. \n\nSo the key idea is that each column of the inverse matrix, which solves Ly = e_j, must have zeros above the jth entry because e_j has zeros in the first j-1 entries. By the problem's assertion, this implies that the solution y (the jth column) has zeros there, hence the inverse is lower triangular. \n\nTherefore, the problem is structured to show that solving Ly = b when the first k entries of b are zero forces the first k entries of y to be zero. By applying this to each standard basis vector e_j (which has zeros in the first j-1 positions), we can conclude that each column of L^{-1} has zeros above the diagonal, hence L^{-1} is lower triangular. \n\nI need to make sure that all the assumptions are correctly extracted. The original problem states that L is a non-singular lower triangular matrix. The user is supposed to show that if b has zeros in the first k entries, then so does y. The hint is to partition L by the first k rows and columns. \n\nSo the assumptions would include that L is a non-singular lower triangular matrix, and that b is a vector in R^n with zeros in the first k entries. The problem then is to show that the solution y to Ly = b also has zeros in the first k entries, and explain why this proves the inverse is lower triangular.",
    "Original_Problem": "Assumption: \n$L$ is a non-singular matrix,\n$L$ is a lower triangular matrix,\n$b \\in \\mathbb{R}^n$ satisfies $b_i = 0$ for $i = 1, \\ldots, k \\leq n$.\nProblem: \nShow that if $Ly = b$, then $y_i = 0$ for $i = 1, \\ldots, k \\leq n$, and explain why this proves $L^{-1}$ is lower triangular.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $L$ is a non-singular matrix,\nAssumption 2: $L$ is a lower triangular matrix,\nAssumption 3: $b \\in \\mathbb{R}^n$ satisfies $b_i = 0$ for $i = 1, \\ldots, k \\leq n$.\nProblem: \nShow that if $Ly = b$, then $y_i = 0$ for $i = 1, \\ldots, k \\leq n$, and explain why this proves $L^{-1}$ is lower triangular.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$A^{-1}=\\left[\\begin{array}{c|c}M & 0_n\\\\\\hline y^T & \\beta\\end{array}\\right]$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $L$ is a non-singular matrix,\nAssumption 2: $L$ is a lower triangular matrix,\nAssumption 3: $b \\in \\mathbb{R}^n$ satisfies $b_i = 0$ for $i = 1, \\ldots, k \\leq n$.\nAssumption 4: $$A^{-1}=\\left[\\begin{array}{c|c}M & 0_n\\\\\\hline y^T & \\beta\\end{array}\\right]$$\nProblem: \nShow that if $Ly = b$, then $y_i = 0$ for $i = 1, \\ldots, k \\leq n$, and explain why this proves $L^{-1}$ is lower triangular."
}