{
    "Link_API": "https://api.stackexchange.com/2.3/questions/1124799",
    "Title": "Uniqueness of determinant",
    "Score": 15,
    "Category": "Chứng minh",
    "Tags": "linear-algebra, determinant",
    "Link": "https://math.stackexchange.com/questions/1124799/uniqueness-of-determinant",
    "Content": "In Artin Algebra 2nd edition page 22, the author proved the uniqueness of determinant by saying that any matrix $A$ can be written in reduced row-echelon form $A'$: $A'=E_1\\cdots E_kA$ where $E_i$ are the elementary matrix. Then $A'$ is either $I$ or has a zero row. If $A'=I$, then $\\delta(A')=1$. Otherwise, $\\delta(A')=0$. In both cases, $\\delta(A')$ is determined, and hence by\n$$\\delta(A')=\\delta(E_1)\\cdots\\delta(E_k)\\delta(A)$$\n$\\delta(A)$ is determined uniquely. However, as he himself pointed out immediately in the following paragraph, the sequence $E_1\\cdots E_k$ is not unique. Then why is $\\delta(A)$ uniquely determined? Edit:\nThe author defined determinant as a function $\\delta(A)=d\\in \\mathbb{R}$ satisfying the following 3 conditions: (i) $\\delta(I)=1$ (ii) $\\delta$ is linear in the rows of the matrix $A$ (iii) If two adjacent rows of $A$ are equal, then $\\delta(A)=0$ He then proved that the above conditions imply some properties that all of us know, e.g., (a) Interchanging two rows reverses the sign (b) If $A$ has a zero row, then $\\delta(A)=0$ (c) Multiplying one row by a number and adding it to another row doesn't change the determinant (d) $\\delta(E)=\\pm1$ or $c$ (e) $\\delta(AB)=\\delta(A)\\delta(B)$ Then he proved that the function $\\delta$ so defined is unique, as shown in the beginning of my post, which I don't understand",
    "AcceptedAnswer": "If the determinant $\\delta$ exists, you can prove that $\\delta(E)=c$ if $E$ is the elementary matrix corresponding to multiplication of a row by $c$; $\\delta(E)=1$ if $E$ is the elementary matrix corresponding to summing a row to another multiplied by a constant; $\\delta(E)=-1$ if $E$ is the elementary matrix corresponding to switching two rows; $\\delta(A)=0$ if $A$ is not invertible; $\\delta(AB)=\\delta(A)\\delta(B)$. If two determinant functions $\\delta$ and $\\delta'$ exist, then they are both zero on the noninvertible matrices, but, writing an invertible $A$ as\n$$\nA=E_1E_2\\dots E_k\n$$\na product of elementary matrices, we conclude that\n$$\n\\delta(A)=\\delta(E_1)\\delta(E_2)\\dots\\delta(E_k)=\\delta'(A)\n$$ Note the initial if : we're assuming the existence, not proving it. Also, note that the decomposition into a product of elementary matrices doesn't depend on the determinant; so just use the same decomposition for computing $\\delta(A)$ and $\\delta'(A)$. The fact that the decomposition as product of elementary matrices is not unique is indeed a problem, but with respect to the existence of the determinant. In principle you could find two decompositions that produce different values when computed with rules 1–5, but this would simply prove that the determinant doesn't exist .",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$\\delta$ is a function satisfying (i) $\\delta(I) = 1$, (ii) $\\delta$ is linear in the rows of the matrix, (iii) $\\delta(A) = 0$ if two adjacent rows of $A$ are equal,\nAny matrix $A$ can be transformed into a reduced row-echelon form $A'$ via elementary matrices $E_1, \\dots, E_k$ such that $A' = E_1 \\cdots E_k A$,\n$A'$ is either the identity matrix $I$ or has a zero row,\n$\\delta(E_i)$ is uniquely determined by the type of elementary operation (row swap, scaling, or row addition),\n$\\delta(A')$ is uniquely determined (either $1$ if $A' = I$ or $0$ if $A'$ has a zero row).\nProblem: \nProve that $\\delta(A)$ is uniquely determined despite the non-uniqueness of the sequence $E_1, \\dots, E_k$.\n###END_OF_FORMAT###",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem step by step. The user is asking about the uniqueness of the determinant function as presented in Artin's Algebra. The author claims that even though the sequence of elementary matrices used to reduce a matrix to its row-echelon form isn't unique, the determinant δ(A) ends up being uniquely determined. The user is confused about why this is the case, given the non-uniqueness of the elementary matrices.\n\nFirst, let's recap what the determinant function δ is supposed to satisfy according to Artin's three conditions: (i) δ(I) = 1, (ii) δ is linear in the rows, and (iii) if two adjacent rows are equal, δ(A) = 0. Then, using these properties, Artin derives other standard determinant properties like row swapping changing the sign, etc.\n\nThe key part of Artin's proof for uniqueness is that any matrix A can be reduced to a reduced row-echelon form A' via elementary matrices E_1...E_k, so A' = E_1...E_k A. Then, depending on whether A' is I or has a zero row, δ(A') is either 1 or 0. Then, since δ(A') = δ(E_1)...δ(E_k) δ(A), we can solve for δ(A) as δ(A) = δ(A') / (δ(E_1)...δ(E_k)). But the user is pointing out that the sequence of E_i isn't unique, so different sequences could lead to different δ(E_i) products, which might affect δ(A).\n\nWait, but Artin has already shown that the determinant function has certain properties, such as δ(AB) = δ(A)δ(B). Also, each elementary matrix E has a determinant δ(E) that is fixed by the type of elementary operation: row swaps give δ(E) = -1, scaling a row by c gives δ(E) = c, and adding a multiple of a row to another gives δ(E) = 1. So even if there are different sequences of elementary matrices leading to A', the product δ(E_1)...δ(E_k) should be the same because any two sequences that reduce A to A' would have their δ products equal. Therefore, even if the E_i are different, the product of their determinants must be the same, hence δ(A) is uniquely determined by δ(A') divided by that product.\n\nWait, but why is the product of δ(E_i) the same for different sequences? Because different sequences could involve different operations. For example, maybe you can reach A' by swapping rows first and then scaling, or scaling first and then swapping. However, the determinant is a group homomorphism, so δ(AB) = δ(A)δ(B). So regardless of the path taken, as long as the composition of operations leads from A to A', the product of the δ(E_i) must be equal to the ratio δ(A')/δ(A). But since δ(A') is fixed (either 0 or 1), then δ(A) must be uniquely determined as δ(A') divided by the product of δ(E_i). However, even if different sequences have different products, how can we ensure that when δ(A') is divided by different products, we get the same δ(A)?\n\nWait, perhaps the key is that the determinant is well-defined regardless of the operations chosen. Because even if there are different sequences of elementary matrices, the determinant is a function that is uniquely determined by the three properties, and thus the product of δ(E_i) must be the same no matter which elementary matrices are used to reach A'. Therefore, even though the factorization into elementary matrices isn't unique, the value of the product δ(E_1)...δ(E_k) must be the same. Hence, δ(A) = δ(A') / [δ(E_1)...δ(E_k)] must be the same regardless of the choice of E_i.\n\nBut why is the product δ(E_1)...δ(E_k) the same for different sequences? Because the determinant is a function that's uniquely determined by the matrix. Each elementary matrix corresponds to an operation, and the determinant of each elementary matrix is fixed (swap: -1, scale: c, row add: 1). Therefore, any two sequences of elementary matrices that take A to A' must have the same product of determinants. Because the determinant of the product of matrices is the product of their determinants. So if E_1...E_k A = A', then δ(E_1)...δ(E_k) δ(A) = δ(A'). Since A' is either I (determinant 1) or has a zero row (determinant 0). Therefore, if there are two different sequences E_1...E_k and F_1...F_m such that E_1...E_k A = F_1...F_m A = A', then δ(E_1)...δ(E_k) δ(A) = δ(F_1)...δ(F_m) δ(A) = δ(A'). So δ(A) = δ(A') / [δ(E_1)...δ(E_k)] = δ(A') / [δ(F_1)...δ(F_m)]. Therefore, for this to hold, the products δ(E_1)...δ(E_k) and δ(F_1)...δ(F_m) must be equal. Therefore, even though the sequences are different, their determinant products are the same, leading to the same δ(A).\n\nBut why are the products of the δ(E_i) the same for different sequences? Because the determinant is a well-defined function. The determinant of A' is fixed (either 1 or 0), and the determinant of the product of elementary matrices is the product of their determinants. Since A' = E_1...E_k A, taking determinants, we have δ(A') = δ(E_1)...δ(E_k) δ(A). Therefore, δ(A) = δ(A') / [δ(E_1)...δ(E_k)]. But if there's another sequence F_1...F_m with A' = F_1...F_m A, then similarly δ(A') = δ(F_1)...δ(F_m) δ(A), so δ(A) = δ(A') / [δ(F_1)...δ(F_m)]. Thus, the two expressions for δ(A) must be equal, meaning that δ(E_1)...δ(E_k) = δ(F_1)...δ(F_m). Therefore, regardless of the sequence, the product of the δ(E_i) is the same. Hence, δ(A) is uniquely determined.\n\nBut why is δ(E_1)...δ(E_k) = δ(F_1)...δ(F_m}? Because both products equal δ(A') / δ(A), but since δ(A') is fixed (1 or 0), and δ(A) is the same regardless of the sequence, then the products must be the same. Wait, but we are trying to solve for δ(A), so this seems circular. Let me think again.\n\nSuppose there are two different sequences E_1...E_k and F_1...F_m such that E_1...E_k A = F_1...F_m A = A'. Then, taking determinants, we have:\n\nδ(E_1)...δ(E_k) δ(A) = δ(A')  \nδ(F_1)...δ(F_m) δ(A) = δ(A')\n\nTherefore, δ(E_1)...δ(E_k) = δ(F_1)...δ(F_m) = δ(A') / δ(A). But if we don't know δ(A) yet, how can we conclude that the products are equal? Wait, but δ(A') is known (either 0 or 1). If A' is the identity, then δ(A') = 1, so δ(E_1)...δ(E_k) δ(A) = 1, so δ(A) = 1 / [δ(E_1)...δ(E_k)]. Similarly, δ(A) = 1 / [δ(F_1)...δ(F_m)}. Therefore, if two different sequences give different products, δ(A) would have two different values, which contradicts uniqueness. Therefore, the products must be equal because δ(A) is uniquely determined, which is what we're trying to prove. Wait, but this seems like using the conclusion to justify itself.\n\nAlternatively, perhaps the key is that the determinant function is uniquely determined by the three properties, so even if different sequences of elementary matrices are used, the resulting δ(A) must be the same. Since the determinant is a function that satisfies multilinear, alternating, and normalized conditions, by the uniqueness theorem of such functions, δ(A) is uniquely determined. But Artin's approach is to derive uniqueness through the process of row reduction, so the user is confused why different sequences don't affect the outcome.\n\nMaybe the answer lies in the fact that although the sequences of elementary matrices aren't unique, the effect of each elementary operation on the determinant is uniquely determined by its type (swap, scale, add). Therefore, even if you take different paths, the cumulative effect on the determinant (the product of the δ(E_i)) would be the same because any two sequences that reduce A to A' must differ by operations that don't affect the determinant product. For example, if you have two different sequences that reduce A to A', the composition of one sequence with the inverse of the other would be a sequence that takes A' to A', i.e., an automorphism of A'. But since A' is either I or has a zero row, in the case of A' = I, any automorphism would be a product of elementary matrices that equal the identity, so their determinant product would be 1. Therefore, the difference between two sequences would be a product of elementary matrices with determinant 1, hence not changing the overall product. Similarly, if A' has a zero row, then δ(A') = 0, so δ(A) must be zero regardless of the product of δ(E_i)s, because δ(A') = 0 implies δ(A) = 0 / [product], but if the product is non-zero, then δ(A) = 0. However, if A has a zero row, then δ(A) = 0 by property (b), so this is consistent.\n\nWait, but if A' has a zero row, then δ(A') = 0. Then δ(A') = product of δ(E_i) * δ(A). So 0 = product * δ(A). Since elementary matrices have invertible determinants (except for the zero case?), but in reality, elementary matrices corresponding to row addition have det 1, swaps have det -1, and scaling by c ≠ 0 has det c. So the product of δ(E_i) is non-zero (since all are non-zero). Therefore, 0 = product * δ(A) implies δ(A) = 0. So regardless of the product, δ(A) must be 0. So in this case, δ(A) is uniquely 0. \n\nIf A' is I, then δ(A') = 1. Then δ(A) = 1 / (product of δ(E_i)). But here, even if there are different sequences leading to I, their product of δ(E_i) must be the same, otherwise δ(A) would have different values. But why is the product the same? Because the determinant of A is uniquely defined as 1 divided by the product. But how do we know that different sequences give the same product? Because the determinant of A is a fixed value determined by its entries, so regardless of the reduction path, the product of the δ(E_i) must adjust to give the same δ(A). However, in Artin's approach, he is building the determinant from the axioms, not from the usual cofactor expansion. Therefore, the uniqueness is shown by the fact that any such function δ must satisfy δ(A) = δ(A') / product(δ(E_i)), and since δ(A') is fixed (1 or 0), and the product is determined by the operations, but the product must be consistent because any two reduction paths would lead to the same determinant.\n\nAlternatively, maybe the key is that the three properties (i), (ii), (iii) uniquely determine the function δ, so regardless of how you compute it via row operations, you must end up with the same value. Therefore, even if the sequences of E_i are different, the axioms force δ(A) to be the same. The author's argument is that because δ(A') is determined (either 0 or 1), and the product of δ(E_i) is determined by the row operations (each of which has a δ value fixed by the type of operation), then δ(A) is uniquely determined as δ(A') divided by that product. The fact that different sequences would require the product δ(E_i) to be the same is because otherwise, δ(A) would not be uniquely determined, contradicting the axioms. Therefore, the uniqueness of δ(A) follows from the properties (i)-(iii) forcing the product of δ(E_i) to be the same regardless of the sequence, hence leading to a unique δ(A).\n\nAnother angle: Since the determinant function is a function that satisfies δ(AB) = δ(A)δ(B), then for any two sequences E_1...E_k and F_1...F_m such that E_1...E_k A = F_1...F_m A = A', we can write E_1...E_k = F_1...F_m B, where B is some product of elementary matrices that act as automorphisms on A. But if A' is I, then B would be an automorphism of I, i.e., B is an invertible matrix such that B I = I, so B = I. Therefore, the only such B is the identity, so E_1...E_k = F_1...F_m, hence their determinants are the same. But this can't be right because there are multiple ways to reduce a matrix to I. Wait, no. If you have two different sequences that reduce A to I, then the product E_1^{-1}...E_k^{-1} F_1...F_m must equal the identity. Therefore, the composition of these two sequences gives a product of elementary matrices that equals the identity, so their determinants multiply to 1. Therefore, δ(E_1)...δ(E_k)^{-1} δ(F_1)...δ(F_m) = 1, hence δ(F_1)...δ(F_m) = δ(E_1)...δ(E_k). Therefore, the products are the same, hence δ(A) = 1 / product is the same.\n\nThis seems to resolve the issue. If two different sequences E and F reduce A to I, then the product E^{-1} F would be a sequence that reduces I to I, i.e., the identity. Therefore, the determinant of E^{-1} F must be 1. Since δ(E^{-1} F) = δ(E^{-1}) δ(F) = (δ(E))^{-1} δ(F) = 1, hence δ(F) = δ(E). Therefore, the products δ(E) and δ(F) must be equal. Therefore, the product of determinants of any two reduction sequences is the same, hence δ(A) is uniquely determined.\n\nSimilarly, if A reduces to a matrix with a zero row, then δ(A) must be 0 by property (b), regardless of the product of δ(E_i)s, because 0 = product * δ(A) implies δ(A) = 0.\n\nTherefore, the key points are:\n\n1. For A reducing to I, different sequences must have their δ products equal, ensuring δ(A) is unique.\n\n2. For A reducing to a zero row, δ(A) is 0 uniquely.\n\nThus, despite the non-uniqueness of the elementary matrices, δ(A) is uniquely determined.",
    "Original_Problem": "Assumption: \n$\\delta$ is a function satisfying (i) $\\delta(I) = 1$, (ii) $\\delta$ is linear in the rows of the matrix, (iii) $\\delta(A) = 0$ if two adjacent rows of $A$ are equal,\nAny matrix $A$ can be transformed into a reduced row-echelon form $A'$ via elementary matrices $E_1, \\dots, E_k$ such that $A' = E_1 \\cdots E_k A$,\n$A'$ is either the identity matrix $I$ or has a zero row,\n$\\delta(E_i)$ is uniquely determined by the type of elementary operation (row swap, scaling, or row addition),\n$\\delta(A')$ is uniquely determined (either $1$ if $A' = I$ or $0$ if $A'$ has a zero row).\nProblem: \nProve that $\\delta(A)$ is uniquely determined despite the non-uniqueness of the sequence $E_1, \\dots, E_k$.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $\\delta$ is a function satisfying (i) $\\delta(I) = 1$, (ii) $\\delta$ is linear in the rows of the matrix, (iii) $\\delta(A) = 0$ if two adjacent rows of $A$ are equal,\nAssumption 2: Any matrix $A$ can be transformed into a reduced row-echelon form $A'$ via elementary matrices $E_1, \\dots, E_k$ such that $A' = E_1 \\cdots E_k A$,\nAssumption 3: $A'$ is either the identity matrix $I$ or has a zero row,\nAssumption 4: $\\delta(E_i)$ is uniquely determined by the type of elementary operation (row swap, scaling, or row addition),\nAssumption 5: $\\delta(A')$ is uniquely determined (either $1$ if $A' = I$ or $0$ if $A'$ has a zero row).\nProblem: \nProve that $\\delta(A)$ is uniquely determined despite the non-uniqueness of the sequence $E_1, \\dots, E_k$.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$\n\\delta(A)=\\delta(E_1)\\delta(E_2)\\dots\\delta(E_k)=\\delta'(A)\n$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $\\delta$ is a function satisfying (i) $\\delta(I) = 1$, (ii) $\\delta$ is linear in the rows of the matrix, (iii) $\\delta(A) = 0$ if two adjacent rows of $A$ are equal,\nAssumption 2: Any matrix $A$ can be transformed into a reduced row-echelon form $A'$ via elementary matrices $E_1, \\dots, E_k$ such that $A' = E_1 \\cdots E_k A$,\nAssumption 3: $A'$ is either the identity matrix $I$ or has a zero row,\nAssumption 4: $\\delta(E_i)$ is uniquely determined by the type of elementary operation (row swap, scaling, or row addition),\nAssumption 5: $\\delta(A')$ is uniquely determined (either $1$ if $A' = I$ or $0$ if $A'$ has a zero row).\nAssumption 6: $$\n\\delta(A)=\\delta(E_1)\\delta(E_2)\\dots\\delta(E_k)=\\delta'(A)\n$$\nProblem: \nProve that $\\delta(A)$ is uniquely determined despite the non-uniqueness of the sequence $E_1, \\dots, E_k$."
}