{
    "Link_API": "https://api.stackexchange.com/2.3/questions/1265913",
    "Title": "Almost sure convergence and L1 convergence",
    "Score": 17,
    "Category": "Chứng minh",
    "Tags": "probability-theory, convergence-divergence",
    "Link": "https://math.stackexchange.com/questions/1265913/almost-sure-convergence-and-l1-convergence",
    "Content": "I am preparing myself for the mid-term exam of my probability theory exam, and am solving questions from previous years exams. One of these questions I couldn't answer, and so far I haven't found anything similar online. Suppose that $X_n \\rightarrow  X$ a.s. as $n \\rightarrow \\infty$. Prove or disprove that, if $\\lim_{n \\rightarrow \\infty} \\mathbb{E}|X_n| \\rightarrow \\mathbb{E}|X| < \\infty$, then $X_n \\rightarrow X$ in $L^1$ i.e. $\\Bbb E[|X_n-X|] \\to 0$. Here's my current approach:\nGiven \\begin{equation}\\mathbb{P}(\\omega \\in \\Omega: \\lim_{n \\rightarrow \\infty}X_n = X) = 1 \\Leftrightarrow X_n \\rightarrow X\\text{ a.s.}\\end{equation} NTS: \\begin{equation} \\lim_{n \\rightarrow \\infty}\\mathbb{E}|X_n| \\rightarrow E|X|<\\infty \\Rightarrow \\lim_{n\\rightarrow \\infty}\\mathbb{E}[|X_n - X|^1 ] =0.\\end{equation}\nSince $X_n \\rightarrow X$ almost surely, $X_n \\rightarrow X$ in probability. $L^1$ convergence is implied by convergence in probability + uniform integrability, so it suffices to show that $(X_n)$ is uniformly integrable. To show uniform integrability, I then define a function $f$ that is bounded and continuous, so that $f \\circ X_n \\rightarrow f \\circ X$ in probability, and therefore $\\mathbb{E}[f \\circ X_n] \\rightarrow \\mathbb{E}[f \\circ X]$, which (together with the assumption that $\\mathbb{E}X_n \\rightarrow \\mathbb{E}X$) implies that $\\mathbb{E}[X_n - f \\circ X_n] \\rightarrow \\mathbb{E}[X - f \\circ X]$. Last, fix some $\\varepsilon <0$ and use the fact that X is integrable to show that the expectation of X over some interval of the function tends to 0. For more details, the proof is also given in the book \"Probability and Stochastics\" by Erhan Cinlar (page 108f, Theorem 4.9). However, this proof seems a little indirect because I am not \"really\" using the almost sure convergence, but rather am just working with convergence in probability. Is there any better (i.e more direct) approach?",
    "AcceptedAnswer": "This is a direct consequence of Scheffé's lemma , which is actually due to Riesz : Lemma: If a sequence of $L^p$ integrable functions $f_n$ converges a.e. to an $L^p$ integrable function $f$ with $p\\geq 1$ and $\\lim_n \\Vert f_n \\Vert_p = \\Vert f \\Vert_p$ holds true, then $\\lim_n \\Vert f_n - f \\Vert_p = 0$. Proof for p=1 (taken from Kusolitsch (2010) ): Consider functions\n$$ f_n^* = \\begin{cases} f_n, & \\vert f_n \\vert \\leq \\vert f \\vert, \\\\ \\vert f \\vert sgn(f_n), &  \\vert f_n \\vert > \\vert f \\vert, \\end{cases}$$\nwhich are dominated by the $L^1$ integrable $\\vert f \\vert$ and converge to $f$ a.e. So the functions $\\vert f_n^* - f \\vert$ are dominated by $2\\vert f \\vert$ and vanish a.e., and the dominated convergence theorem yields\n$$\\lim_n \\int \\vert f_n^* \\vert = \\int \\vert f \\vert$$\nand also \n$$\\lim_n \\int \\vert f_n^* - f \\vert = 0.$$\nBy definition $f_n^*$ always has the same sign as $f_n$ and $\\vert f_n^* \\vert \\leq \\vert f_n \\vert$. So one gets $\\vert f_n - f_n^* \\vert = \\vert f_n \\vert - \\vert f_n^* \\vert$, and \n$$ \\int \\vert f_n - f_n^* \\vert = \\int \\vert f_n \\vert - \\int \\vert f_n^* \\vert. $$\nSince both integrals on the right hand side converge to $\\int \\vert f\\vert<\\infty$, this yields the conclusion.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$X_n$ converges to $X$ almost surely as $n \\rightarrow \\infty$,\n$\\lim_{n \\rightarrow \\infty} \\mathbb{E}|X_n| = \\mathbb{E}|X|$,\n$\\mathbb{E}|X| < \\infty$.\nProblem: \nProve or disprove that $X_n \\rightarrow X$ in $L^1$, i.e., $\\lim_{n \\rightarrow \\infty} \\mathbb{E}[|X_n - X|] = 0$.\n###END_OF_FORMAT###\n\n**Answer:**  \nThe statement is **true**. Here’s the key reasoning:  \n\n1. **Almost sure convergence implies convergence in probability** (by definition).  \n2. **Uniform integrability (UI)** is needed for $L^1$ convergence. To show $(X_n)$ is UI:  \n   - From $\\mathbb{E}|X_n| \\to \\mathbb{E}|X| < \\infty$ and $X_n \\to X$ in probability, a classical result in measure theory states that $(X_n)$ is uniformly integrable.  \n3. **Vitali’s Convergence Theorem** directly applies: If $X_n \\to X$ in probability and $(X_n)$ is UI, then $X_n \\to X$ in $L^1$.  \n\nThus, the given conditions ($X_n \\to X$ a.s. + $\\mathbb{E}|X_n| \\to \\mathbb{E}|X|$) suffice to conclude $L^1$ convergence. The initial approach (using UI and convergence in probability) is valid.",
    "reasoning_create_structured_problem": "Okay, let me try to work through this problem step by step. The user wants to know if almost sure convergence of X_n to X, along with the convergence of the expectations E|X_n| to E|X| which is finite, implies L1 convergence. \n\nFirst, I remember that convergence in L1 isn't generally guaranteed by almost sure convergence alone. There's a standard example where X_n converges a.s. to 0 but not in L1, like the type where X_n is n times the indicator of [0,1/n] on the unit interval. But in that case, the expectation E|X_n| would be 1, which doesn't converge to 0. So here, the key difference is that the expectations are converging to E|X|. Maybe that adds enough to get L1 convergence?\n\nThe user mentioned using uniform integrability. Since a.s. convergence plus uniform integrability implies L1 convergence, but here instead of uniform integrability, they have convergence of expectations. Wait, but uniform integrability is related to controlling the tails of the distributions. Maybe if the expectations converge, that plus a.s. convergence gives uniform integrability?\n\nAlternatively, there's a theorem by Vitali which states that X_n converges to X in L1 if and only if X_n is uniformly integrable and converges in probability. Since a.s. convergence implies convergence in probability, if the given condition (E|X_n| → E|X|) implies uniform integrability, then the conclusion holds.\n\nWait, does convergence of expectations to a finite limit imply uniform integrability? Not necessarily. For example, consider X_n = X + Y_n, where Y_n are not uniformly integrable but EY_n → 0. Then E|X_n| → E|X|, but X_n might not be UI. Hmm, but maybe under the a.s. convergence condition, the convergence of expectations does give UI. \n\nAlternatively, maybe we can use Scheffé's lemma, which says that if X_n converges a.s. to X and the expectations of |X_n| converge to the expectation of |X|, then X_n converges to X in L1. Wait, is that correct? Let me recall. Scheffé's lemma requires that the densities converge a.s., and if the integral of the density converges, then you get L1 convergence. But in the general case, does Scheffé apply here?\n\nWait, the standard Scheffé's lemma is for dominated convergence. But maybe there's a similar result. Let me check the exact statement. Scheffé’s Theorem states that if f_n → f a.e., and f_n are integrable with ∫f_n → ∫f, then ∫|f_n - f| → 0. But this is in the context of densities, i.e., non-negative functions. So if we have random variables X_n → X a.s. and E|X_n| → E|X|, does that imply E|X_n - X| → 0? \n\nWait, if X_n and X are non-negative, then maybe. But in general, if X_n can be positive and negative, it's not so straightforward. Let me think. Suppose X_n → X a.s., and E|X_n| → E|X|. If we can apply the lemma, then perhaps. But Scheffé's lemma is for densities, which are non-negative. So maybe that's not directly applicable. \n\nAlternatively, perhaps use the dominated convergence theorem. But to apply DCT, we need |X_n| ≤ Y for some integrable Y. However, the problem doesn't assume domination. \n\nWait, but if we have E|X_n| → E|X|, and X_n → X a.s., maybe we can use the Vitali convergence theorem, which requires the sequence to be uniformly integrable and convergent in measure. Since a.s. convergence implies convergence in probability (which is convergence in measure if the measure is finite), and if we can show uniform integrability, then Vitali's theorem gives L1 convergence. \n\nBut how to get uniform integrability? One sufficient condition for uniform integrability is that sup E[|X_n| 1_{|X_n| > a}] → 0 as a → ∞. Now, since E|X_n| converges to E|X|, which is finite, perhaps we can show that the tails are uniformly controlled. \n\nSuppose for contradiction that the sequence isn't uniformly integrable. Then there exists ε > 0 and a subsequence n_k such that E[|X_{n_k}| 1_{|X_{n_k}| > k}] ≥ ε. But since E|X_{n_k}| → E|X|, the expectation is approaching a finite limit. If the tails weren't uniformly controlled, maybe E|X_{n_k}| would not converge? I'm not sure. \n\nAlternatively, maybe use the fact that if X_n → X a.s. and E|X_n| → E|X|, then X_n is uniformly integrable. How? Let's consider. For uniform integrability, we need that for every ε > 0, there exists a K such that sup_n E[|X_n| 1_{|X_n| > K}] < ε. \n\nSince X is integrable, for any ε, there exists K such that E[|X| 1_{|X| > K}] < ε/2. Because X_n → X a.s., by the triangle inequality, |X_n| ≤ |X| + |X_n - X|. But I'm not sure. Alternatively, since E|X_n| → E|X|, maybe applying the lemma that says if X_n → X in probability and E|X_n| → E|X|, then X_n is UI. Wait, I think there's a theorem along those lines. \n\nYes, in some textbooks, it's stated that if X_n converges to X in probability and E|X_n| → E|X| < ∞, then the sequence X_n is uniformly integrable. Therefore, combining with convergence in probability (which follows from a.s. convergence), you get L1 convergence. \n\nBut in the problem, the user is given a.s. convergence and E|X_n| → E|X|. Then, since a.s. convergence implies convergence in probability, and given E|X_n| → E|X|, then by that theorem, X_n is uniformly integrable. Hence, by Vitali's theorem, X_n converges in L1. \n\nBut the user is asking if this is true. The answer would be yes, under the given conditions. But wait, is that theorem correct? Let me check. \n\nSuppose X_n → X in probability and E|X_n| → E|X|. Then {X_n} is uniformly integrable. Is that true? \n\nI think yes. Here's a possible proof sketch: Since X_n converges in probability to X, and E|X_n| converges to E|X|, then by a result in Chung's \"A Course in Probability Theory\", if X_n → X in probability and {X_n} is uniformly integrable, then E|X_n| → E|X|. Conversely, if X_n → X in probability and E|X_n| → E|X|, then {X_n} is uniformly integrable. Wait, I might be confusing the directions here. \n\nAlternatively, recall that uniform integrability can be characterized by: For every ε > 0, there exists δ > 0 such that for every A with P(A) < δ, E[|X_n| 1_A] < ε for all n. \n\nSince X_n converges in probability to X, given any δ, for sufficiently large n, P(|X_n - X| > ε) < δ. But I'm not sure. \n\nAlternatively, another approach: Since X_n → X a.s., by Egorov's theorem, for any ε > 0, there exists a set A with P(A) < ε such that X_n → X uniformly on A^c. Then, on A^c, |X_n| ≤ |X| + 1 for sufficiently large n. Then, the integral over A^c can be controlled, and the integral over A is small because P(A) is small. But this seems similar to showing uniform integrability. \n\nAlternatively, using the fact that if E|X_n| → E|X|, and X_n → X a.s., then by the Skorokhod representation theorem, since we have a.s. convergence, maybe we can work on a different probability space where convergence is almost sure, but I don't think that helps here. \n\nWait, but let's think directly. Suppose we have X_n → X a.s., and E|X_n| → E|X|. We want to show E|X_n - X| → 0. \n\nConsider that |X_n - X| ≤ |X_n| + |X|, so E|X_n - X| ≤ E|X_n| + E|X| → 2E|X|. But that's just boundedness. To show convergence, maybe use the dominated convergence theorem? For that, we would need |X_n - X| ≤ Y for some integrable Y. But since X_n → X a.s., we can write |X_n| ≤ |X| + |X_n - X|. If we can bound |X_n - X| by something, but without UI or domination, I don't think that's possible. \n\nAlternatively, consider the function f_a(x) = |x| if |x| ≤ a, and a otherwise. Then f_a is a contraction. So, E|X_n| ≥ E[f_a(X_n)]. As a → ∞, E[f_a(X_n)] → E|X_n|. Similarly for X. If E|X_n| → E|X|, then for any ε > 0, there exists a such that E|X_n| - E[f_a(X_n)] < ε for all n. Because otherwise, there exists ε > 0 and a subsequence n_k where E|X_{n_k}| - E[f_k(X_{n_k})] ≥ ε. But since E|X_{n_k}| → E|X|, which is finite, and E[f_k(X_{n_k})] would approach E|X_{n_k}|, which is a contradiction. Hence, the tails are uniformly controlled, implying uniform integrability. \n\nTherefore, the sequence {X_n} is uniformly integrable. Then, since we have convergence in probability (from a.s. convergence), by Vitali's theorem, we have L1 convergence. \n\nSo the answer is yes, the conclusion holds. Therefore, the initial approach using uniform integrability is correct, even if it feels indirect. The user was concerned that they aren't \"really\" using almost sure convergence, but since a.s. convergence implies convergence in probability, and the key part is the uniform integrability from the convergence of expectations, the proof is valid. \n\nAlternatively, there might be a more direct approach using the a.s. convergence. For example, consider that |X_n - X| → 0 a.s., and if we can apply the Vitali convergence theorem which requires the sequence |X_n - X| to be uniformly integrable. But I think that still circles back to needing UI of X_n. \n\nAnother angle: Since X_n → X a.s., and E|X_n| → E|X|, then by the reverse Fatou lemma, lim sup E|X_n| ≤ E|X|. But since the lim inf is also ≥ E|X| by Fatou, we have convergence. But how does that help with L1 convergence? \n\nAlternatively, consider that E|X_n - X| = E[|X_n - X|] ≤ E[|X_n| - |X|] + 2E[ |X| 1_{|X_n - X| > ε} ]... Not sure. \n\nWait, maybe write |X_n - X| as |X_n - X| = |X_n - X| (1_{|X_n - X| ≥ ε} + 1_{|X_n - X| < ε}). Then, E|X_n - X| ≤ ε + E[|X_n - X| 1_{|X_n - X| ≥ ε}]. Since X_n → X a.s., for any ε > 0, the measure of {|X_n - X| ≥ ε} tends to zero. If we can show that E[|X_n - X| 1_{|X_n - X| ≥ ε}] → 0, then the whole thing tends to zero. But to show that, we need uniform integrability of |X_n - X|. But |X_n - X| is dominated by |X_n| + |X|. If |X_n| is UI and |X| is integrable, then |X_n| + |X| is UI. Hence, |X_n - X| is UI. Therefore, E[|X_n - X| 1_{|X_n - X| ≥ ε}] can be made small uniformly in n for large a. \n\nBut this again relies on UI of X_n. So the crux is still showing that X_n is UI, which comes from convergence of expectations. Therefore, the initial approach is correct. \n\nIn conclusion, the answer is that the statement is true: under the conditions of almost sure convergence and convergence of expectations to a finite limit, L1 convergence follows. The proof involves showing uniform integrability using the convergence of expectations and then applying Vitali's theorem.",
    "Original_Problem": "Assumption: \n$X_n$ converges to $X$ almost surely as $n \\rightarrow \\infty$,\n$\\lim_{n \\rightarrow \\infty} \\mathbb{E}|X_n| = \\mathbb{E}|X|$,\n$\\mathbb{E}|X| < \\infty$.\nProblem: \nProve or disprove that $X_n \\rightarrow X$ in $L^1$, i.e., $\\lim_{n \\rightarrow \\infty} \\mathbb{E}[|X_n - X|] = 0$.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $X_n$ converges to $X$ almost surely as $n \\rightarrow \\infty$,\nAssumption 2: $\\lim_{n \\rightarrow \\infty} \\mathbb{E}|X_n| = \\mathbb{E}|X|$,\nAssumption 3: $\\mathbb{E}|X| < \\infty$.\nProblem: \nProve or disprove that $X_n \\rightarrow X$ in $L^1$, i.e., $\\lim_{n \\rightarrow \\infty} \\mathbb{E}[|X_n - X|] = 0$.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$ \\int \\vert f_n - f_n^* \\vert = \\int \\vert f_n \\vert - \\int \\vert f_n^* \\vert. $$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $X_n$ converges to $X$ almost surely as $n \\rightarrow \\infty$,\nAssumption 2: $\\lim_{n \\rightarrow \\infty} \\mathbb{E}|X_n| = \\mathbb{E}|X|$,\nAssumption 3: $\\mathbb{E}|X| < \\infty$.\nAssumption 4: $$ \\int \\vert f_n - f_n^* \\vert = \\int \\vert f_n \\vert - \\int \\vert f_n^* \\vert. $$\nProblem: \nProve or disprove that $X_n \\rightarrow X$ in $L^1$, i.e., $\\lim_{n \\rightarrow \\infty} \\mathbb{E}[|X_n - X|] = 0$."
}