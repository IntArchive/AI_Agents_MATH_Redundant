{
    "Link_API": "https://api.stackexchange.com/2.3/questions/243348",
    "Title": "Sample variance converge almost surely",
    "Score": 15,
    "Category": "Chứng minh",
    "Tags": "probability-theory, statistics, convergence-divergence",
    "Link": "https://math.stackexchange.com/questions/243348/sample-variance-converge-almost-surely",
    "Content": "Suppose $X_{1},X_{2},\\ldots$ be i.i.d. random variables such that\n$E\\left[X_{i}\\right]=\\mu$ and $Var(X_{i})=\\sigma^{2}<\\infty$. Let\n$\\bar{X}=\\left(X_{1}+\\cdots+X_{n}\\right)/n$. Show that $\\frac{1}{n}\\overset{n}{\\underset{i=1}{\\sum}}\\left(X_{i}-\\bar{X}\\right)^{2}\\rightarrow\\sigma^{2}$\na.s. Solution: Let $S_{n}=\\frac{1}{n}\\overset{n}{\\underset{i=1}{\\sum}}\\left(X_{i}-\\bar{X}\\right)^{2}$.\nBy Chebyshev's Inequality, $\\sum_{n=1}^{\\infty}P\\left(\\left|S_{n}-E\\left[S_{n}\\right]\\right|>\\varepsilon\\right)\\leq\\sum_{n=1}^{\\infty}\\frac{Var(S_{n})}{\\varepsilon^{2}}$.\nAnd we know that $E\\left[S_{n}\\right]\\rightarrow\\sigma^{2}$, so I\nwould like to finish this proof by using first Borel-Cantelli Lemma\nif I can show the right hand side is summable. However, $Var(S_{n})=\\frac{2\\sigma^{4}}{n-1}$,\nso the sum is infinity, which means it doesn't converge almost surely.\nWhere am I wrong?",
    "AcceptedAnswer": "Since you used an inequality to obtain an estimate for $\\mathbb{P}(|S_n-\\mathbb{E}S_n|>\\varepsilon)$ the fact that the sum does not converge does not imply that $S_n$ does not converge almost surely. It's easier like that: $$\\begin{align} (X_i-\\mu+(\\mu-\\bar{X}))^2 &= (X_i-\\mu)^2 + 2 (X_i-\\mu) \\cdot (\\mu-\\bar{X})+(\\mu-\\bar{X})^2 \\\\\n\\Rightarrow S_n= \\frac{1}{n} \\sum_{i=1}^n (X_i-\\bar{X})^2 &= \\frac{1}{n} \\sum_{i=1}^n (X_i-\\mu)^2 + 2 (\\mu-\\bar{X}) \\underbrace{\\frac{1}{n} \\cdot \\sum_{i=1}^n (X_i-\\mu)}_{\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right)-\\mu =(\\bar{X}-\\mu)} + (\\mu-\\bar{X})^2 \\\\ &=  \\frac{1}{n} \\sum_{i=1}^n (X_i-\\mu)^2  - (\\bar{X}-\\mu)^2 \\end{align}$$ By the strong law of large numbers we obtain $$\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i \\to \\mu \\quad \\text{almost surely} \\\\ \\frac{1}{n} \\sum_{i=1}^n (X_i-\\mu)^2 \\to \\mathbb{E} \\left( (X_i-\\mu)^2 \\right)=\\sigma^2 \\quad \\text{almost surely} $$ Hence $S_n \\to \\sigma^2$ almost surely.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$X_1, X_2, \\ldots$ are independent and identically distributed (i.i.d.) random variables,\nEach $X_i$ has expected value $\\mu$,\nEach $X_i$ has variance $\\sigma^2$,\n$\\sigma^2$ is finite.\nProblem: \nShow that $$\\frac{1}{n}\\sum_{i=1}^n \\left(X_i - \\bar{X}\\right)^2 \\rightarrow \\sigma^2$$ almost surely, where $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$.\n###",
    "reasoning_create_structured_problem": "Okay, let's see. The user wants me to act as a bilingual math professor and structure the given problem from Math Stack Exchange into their specified format. The example they provided involved listing assumptions line by line and then stating the problem. \n\nFirst, I need to parse the original question from the user. The problem is about showing that the sample variance converges almost surely to the population variance. The user mentions that they tried using Chebyshev's Inequality and Borel-Cantelli but ran into an issue because the variance of S_n leads to a divergent series.\n\nSo, my task is to extract the assumptions and the problem statement. Let me read through the original question again. The user states that X₁, X₂, ... are i.i.d. random variables with mean μ and variance σ² < ∞. Then, they define the sample mean X̄ and the sample variance S_n as 1/n times the sum of (X_i - X̄)². The problem is to show that S_n converges almost surely to σ².\n\nNow, breaking down the assumptions. Each assumption should address one property or condition of a single object. The first assumption is that the random variables X₁, X₂, ... are independent and identically distributed (i.i.d.). That's one line. Then, each X_i has expected value μ. That's another line. Next, each X_i has finite variance σ². Then, the problem defines S_n as the sample variance. The problem statement is to show that S_n converges almost surely to σ².\n\nWait, but in the original problem, the user also mentions their attempt involving Chebyshev and Borel-Cantelli. However, in the example given, the formatted problem didn't include the user's solution attempt. So, the answer should filter out the solution attempt and focus only on the problem statement and assumptions.\n\nTherefore, the assumptions should list the i.i.d. property, the expectation, the finite variance, and the definition of S_n as the sample variance. Wait, but the definition of S_n is part of the problem setup, not an assumption. So perhaps the assumptions are:\n\n1. X₁, X₂, ... are i.i.d. random variables.\n2. Each X_i has expected value μ.\n3. Each X_i has variance σ².\n4. σ² is finite.\n\nThen, the problem is to show that S_n, defined as the sample variance, converges almost surely to σ².\n\nBut wait, in the example provided, the assumptions listed the conditions on n and A(n). So in this case, the assumptions are on the random variables. Let me check the example again. In the example, the original problem had A(n) defined, and the assumptions were that n is an integer and n is divisible by 7. However, in the user's problem here, the conditions are on the X_i's.\n\nSo translating that, the assumptions here would be:\n\n- X₁, X₂, ... are i.i.d.\n- Each X_i has expectation μ.\n- Each X_i has variance σ².\n- The variance σ² is finite.\n\nBut since the problem mentions \"σ² < ∞\", that's part of the variance condition, so maybe combine the variance into one line. However, according to the user's example, each assumption should be a single line, addressing one property. So perhaps:\n\nAssumption:\nThe random variables X₁, X₂, ... are independent and identically distributed (i.i.d.),\nEach X_i has expected value μ,\nEach X_i has variance σ²,\nσ² is finite.\n\nBut in the original problem statement, the variance is given as σ² < ∞, so maybe split into two lines: Each X_i has variance σ², and σ² is finite. Wait, but \"Var(X_i) = σ² < ∞\" is a single condition. However, following the example's structure, which split \"n is an integer\" and \"n is divisible by 7\" into separate lines, even though both are about n. So here, perhaps \"Each X_i has variance σ²\" and \"σ² is finite\" as separate lines. Although technically, Var(X_i) = σ² implies σ² is finite, but maybe the problem states it as σ² < ∞ to emphasize finiteness, so that's a separate condition.\n\nBut maybe the user's original problem says \"Var(X_i) = σ² < ∞\", so combining both into one line. But according to the example's format, each line should have one condition. So if Var(X_i) = σ² and σ² is finite are two separate conditions? Hmm, perhaps the Var(X_i) = σ² is one line, and σ² is finite (σ² < ∞) is another. Because the problem explicitly mentions σ² < ∞. Therefore, the assumptions are:\n\n1. X₁, X₂, ... are i.i.d. random variables.\n2. Each X_i has expected value μ.\n3. Each X_i has variance σ².\n4. σ² is finite.\n\nThen, the problem is to show that S_n converges almost surely to σ², where S_n is defined as (1/n) sum_{i=1}^n (X_i - X̄)^2.\n\nWait, but in the problem statement, the user wrote \"Show that 1/n sum (X_i - X̄)^2 → σ² a.s.\" So maybe the problem is to show that the sample variance (using 1/n) converges to σ² almost surely. But in standard statistics, the sample variance is often 1/(n-1) sum ... , but here the problem uses 1/n. So that's part of the problem's setup.\n\nTherefore, the problem statement is: Show that (1/n) sum_{i=1}^n (X_i - X̄)^2 converges almost surely to σ².\n\nSo putting it all together, the assumptions are as listed, and the problem is to show the almost sure convergence.\n\nSo the formatted problem should be:\n\nAssumption:\nX₁, X₂, ... are independent and identically distributed (i.i.d.),\nEach X_i has expected value μ,\nEach X_i has variance σ²,\nσ² is finite.\n\nProblem:\nShow that $$\\frac{1}{n}\\sum_{i=1}^n \\left(X_i - \\bar{X}\\right)^2 \\rightarrow \\sigma^2$$ almost surely.\n\nI need to check if there's any other assumption. The user's problem mentions \"Var(X_i) = σ² < ∞\", so the fourth assumption is covered by \"σ² is finite\". The rest are covered.\n\nSo this should be the correct formatting.",
    "Original_Problem": "Assumption: \n$X_1, X_2, \\ldots$ are independent and identically distributed (i.i.d.) random variables,\nEach $X_i$ has expected value $\\mu$,\nEach $X_i$ has variance $\\sigma^2$,\n$\\sigma^2$ is finite.\nProblem: \nShow that $$\\frac{1}{n}\\sum_{i=1}^n \\left(X_i - \\bar{X}\\right)^2 \\rightarrow \\sigma^2$$ almost surely, where $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $X_1, X_2, \\ldots$ are independent and identically distributed (i.i.d.) random variables,\nAssumption 2: Each $X_i$ has expected value $\\mu$,\nAssumption 3: Each $X_i$ has variance $\\sigma^2$,\nAssumption 4: $\\sigma^2$ is finite.\nProblem: \nShow that $$\\frac{1}{n}\\sum_{i=1}^n \\left(X_i - \\bar{X}\\right)^2 \\rightarrow \\sigma^2$$ almost surely, where $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i \\to \\mu \\quad \\text{almost surely} \\\\ \\frac{1}{n} \\sum_{i=1}^n (X_i-\\mu)^2 \\to \\mathbb{E} \\left( (X_i-\\mu)^2 \\right)=\\sigma^2 \\quad \\text{almost surely} $$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $X_1, X_2, \\ldots$ are independent and identically distributed (i.i.d.) random variables,\nAssumption 2: Each $X_i$ has expected value $\\mu$,\nAssumption 3: Each $X_i$ has variance $\\sigma^2$,\nAssumption 4: $\\sigma^2$ is finite.\nAssumption 5: $$\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i \\to \\mu \\quad \\text{almost surely} \\\\ \\frac{1}{n} \\sum_{i=1}^n (X_i-\\mu)^2 \\to \\mathbb{E} \\left( (X_i-\\mu)^2 \\right)=\\sigma^2 \\quad \\text{almost surely} $$\nProblem: \nShow that $$\\frac{1}{n}\\sum_{i=1}^n \\left(X_i - \\bar{X}\\right)^2 \\rightarrow \\sigma^2$$ almost surely, where $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$."
}