{
    "Link_API": "https://api.stackexchange.com/2.3/questions/47009",
    "Title": "Proof of $\\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2_{n-1}$",
    "Score": 43,
    "Category": "Chứng minh",
    "Tags": "statistics, probability-distributions",
    "Link": "https://math.stackexchange.com/questions/47009/proof-of-fracn-1s2-sigma2-sim-chi2-n-1",
    "Content": "It's a standard result that given $X_1,\\cdots ,X_n $ random sample from $N(\\mu,\\sigma^2)$, the random variable $$\\frac{(n-1)S^2}{\\sigma^2}$$ has a chi-square distribution with $(n-1)$ degrees of freedom, where $$S^2=\\frac{1}{n-1}\\sum^{n}_{i=1}(X_i-\\bar{X})^2.$$\nI would like help in proving the above result. Thanks.",
    "AcceptedAnswer": "A standard proof goes something like this.  It assumes you already know the following. $\\bar{X}$ (the sample mean) and $S^2$ are independent. If $Z \\sim N(0,1)$ then $Z^2 \\sim \\chi^2(1)$. If $X_i \\sim \\chi^2(1)$ and the $X_i$ are independent then $\\sum_{i=1}^n X_i \\sim \\chi^2(n)$. A $\\chi^2(n)$ random variable has the moment generating function $(1-2t)^{-n/2}$. With some algebra, you can show, by adding $-\\bar{X} + \\bar{X}$ inside the parentheses and grouping appropriately, that $\\sum_{i=1}^n (X_i - \\mu)^2 = \\sum_{i=1}^n (X_i - \\bar{X})^2 + n(\\bar{X} - \\mu)^2$.  Then, dividing through by $\\sigma^2$ yields\n$$ \\sum_{i=1}^n \\left(\\frac{X_i - \\mu}{\\sigma}\\right)^2 = \\sum_{i=1}^n \\left(\\frac{X_i - \\bar{X}}{\\sigma}\\right)^2 +  \\left(\\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}}\\right)^2.$$ Denote these expressions by $U, V$, and $W$, respectively, so that the formula reads $U = V+W$. \nBy facts (2) and (3) above, $U \\sim \\chi^2(n)$ and $W \\sim \\chi^2(1)$.  Also, $V = \\frac{(n-1)S^2}{\\sigma^2}$. Since $\\bar{X}$ and $S^2$ are independent, so are $V$ and $W$.  Thus $M_U(t) = M_V(t) M_W(t)$, where $M_X(t)$ denotes the moment generating function of the random variable $X$.  By fact (4) above, this says that $$\\frac{1}{(1-2t)^{n/2}} = M_V(t) \\frac{1}{(1-2t)^{1/2}}.$$ \nThus $$M_V(t) = \\frac{1}{(1-2t)^{(n-1)/2}},$$ and therefore $V \\sim \\chi^2(n-1)$.",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$X_1, X_2, \\dots, X_n$ are independent random variables,\neach $X_i$ follows a normal distribution $N(\\mu, \\sigma^2)$,\n$\\bar{X}$ is the sample mean defined as $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$,\n$S^2$ is the sample variance defined as $S^2 = \\frac{1}{n-1}\\sum_{i=1}^n (X_i - \\bar{X})^2$.\nProblem: \nProve that the random variable $$\\frac{(n-1)S^2}{\\sigma^2}$$ follows a chi-square distribution with $n-1$ degrees of freedom.\n###END_OF_FORMAT###",
    "reasoning_create_structured_problem": "Okay, let's tackle this problem step by step. The user wants to prove that the random variable (n-1)S²/σ² follows a chi-square distribution with n-1 degrees of freedom, given that X₁,...,Xₙ is a random sample from a normal distribution N(μ, σ²). \n\nFirst, I need to recall the basic definitions and theorems related to this. The sample variance S² is defined as the sum of squared deviations from the sample mean divided by n-1. The key here is understanding the distribution of this sum. \n\nI remember that for normal distributions, the sum of squared deviations from the population mean divided by σ² follows a chi-square distribution with n degrees of freedom. But in this case, we're using the sample mean instead of the population mean, which introduces a dependency among the terms in the sum. This probably reduces the degrees of freedom by 1. \n\nThere's a theorem called Cochran's theorem that might be relevant here. Cochran's theorem deals with the distribution of quadratic forms in normal variables. If I can express the sum ∑(Xᵢ - X̄)² as a quadratic form that meets the conditions of Cochran's theorem, then it would follow that this sum divided by σ² is chi-square distributed with n-1 degrees of freedom. \n\nAlternatively, another approach could involve transforming the original variables into a set of independent normal variables. For example, using the fact that the sample mean and sample variance are independent in normal samples. If I can show that (n-1)S²/σ² is a sum of squares of n-1 independent standard normal variables, then that would prove the result. \n\nLet me think about the transformation. Suppose we define Zᵢ = (Xᵢ - μ)/σ, which are standard normal variables. Then the sum ∑Zᵢ² would be chi-square(n). But when we replace μ with X̄, the sum becomes ∑(Zᵢ - Z̄)², where Z̄ is the sample mean of the Zᵢ's. This sum should be chi-square(n-1) because we're estimating one parameter (the mean), which consumes one degree of freedom. \n\nYes, that makes sense. The key idea is that estimating the mean from the data itself imposes a linear constraint, reducing the degrees of freedom by one. Therefore, the quadratic form involving the sample variance has a chi-square distribution with n-1 degrees of freedom.\n\nI should also mention the independence of the sample mean and sample variance in normal distributions, which is a crucial point here. Since they are independent, the distribution of the sample variance doesn't depend on the sample mean, reinforcing that it's a chi-square distribution with the reduced degrees of freedom.\n\nAnother way to look at it is through the lens of orthogonal transformations. If we apply an orthogonal transformation to the data vector, such that one component is the sample mean and the remaining components are some orthogonal directions, then the sum of squares of the remaining components (which corresponds to the sample variance) would follow a chi-square distribution with n-1 degrees of freedom. This is because the transformation preserves the independence and normality of the variables.\n\nPutting it all together, the proof would involve showing that the sum ∑(Xᵢ - X̄)² can be expressed as a sum of n-1 independent standard normal variables squared, hence scaling by σ² and multiplying by (n-1) gives the chi-square distribution with n-1 degrees of freedom.",
    "Original_Problem": "Assumption: \n$X_1, X_2, \\dots, X_n$ are independent random variables,\neach $X_i$ follows a normal distribution $N(\\mu, \\sigma^2)$,\n$\\bar{X}$ is the sample mean defined as $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$,\n$S^2$ is the sample variance defined as $S^2 = \\frac{1}{n-1}\\sum_{i=1}^n (X_i - \\bar{X})^2$.\nProblem: \nProve that the random variable $$\\frac{(n-1)S^2}{\\sigma^2}$$ follows a chi-square distribution with $n-1$ degrees of freedom.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $X_1, X_2, \\dots, X_n$ are independent random variables,\nAssumption 2: each $X_i$ follows a normal distribution $N(\\mu, \\sigma^2)$,\nAssumption 3: $\\bar{X}$ is the sample mean defined as $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$,\nAssumption 4: $S^2$ is the sample variance defined as $S^2 = \\frac{1}{n-1}\\sum_{i=1}^n (X_i - \\bar{X})^2$.\nProblem: \nProve that the random variable $$\\frac{(n-1)S^2}{\\sigma^2}$$ follows a chi-square distribution with $n-1$ degrees of freedom.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$\\frac{1}{(1-2t)^{n/2}} = M_V(t) \\frac{1}{(1-2t)^{1/2}}.$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $X_1, X_2, \\dots, X_n$ are independent random variables,\nAssumption 2: each $X_i$ follows a normal distribution $N(\\mu, \\sigma^2)$,\nAssumption 3: $\\bar{X}$ is the sample mean defined as $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$,\nAssumption 4: $S^2$ is the sample variance defined as $S^2 = \\frac{1}{n-1}\\sum_{i=1}^n (X_i - \\bar{X})^2$.\nAssumption 5: $$\\frac{1}{(1-2t)^{n/2}} = M_V(t) \\frac{1}{(1-2t)^{1/2}}.$$\nProblem: \nProve that the random variable $$\\frac{(n-1)S^2}{\\sigma^2}$$ follows a chi-square distribution with $n-1$ degrees of freedom."
}