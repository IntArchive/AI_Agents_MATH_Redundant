{
    "Link_API": "https://api.stackexchange.com/2.3/questions/243925",
    "Title": "Integral of Brownian motion is Gaussian?",
    "Score": 43,
    "Category": "Chứng minh",
    "Tags": "probability-theory, probability-distributions, brownian-motion, stochastic-integrals",
    "Link": "https://math.stackexchange.com/questions/243925/integral-of-brownian-motion-is-gaussian",
    "Content": "Let $(W_t)$ be a standard Brownian motion, so that $W_t \\sim N(0,t)$. I'm trying to show that the random variable defined by $Z_t = \\int_0^t W_s \\ ds$ is a Gaussian random variable, but have not gotten very far. I tried approximating the integral by a Riemann sum: choose $\\delta, M$ such that $M\\delta = t$, then the integral is approximated by\n$$\n\\sum_{k=0}^{M-1} (W_{(k+1)\\delta} - W_{k\\delta}  )\\delta = \\delta \\sum\\limits_{k=0}^{M-1} X_k\n$$\nwhere using standard properties of the Brownian motion, the $X_k$'s are independent identically distributed $N(0, \\delta)$ random variables. So I find that $Z_t$ is approximated by a random variable with distribution $ N(0, M\\delta^3) = N(0,t\\delta^2) $. Now letting $ \\delta \\to 0$, I find the variance of $Z_t$ is also $0$, which does not make sense to me. Any help is appreciated!",
    "AcceptedAnswer": "First of all, the Riemann sum is given by $$\\sum_{k=0}^{M-1} W_{k \\delta} \\cdot (\\delta (k+1)-\\delta k).$$ Note that this expression does not equal $$\\sum_{k=0}^{M-1} (W_{(k+1)\\delta}-W_{k \\delta}) \\cdot \\delta.$$ Let $t_k := \\delta \\cdot k$, then $$\\begin{align} G_M &:= \\sum_{k=0}^{M-1} W_{k \\cdot \\delta} \\cdot (t_{k+1}-t_k) =\\ldots= \\sum_{k=0}^{M-1} (W_{t_{k-1}} - W_{t_k}) \\cdot t_k + W_{t_{M-1}} \\cdot t \\\\ &= \\sum_{k=0}^{M-1} (W_{t_{k-1}}-W_{t_k}) \\cdot (t_k-t) \\end{align}$$ where $t_{-1}:=0$. Clearly, $G_M$ is Gaussian, $\\mathbb{E}G_M=0$ and (using the independence of the increments) $$\\begin{align*} \\mathbb{E}(G_M^2)& = \\sum_{k=0}^{M-1} (t_k-t)^2 \\cdot \\underbrace{\\mathbb{E}((W_{t_k}-W_{t_{k-1}})^2)}_{t_k-t_{k-1}} \\\\ &\\to \\int_0^t (s-t)^2 \\, ds \\quad \\text{as} \\, \\, M \\to \\infty. \\end{align*}$$ Hence, as $G_M \\to Z_t$ as $M \\to \\infty$ almost surely, we conclude that $Z_t$ is Gaussian with mean $0$ and variance $\\int_0^t (s-t)^2 \\, ds$ (see this question for further details). Remark: In fact, the statement holds in a more general setting. The random variable $Y_t := \\int_0^t X_s \\, ds$ is Gaussian for any (measurable) Gaussian process $(X_t)_{t \\geq 0}$, see this question .",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$(W_t)$ is a standard Brownian motion,\n$W_t$ follows a normal distribution $N(0, t)$,\n$Z_t$ is defined as $Z_t = \\int_0^t W_s \\, ds$.\nProblem: \nProve that $Z_t = \\int_0^t W_s \\, ds$ is a Gaussian random variable.\n###",
    "reasoning_create_structured_problem": "Okay, let's start by understanding the problem here. The user wants to show that the integral of a Brownian motion over time, specifically Z_t = ∫₀ᵗ W_s ds, is a Gaussian random variable. They tried approximating the integral with a Riemann sum but ended up with a variance that goes to zero as the partition becomes finer, which doesn't make sense. Let me break this down.\n\nFirst, let's recall that a Brownian motion W_t is a Gaussian process with mean zero and variance t. The increments are independent and normally distributed. The user's approach was to approximate the integral by a Riemann sum: splitting the interval [0, t] into M subintervals each of width δ = t/M. Then the integral becomes a sum of terms involving increments of W multiplied by δ.\n\nIn their calculation, they approximated the integral as δ times the sum of X_k, where each X_k is N(0, δ). But wait, if each X_k is the increment W_{(k+1)δ} - W_{kδ}, then that's correct—each increment is normal with mean 0 and variance δ. So summing them would give a normal variable with variance Mδ (since variances add for independent variables). Then multiplying by δ gives a variance of δ² * Mδ = Mδ³. Since M = t/δ, substituting gives Mδ³ = tδ². So as δ approaches zero, the variance would indeed go to zero. But that's a problem because the actual variance of Z_t shouldn't be zero. \n\nHmm, so there's a mistake in the approximation here. Maybe the Riemann sum approach isn't capturing the right dependency structure? Alternatively, perhaps the Riemann sum is not the best way to approach this. Let's think: the integral ∫₀ᵗ W_s ds can be expressed as a linear combination of the Brownian motion at different times. Since Brownian motion is a Gaussian process, any linear combination (or integral) of its values should also be Gaussian. But to show that rigorously, maybe we need to consider the covariance structure or use properties of Gaussian processes.\n\nAlternatively, maybe the user made an error in how they set up the Riemann sum. Let's check their steps again. They approximated Z_t ≈ δ Σ_{k=0}^{M-1} W_{kδ} δ. Wait, no, the standard Riemann sum for ∫₀ᵗ W_s ds would approximate the integral as Σ_{k=0}^{M-1} W_{kδ} * δ. But the user wrote the sum as Σ (W_{(k+1)δ} - W_{kδ}) δ. Wait, that seems different. Wait, hold on. If they are using the increments multiplied by δ, that's not the same as evaluating W at the left endpoint. Instead, they might be confusing the integral with the quadratic variation or something else.\n\nWait, actually, integrating W_s ds from 0 to t would typically be approximated by summing W_{kδ} * δ for each subinterval. But the user wrote the sum as (W_{(k+1)δ} - W_{kδ}) * δ. That seems incorrect because each term in the Riemann sum should be W_s evaluated at some point times the interval width. Instead, they are taking the increment of W over the subinterval and multiplying by δ. That might not approximate the integral correctly. \n\nSo, the mistake might be in the Riemann sum setup. The correct approximation should be Σ W_{kδ} * δ, not Σ (W_{(k+1)δ} - W_{kδ}) * δ. The latter would be like integrating the increments of W, but the integral of W_s ds is summing W_s over the interval, not its increments. Therefore, the user's Riemann sum is incorrectly formulated. \n\nIf they use the correct Riemann sum, which is Σ W_{kδ} δ, then each term W_{kδ} is N(0, kδ) because W_{kδ} ~ N(0, kδ). Wait, but the sum Σ W_{kδ} δ would then be a sum of normal variables with different variances and they are correlated because W_{kδ} and W_{jδ} are correlated for j ≠ k. However, the sum of correlated normals is still normal. So maybe the variance calculation needs to account for the covariance between terms.\n\nAlternatively, we can compute the variance of Z_t directly. Since Z_t is ∫₀ᵗ W_s ds, then Var(Z_t) = E[(∫₀ᵗ W_s ds)^2] = E[∫₀ᵗ ∫₀ᵗ W_u W_v du dv] = ∫₀ᵗ ∫₀ᵗ E[W_u W_v] du dv. Since E[W_u W_v] = min(u, v), then Var(Z_t) = ∫₀ᵗ ∫₀ᵗ min(u, v) du dv. Computing this double integral would give the correct variance. Let's do that:\n\nFor u from 0 to t and v from 0 to t, split the integral into two regions: u ≤ v and u > v.\n\nSo Var(Z_t) = 2 ∫₀ᵗ ∫₀^u v dv du. Wait, no. Let me correct that. The integral over u and v from 0 to t of min(u, v) is equal to 2 ∫₀ᵗ ∫₀^u v dv du. Wait, actually, let's fix the limits. If we consider u ≤ v, then min(u, v) = u. So ∫₀ᵗ ∫₀ᵗ min(u, v) du dv = ∫₀ᵗ ∫₀^v u du dv + ∫₀ᵗ ∫v^t v du dv.\n\nFirst integral: ∫₀ᵗ [ (u²)/2 from 0 to v ] dv = ∫₀ᵗ v²/2 dv = (1/2)(t³/3) = t³/6.\n\nSecond integral: ∫₀ᵗ v*(t - v) dv = ∫₀ᵗ (t v - v²) dv = (t³/2 - t³/3) = t³/6.\n\nAdding both parts: t³/6 + t³/6 = t³/3. So Var(Z_t) = t³/3. Therefore, Z_t ~ N(0, t³/3). But this contradicts the user's result where they found the variance approaching zero. So the error must be in their Riemann sum approach. \n\nGoing back, the user approximated the integral as the sum of increments multiplied by δ, which is not correct. The correct Riemann sum should involve evaluating W at points and multiplying by δ, not the increments. So when they approximated Z_t ≈ δ Σ X_k where X_k are increments, that's not the integral of W_s ds, but rather the integral of dW_s times δ, which would indeed be a scaled sum of increments. But integrating dW_s would give W_t - W_0 = W_t, but multiplied by δ? That seems confused. \n\nAlternatively, maybe the user confused the Riemann sum for the integral ∫ W_s ds with the stochastic integral ∫ dW_s, but they are different. The Riemann sum for ∫ W_s ds is indeed Σ W_{kδ} δ, which is a sum of correlated normals. The sum of correlated normals is still normal, so Z_t should be Gaussian. The variance calculation via the double integral gives t³/3. So the user's mistake was in the setup of the Riemann sum, leading to an incorrect variance that goes to zero. \n\nTherefore, the key steps are: recognizing that the integral of a Gaussian process is Gaussian, properly setting up the Riemann sum as Σ W_{kδ} δ, then taking the limit. The sum of correlated normals is normal, and the variance can be computed via the covariance function. Alternatively, use integration techniques to compute the variance directly, which shows it's t³/3, not zero. Hence, Z_t is indeed Gaussian with mean 0 and variance t³/3.",
    "Original_Problem": "Assumption: \n$(W_t)$ is a standard Brownian motion,\n$W_t$ follows a normal distribution $N(0, t)$,\n$Z_t$ is defined as $Z_t = \\int_0^t W_s \\, ds$.\nProblem: \nProve that $Z_t = \\int_0^t W_s \\, ds$ is a Gaussian random variable.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $(W_t)$ is a standard Brownian motion,\nAssumption 2: $W_t$ follows a normal distribution $N(0, t)$,\nAssumption 3: $Z_t$ is defined as $Z_t = \\int_0^t W_s \\, ds$.\nProblem: \nProve that $Z_t = \\int_0^t W_s \\, ds$ is a Gaussian random variable.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$\\sum_{k=0}^{M-1} (W_{(k+1)\\delta}-W_{k \\delta}) \\cdot \\delta.$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $(W_t)$ is a standard Brownian motion,\nAssumption 2: $W_t$ follows a normal distribution $N(0, t)$,\nAssumption 3: $Z_t$ is defined as $Z_t = \\int_0^t W_s \\, ds$.\nAssumption 4: $$\\sum_{k=0}^{M-1} (W_{(k+1)\\delta}-W_{k \\delta}) \\cdot \\delta.$$\nProblem: \nProve that $Z_t = \\int_0^t W_s \\, ds$ is a Gaussian random variable."
}