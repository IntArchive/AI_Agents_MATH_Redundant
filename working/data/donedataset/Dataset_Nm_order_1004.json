{
    "Link_API": "https://api.stackexchange.com/2.3/questions/530915",
    "Title": "&quot;If $1/a + 1/b = 1 /c$ where $a, b, c$ are positive integers with no common factor, $(a + b)$ is the square of an integer&quot;",
    "Score": 24,
    "Category": "Chứng minh",
    "Tags": "elementary-number-theory, recreational-mathematics, contest-math",
    "Link": "https://math.stackexchange.com/questions/530915/if-1-a-1-b-1-c-where-a-b-c-are-positive-integers-with-no-common-fact",
    "Content": "If $1/a  +  1/b  =  1 /c$   where $a, b, c$ are positive integers with no common factor, $(a + b)$ is the square of an integer. I found this question in RMO 1992 paper ! Can anyone help me to prove this ? May be it's too easy and simple . But , I'm just novice in number theory !",
    "AcceptedAnswer": "Let $\\gcd(a,b) = g$, and $a = a'g$ and $b = b'g$ (so that $\\gcd(a', b') = 1$). The equation $\\frac1a + \\frac1b = \\frac1c$ is the same as $c(a+b) = ab$, which, dividing throughout by $g$, is $$c(a' + b') = a'b'g.$$ Now, as $(a' + b')$ divides $a'b'g$ but is relatively prime to both $a'$ and $b'$, it must divide $g$. Similarly, as $g$ divides $c(a'+b')$ but is relatively prime to $c$ (note that $\\gcd(g, c) = \\gcd(\\gcd(a,b), c) = \\gcd(a, b, c) = 1$) it must divide $(a' + b')$. Thus as both $g$ and $(a' + b')$ divide each other, we have $$(a' + b') = g,$$ and therefore \n$$(a + b) = g(a' + b') = g^2.$$",
    "llm_answer_create_structured_problem": "###BEGIN_OF_FORMAT###\nAssumption: \n$a$, $b$, $c$ are positive integers,\n$\\gcd(a, b, c) = 1$,\n$\\frac{1}{a} + \\frac{1}{b} = \\frac{1}{c}$.\nProblem: \nProve that $a + b$ is the square of an integer.\n###",
    "reasoning_create_structured_problem": "Okay, let's try to tackle this problem. So, the problem states that if 1/a + 1/b = 1/c, where a, b, c are positive integers with no common factor, then a + b is the square of an integer. Alright, first, I need to parse the assumptions and the conclusion carefully.\n\nFirst, the assumptions:\n\n1. a, b, c are positive integers.\n2. They have no common factor. So, gcd(a, b, c) = 1.\n3. The equation 1/a + 1/b = 1/c holds.\n4. The conclusion to prove is that a + b is a perfect square.\n\nLet me start by working with the equation. Let's rewrite 1/a + 1/b = 1/c. Combining the fractions on the left, we get (b + a)/(ab) = 1/c. Cross-multiplying gives c(a + b) = ab. So, ab = c(a + b). \n\nHmm, maybe rearrange terms to ab - c(a + b) = 0. Let's see if we can factor this. Adding c² to both sides: ab - c(a + b) + c² = c². Then, the left side factors as (a - c)(b - c) = c². That's a useful step because now we have a product of two terms equal to a square. Since a, b, c are positive integers, (a - c) and (b - c) must be positive integers as well. Wait, but is that necessarily true? Let's check. Since a and b are positive integers, and 1/a + 1/b must equal 1/c, so each of 1/a and 1/b is less than 1/c, which would imply that a and b are greater than c. Therefore, a - c and b - c are positive integers. So, (a - c)(b - c) = c².\n\nNow, since (a - c) and (b - c) multiply to c², they must be divisors of c². Moreover, since a, b, c have no common factor, we need to ensure that this condition is maintained. Let's denote x = a - c and y = b - c. Then, x * y = c². Since x and y are positive integers, they are factors of c². \n\nBut since a, b, c have no common factor, we need to check if x and y are coprime. Wait, let's think. Suppose d is a common divisor of x and y. Then, d divides x = a - c and y = b - c. Then, d divides (a - c) and (b - c). Then, d would divide (a - c) + (b - c) = (a + b) - 2c. But from the equation ab = c(a + b), maybe we can relate this. Alternatively, since x * y = c², and d divides both x and y, then d² divides c², so d divides c. But if d divides c, then d divides a = x + c and b = y + c. Therefore, d would be a common divisor of a, b, c. But the problem states that a, b, c have no common factor, so d must be 1. Therefore, x and y must be coprime. \n\nTherefore, x and y are coprime positive integers with x * y = c². Since x and y are coprime and their product is a square, each of x and y must themselves be squares. Because in a coprime factorization, each prime factor in x and y must be distinct, so each factor must be a square. Therefore, x = m² and y = n², where m and n are positive integers, and m * n = c. Because x * y = (m²)(n²) = (m n)^2 = c², so c = m n.\n\nTherefore, substituting back:\n\na = x + c = m² + m n = m(m + n)\n\nb = y + c = n² + m n = n(m + n)\n\nSo, a = m(m + n), b = n(m + n), and c = m n.\n\nNow, let's compute a + b. That would be m(m + n) + n(m + n) = (m + n)(m + n) = (m + n)^2. Which is a perfect square. Therefore, a + b is the square of an integer, specifically (m + n)^2. \n\nBut wait, we need to check if the original condition that a, b, c have no common factor is satisfied. Let's see. Since a = m(m + n), b = n(m + n), and c = m n. Let's compute gcd(a, b, c). \n\nFirst, gcd(a, b) would be gcd(m(m + n), n(m + n)). Since m and n are factors here, and since m and n could have a common divisor. Wait, but earlier we concluded that x and y are coprime, which are m² and n², so m and n must themselves be coprime. Because if m and n had a common divisor d > 1, then x = m² and y = n² would have d² as a common divisor, contradicting that x and y are coprime. Therefore, m and n are coprime.\n\nTherefore, gcd(m, n) = 1. Then, let's compute gcd(a, b, c). \n\nCompute gcd(a, b, c) = gcd(m(m + n), n(m + n), m n). Let's see. Let d be a common divisor.\n\nSince d divides m(m + n) and n(m + n), and m and n are coprime. Let's factor d.\n\nSince m and n are coprime, any common divisor of m(m + n) and n(m + n) must divide (m + n). Because m and n are coprime, so if d divides m(m + n) and n(m + n), then d divides (m + n). Therefore, gcd(m(m + n), n(m + n)) = gcd(m, n) * gcd(m + n, m + n) = 1 * (m + n). Wait, but m and n are coprime, so perhaps the gcd is (m + n)? Wait, no, that's not necessarily correct. Wait, let me think again. Let's compute gcd(m(m + n), n(m + n)). Since m and n are coprime, the gcd is gcd(m(m + n), n(m + n)) = gcd(m(m + n), n(m + n)) = (m + n) * gcd(m, n) = (m + n)*1 = m + n. Because m and n are coprime, so gcd(m, n) = 1. So, gcd(a, b) = m + n. Then, we need to check if m + n divides c = m n. Since m and n are coprime, gcd(m + n, m n). Let's compute gcd(m + n, m n). Since m and n are coprime, any common divisor of m + n and m n must divide (m + n) and m n. If a prime p divides both m + n and m n, then since p divides m n and gcd(m, n) = 1, p divides either m or n. Suppose p divides m, then since p divides m + n, it would also divide n, which contradicts gcd(m, n) = 1. Similarly, if p divides n, same contradiction. Therefore, gcd(m + n, m n) = 1. Therefore, gcd(a, b) = m + n, and gcd(m + n, c) = gcd(m + n, m n) = 1. Therefore, the overall gcd(a, b, c) = gcd(gcd(a, b), c) = gcd(m + n, m n) = 1. Hence, the condition that a, b, c have no common factor is satisfied only if m + n and m n are coprime, which we just established. Therefore, the gcd(a, b, c) is 1, as required.\n\nTherefore, the conclusion that a + b = (m + n)^2 holds, given the conditions. Thus, the problem is proved.\n\nBut let me check with an example. Suppose m = 1, n = 2 (coprime). Then c = 1*2 = 2. a = 1*(1 + 2) = 3, b = 2*(1 + 2) = 6. Then a + b = 9, which is 3². Check if 1/3 + 1/6 = 1/2. Yes, 1/3 + 1/6 = 1/2. And gcd(3, 6, 2) is 1? Wait, gcd(3,6,2) is 1? Wait, gcd(3,6) is 3, then gcd(3,2) is 1. So, the overall gcd is 1. Hmm, but in this case, a = 3, b = 6, c = 2. gcd(a, b, c) = 1. So, it works. Another example: m = 2, n = 3. Then c = 6. a = 2*(2 + 3) = 10, b = 3*(2 + 3) = 15. a + b = 25 = 5². 1/10 + 1/15 = (3 + 2)/30 = 5/30 = 1/6 = 1/c. And gcd(10, 15, 6) = 1. Indeed, gcd(10,15) = 5, gcd(5,6) = 1. So yes, works. \n\nSo, this seems to hold. Therefore, the proof is complete.",
    "Original_Problem": "Assumption: \n$a$, $b$, $c$ are positive integers,\n$\\gcd(a, b, c) = 1$,\n$\\frac{1}{a} + \\frac{1}{b} = \\frac{1}{c}$.\nProblem: \nProve that $a + b$ is the square of an integer.",
    "Original_Problem_with_numerical_assumption": "Assumption:\nAssumption 1: $a$, $b$, $c$ are positive integers,\nAssumption 2: $\\gcd(a, b, c) = 1$,\nAssumption 3: $\\frac{1}{a} + \\frac{1}{b} = \\frac{1}{c}$.\nProblem: \nProve that $a + b$ is the square of an integer.",
    "Proof_problem": "Yes",
    "Redundant_assumption": "$$(a' + b') = g,$$",
    "Problem_with_redundant_assumption": "Assumption:\nAssumption 1: $a$, $b$, $c$ are positive integers,\nAssumption 2: $\\gcd(a, b, c) = 1$,\nAssumption 3: $\\frac{1}{a} + \\frac{1}{b} = \\frac{1}{c}$.\nAssumption 4: $$(a' + b') = g,$$\nProblem: \nProve that $a + b$ is the square of an integer."
}